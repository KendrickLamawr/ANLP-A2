{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yu_Gne3-AfAe"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import html\n",
        "from ftfy import fix_text\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Table of contents**  <a class=\"anchor\" id=\"toc\"></a>\n",
        "### 1. [Data Collection](#first-bullet)   \n",
        "### 2. [Data Preprocessing](#second-bullet)  \n",
        "### 3. [Graphical representation of the dataset](#third-bullet)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4YpA3nw0E0I"
      },
      "source": [
        "# __1. Data Collection <a class=\"anchor\" id=\"first-bullet\"></a>__  \n",
        "[Table of Contents](#toc)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDT9ksXD1lGd"
      },
      "source": [
        "I've written a function called `fetch_questions` that's designed to gather questions from Stack Overflow related to Natural Language Processing (NLP) and related areas.\n",
        "\n",
        "Here's a step-by-step explanation:\n",
        "\n",
        "1.  **Setting up the API:**\n",
        "    * I start by defining the base URL for the Stack Exchange API, which is where I'll be requesting the data from.\n",
        "    * I initialize an empty list called `all_questions` to store all the questions I retrieve.\n",
        "    * I have a list of tags related to NLP, like 'nlp', 'language-model', 'text-classification', and many more. This list is important because I'll use these tags to filter the questions I want.\n",
        "    * I define a dictionary called 'params' that contains all the parameters that will be passed to the stackoverflow api. These parameters include:\n",
        "        * 'page_size': how many questions should be returned per page.\n",
        "        * 'accepted': only return questions that have accepted answers.\n",
        "        * 'order': order the returned questions by their creation date.\n",
        "        * 'sort': sort the returned questions by their creation date.\n",
        "        * 'site': the site to get the questions from, which is stackoverflow.\n",
        "        * 'tagged': the tag to filter the questions by.\n",
        "        * 'key': my api key.\n",
        "        * 'filter': include the body of the question in the returned data.\n",
        "\n",
        "2.  **Looping through Pages and Tags:**\n",
        "    * I use a `while` loop to keep fetching questions until I have at least 30,000 questions.\n",
        "    * Inside the loop, I set the `page` and `tagged` parameters in my request.\n",
        "    * I make a request to the Stack Exchange API using the `requests.get()` function.\n",
        "    * I check if the API request was successful (status code 200). If not, I print an error message and stop.\n",
        "    * I print out the page number to monitor the progress of the data fetching.\n",
        "    * I then extract the 'items' from the json response, which are the questions, and append them to the 'all_questions' list.\n",
        "    * I increse the size variable, that keeps track of how many questions have been added.\n",
        "    * I add a small delay using `time.sleep(1)` to avoid overwhelming the API.\n",
        "    * I increment the page number.\n",
        "    * I check if there are more pages for the current tag. If not, I move to the next tag in the list.\n",
        "    * If all tags have been processed, the loop stops.\n",
        "\n",
        "3.  **Returning the Results:**\n",
        "    * Finally, I return the `all_questions` list, which now contains all the fetched questions.\n",
        "\n",
        "4.  **Creating a DataFrame:**\n",
        "    * Outside the function, I call `fetch_questions()` to get the questions.\n",
        "    * I then convert the list of questions into a Pandas DataFrame for easier data manipulation.\n",
        "\n",
        "In essence, I'm using the Stack Exchange API to gather a large dataset of NLP-related questions from Stack Overflow, ensuring I only get questions with accepted answers. I'm iterating through multiple pages and tags to gather enough data. Then, I convert this data into a Pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpjCuLg2h1kH",
        "outputId": "e51719e3-9920-4696-e062-8ca93ee81360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching data from 1-th page of tag nlp...\n",
            "Fetching data from 21-th page of tag nlp...\n",
            "Fetching data from 41-th page of tag nlp...\n",
            "Fetching data from 61-th page of tag nlp...\n",
            "Fetching data from 81-th page of tag nlp...\n",
            "Fetching data from 101-th page of tag nlp...\n",
            "Fetching data from 121-th page of tag nlp...\n",
            "Fetching data from 141-th page of tag nlp...\n",
            "Fetching data from 161-th page of tag nlp...\n",
            "Fetching data from 181-th page of tag nlp...\n",
            "Fetching data from 201-th page of tag nlp...\n",
            "Fetching data from 221-th page of tag nlp...\n",
            "Fetching data from 241-th page of tag nlp...\n",
            "Fetching data from 261-th page of tag nlp...\n",
            "Fetching data from 281-th page of tag nlp...\n",
            "Fetching data from 1-th page of tag language-model...\n",
            "Fetching data from 1-th page of tag text-classification...\n",
            "Fetching data from 21-th page of tag text-classification...\n",
            "Fetching data from 1-th page of tag word-embedding...\n",
            "Fetching data from 1-th page of tag spacy...\n",
            "Fetching data from 21-th page of tag spacy...\n",
            "Fetching data from 41-th page of tag spacy...\n",
            "Fetching data from 1-th page of tag nltk...\n",
            "Fetching data from 21-th page of tag nltk...\n",
            "Fetching data from 41-th page of tag nltk...\n",
            "Fetching data from 61-th page of tag nltk...\n",
            "Fetching data from 81-th page of tag nltk...\n",
            "Fetching data from 101-th page of tag nltk...\n",
            "Fetching data from 1-th page of tag seq2seq...\n",
            "Fetching data from 1-th page of tag sentence-similarity...\n",
            "Fetching data from 1-th page of tag named-entity-recognition...\n",
            "Fetching data from 1-th page of tag text-processing...\n",
            "Fetching data from 21-th page of tag text-processing...\n",
            "Fetching data from 41-th page of tag text-processing...\n",
            "Fetching data from 1-th page of tag text-mining...\n",
            "Fetching data from 21-th page of tag text-mining...\n",
            "Fetching data from 1-th page of tag sentiment-analysis...\n",
            "Fetching data from 21-th page of tag sentiment-analysis...\n",
            "Fetching data from 1-th page of tag stemming...\n",
            "Fetching data from 1-th page of tag lemmatization...\n",
            "Fetching data from 1-th page of tag huggingface-transformers...\n",
            "Fetching data from 21-th page of tag huggingface-transformers...\n",
            "Fetching data from 1-th page of tag tokenization...\n",
            "Fetching data from 1-th page of tag lstm...\n",
            "Fetching data from 21-th page of tag lstm...\n",
            "Fetching data from 41-th page of tag lstm...\n",
            "Fetching data from 61-th page of tag lstm...\n",
            "Fetching data from 1-th page of tag chatbot...\n",
            "Fetching data from 21-th page of tag chatbot...\n",
            "Fetching data from 41-th page of tag chatbot...\n",
            "Fetching data from 1-th page of tag language-detection...\n",
            "Fetching data from 1-th page of tag speech-to-text...\n",
            "Fetching data from 21-th page of tag speech-to-text...\n",
            "Fetching data from 1-th page of tag text-to-speech...\n",
            "Fetching data from 21-th page of tag text-to-speech...\n",
            "Fetching data from 41-th page of tag text-to-speech...\n",
            "Fetching data from 1-th page of tag gensim...\n",
            "Fetching data from 21-th page of tag gensim...\n",
            "Fetching data from 1-th page of tag deep-learning...\n",
            "Fetching data from 21-th page of tag deep-learning...\n",
            "Fetching data from 41-th page of tag deep-learning...\n",
            "Fetching data from 61-th page of tag deep-learning...\n",
            "Fetching data from 81-th page of tag deep-learning...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def fetch_questions(pages=200, page_size=30):\n",
        "    \"\"\"\n",
        "    Fetches Stack Overflow questions related to Natural Language Processing (NLP) and related topics using the Stack Exchange API.\n",
        "\n",
        "    Args:\n",
        "        pages (int, optional): The maximum number of pages to fetch. Defaults to 200.\n",
        "        page_size (int, optional): The number of questions to fetch per page. Defaults to 100.\n",
        "    Returns:\n",
        "        list: A list of dictionaries, where each dictionary represents a question.\n",
        "    \"\"\"\n",
        "\n",
        "    BASE_URL = \"https://api.stackexchange.com/2.3/search/advanced\"\n",
        "    all_questions = []\n",
        "\n",
        "    tags = ['nlp', 'language-model', 'text-classification', 'word-embedding', 'spacy', 'nltk', 'seq2seq',\n",
        "            'sentence-similarity', 'named-entity-recognition', 'text-processing', 'text-mining',\n",
        "            'sentiment-analysis', 'stemming', 'lemmatization', \"huggingface-transformers\",\n",
        "            'tokenization', 'lstm', 'chatbot', 'language-detection', 'speech-to-text',\n",
        "            'text-to-speech', 'gensim', 'deep-learning', 'machine-learning']  # Supplement 'nlp' if needed.\n",
        "\n",
        "    params = {\n",
        "        'page_size': 30,  # Number of questions per page from the API.\n",
        "        'accepted': 'True',  # Fetch only questions with accepted answers.\n",
        "        'order': 'desc',  # Order results by creation date (newest first).\n",
        "        'sort': 'creation',  # Sort by creation date.\n",
        "        'site': 'stackoverflow',  # Stack Overflow site.\n",
        "        'tagged': 'nlp',  # Initial tag to filter by.\n",
        "        'key': 'rl_GXP3yYDC5NCfRWViwHuhPwMAZ',  # My API key.\n",
        "        'filter': 'withbody',  # Include question body in the response.\n",
        "    }\n",
        "\n",
        "    page = 1\n",
        "    cur_tag = 0\n",
        "    size = 0\n",
        "    while size < 30000:  # Ensure we collect at least 30,000 questions, even if it requires using multiple related tags.\n",
        "        params[\"page\"] = page\n",
        "        params[\"tagged\"] = tags[cur_tag]\n",
        "        response = requests.get(BASE_URL, params=params)\n",
        "        if response.status_code != 200:  # Handle API request errors.\n",
        "            print(f\"Error on page {page}: {response.status_code}. Skipping this page.\")\n",
        "            break\n",
        "\n",
        "        if page % 20 == 1:  # Print progress every 20 pages.\n",
        "            print(f\"Fetching data from {page}-th page of tag {tags[cur_tag]}...\")\n",
        "\n",
        "        data = response.json()\n",
        "        all_questions.extend(data.get(\"items\", []))\n",
        "        size += params['page_size']  # Track total questions fetched.\n",
        "        time.sleep(1)  # Prevent API rate limiting.\n",
        "        page += 1\n",
        "        if data[\"has_more\"] == False:  # Move to the next tag if no more pages for the current tag.\n",
        "            cur_tag += 1\n",
        "            page = 1\n",
        "            if cur_tag + 1 > len(tags):\n",
        "                break\n",
        "    return all_questions\n",
        "\n",
        "questions = fetch_questions()\n",
        "df = pd.DataFrame(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me-WYmqAAeUk"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"nlp_questions.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "U-x9J7wSSzz3",
        "outputId": "76276680-b4e0-446f-d718-710738ea5222"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6b88a200-9721-46cf-9d42-ec83bb9abac6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tags</th>\n",
              "      <th>owner</th>\n",
              "      <th>is_answered</th>\n",
              "      <th>view_count</th>\n",
              "      <th>closed_date</th>\n",
              "      <th>accepted_answer_id</th>\n",
              "      <th>answer_count</th>\n",
              "      <th>score</th>\n",
              "      <th>last_activity_date</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>...</th>\n",
              "      <th>closed_reason</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>content_license</th>\n",
              "      <th>last_edit_date</th>\n",
              "      <th>posted_by_collectives</th>\n",
              "      <th>migrated_from</th>\n",
              "      <th>protected_date</th>\n",
              "      <th>community_owned_date</th>\n",
              "      <th>locked_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[numpy, nlp, dependencies, google-colaboratory...</td>\n",
              "      <td>{'account_id': 8652474, 'reputation': 687, 'us...</td>\n",
              "      <td>True</td>\n",
              "      <td>89</td>\n",
              "      <td>1.743076e+09</td>\n",
              "      <td>79523777</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1742494070</td>\n",
              "      <td>1742481362</td>\n",
              "      <td>...</td>\n",
              "      <td>Duplicate</td>\n",
              "      <td>Trouble getting importing gensim to work in colab</td>\n",
              "      <td>&lt;p&gt;I am trying to import gensim into colab.&lt;/p...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[python, nlp, large-language-model]</td>\n",
              "      <td>{'account_id': 1230089, 'reputation': 5390, 'u...</td>\n",
              "      <td>True</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79501337</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1741708699</td>\n",
              "      <td>1741704631</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Store images instead of showing in a server</td>\n",
              "      <td>&lt;p&gt;I am running the code found on this [site][...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[python, nlp, spacy, langchain, presidio]</td>\n",
              "      <td>{'account_id': 22369526, 'reputation': 69, 'us...</td>\n",
              "      <td>True</td>\n",
              "      <td>210</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79495969</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1742055531</td>\n",
              "      <td>1741040827</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Presidio with Langchain Experimental does not ...</td>\n",
              "      <td>&lt;p&gt;I am using presidio/langchain_experimental ...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>1.741330e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[nlp, opennlp]</td>\n",
              "      <td>{'account_id': 21332, 'reputation': 5495, 'use...</td>\n",
              "      <td>True</td>\n",
              "      <td>32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79475445</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1740743750</td>\n",
              "      <td>1740240371</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OpenNLP POSTaggerME and ChunkerME synergy</td>\n",
              "      <td>&lt;p&gt;I'm trying to use the OpenNLP chunking API ...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>1.740586e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[python, python-3.x, nlp]</td>\n",
              "      <td>{'account_id': 3657839, 'reputation': 1081, 'u...</td>\n",
              "      <td>True</td>\n",
              "      <td>48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79461281</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1740316677</td>\n",
              "      <td>1739980065</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>word/ sentence similarities</td>\n",
              "      <td>&lt;p&gt;I am trying to find if a given word/ set of...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>1.740151e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b88a200-9721-46cf-9d42-ec83bb9abac6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6b88a200-9721-46cf-9d42-ec83bb9abac6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6b88a200-9721-46cf-9d42-ec83bb9abac6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b7e44b1c-dcd7-4582-b0e6-a1656e281a32\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7e44b1c-dcd7-4582-b0e6-a1656e281a32')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b7e44b1c-dcd7-4582-b0e6-a1656e281a32 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                tags  \\\n",
              "0  [numpy, nlp, dependencies, google-colaboratory...   \n",
              "1                [python, nlp, large-language-model]   \n",
              "2          [python, nlp, spacy, langchain, presidio]   \n",
              "3                                     [nlp, opennlp]   \n",
              "4                          [python, python-3.x, nlp]   \n",
              "\n",
              "                                               owner  is_answered  view_count  \\\n",
              "0  {'account_id': 8652474, 'reputation': 687, 'us...         True          89   \n",
              "1  {'account_id': 1230089, 'reputation': 5390, 'u...         True          26   \n",
              "2  {'account_id': 22369526, 'reputation': 69, 'us...         True         210   \n",
              "3  {'account_id': 21332, 'reputation': 5495, 'use...         True          32   \n",
              "4  {'account_id': 3657839, 'reputation': 1081, 'u...         True          48   \n",
              "\n",
              "    closed_date  accepted_answer_id  answer_count  score  last_activity_date  \\\n",
              "0  1.743076e+09            79523777             1      0          1742494070   \n",
              "1           NaN            79501337             1      0          1741708699   \n",
              "2           NaN            79495969             2      4          1742055531   \n",
              "3           NaN            79475445             1      1          1740743750   \n",
              "4           NaN            79461281             1      1          1740316677   \n",
              "\n",
              "   creation_date  ...  closed_reason  \\\n",
              "0     1742481362  ...      Duplicate   \n",
              "1     1741704631  ...            NaN   \n",
              "2     1741040827  ...            NaN   \n",
              "3     1740240371  ...            NaN   \n",
              "4     1739980065  ...            NaN   \n",
              "\n",
              "                                               title  \\\n",
              "0  Trouble getting importing gensim to work in colab   \n",
              "1        Store images instead of showing in a server   \n",
              "2  Presidio with Langchain Experimental does not ...   \n",
              "3          OpenNLP POSTaggerME and ChunkerME synergy   \n",
              "4                        word/ sentence similarities   \n",
              "\n",
              "                                                body content_license  \\\n",
              "0  <p>I am trying to import gensim into colab.</p...             NaN   \n",
              "1  <p>I am running the code found on this [site][...    CC BY-SA 4.0   \n",
              "2  <p>I am using presidio/langchain_experimental ...    CC BY-SA 4.0   \n",
              "3  <p>I'm trying to use the OpenNLP chunking API ...    CC BY-SA 4.0   \n",
              "4  <p>I am trying to find if a given word/ set of...    CC BY-SA 4.0   \n",
              "\n",
              "  last_edit_date posted_by_collectives  migrated_from protected_date  \\\n",
              "0            NaN                   NaN            NaN            NaN   \n",
              "1            NaN                   NaN            NaN            NaN   \n",
              "2   1.741330e+09                   NaN            NaN            NaN   \n",
              "3   1.740586e+09                   NaN            NaN            NaN   \n",
              "4   1.740151e+09                   NaN            NaN            NaN   \n",
              "\n",
              "  community_owned_date  locked_date  \n",
              "0                  NaN          NaN  \n",
              "1                  NaN          NaN  \n",
              "2                  NaN          NaN  \n",
              "3                  NaN          NaN  \n",
              "4                  NaN          NaN  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJxrM1zJZNVs",
        "outputId": "f29176df-837c-4b7f-8ab3-0ae77466de0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 29638 entries, 0 to 29637\n",
            "Data columns (total 22 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   tags                   29638 non-null  object \n",
            " 1   owner                  29638 non-null  object \n",
            " 2   is_answered            29638 non-null  bool   \n",
            " 3   view_count             29638 non-null  int64  \n",
            " 4   closed_date            1222 non-null   float64\n",
            " 5   accepted_answer_id     29638 non-null  int64  \n",
            " 6   answer_count           29638 non-null  int64  \n",
            " 7   score                  29638 non-null  int64  \n",
            " 8   last_activity_date     29638 non-null  int64  \n",
            " 9   creation_date          29638 non-null  int64  \n",
            " 10  question_id            29638 non-null  int64  \n",
            " 11  link                   29638 non-null  object \n",
            " 12  closed_reason          1222 non-null   object \n",
            " 13  title                  29638 non-null  object \n",
            " 14  body                   29638 non-null  object \n",
            " 15  content_license        28388 non-null  object \n",
            " 16  last_edit_date         16534 non-null  float64\n",
            " 17  posted_by_collectives  6 non-null      object \n",
            " 18  migrated_from          35 non-null     object \n",
            " 19  protected_date         121 non-null    float64\n",
            " 20  community_owned_date   11 non-null     float64\n",
            " 21  locked_date            4 non-null      float64\n",
            "dtypes: bool(1), float64(5), int64(7), object(9)\n",
            "memory usage: 4.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU_3wBRz2Frw"
      },
      "source": [
        "### There are some posts might have several tags, so that if we retrieve posts data by querying with different tags, there probably are duplicated posts, here I remove duplicated posts by checking if posts' '__link__' are unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDDxImDEaLIW"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_excel(\"nlp_questions.xlsx\", engine=\"openpyxl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8Vq4UlhZQRw",
        "outputId": "79d35401-bfb7-46d5-9929-7dec85091e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 24776 entries, 0 to 24775\n",
            "Data columns (total 22 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   tags                   24776 non-null  object \n",
            " 1   owner                  24775 non-null  object \n",
            " 2   is_answered            24775 non-null  object \n",
            " 3   view_count             24775 non-null  object \n",
            " 4   closed_date            1033 non-null   float64\n",
            " 5   accepted_answer_id     24775 non-null  float64\n",
            " 6   answer_count           24774 non-null  float64\n",
            " 7   score                  24775 non-null  float64\n",
            " 8   last_activity_date     24775 non-null  float64\n",
            " 9   creation_date          24775 non-null  float64\n",
            " 10  question_id            24775 non-null  float64\n",
            " 11  link                   24775 non-null  object \n",
            " 12  closed_reason          1033 non-null   object \n",
            " 13  title                  24774 non-null  object \n",
            " 14  body                   24774 non-null  object \n",
            " 15  content_license        23712 non-null  object \n",
            " 16  last_edit_date         13876 non-null  object \n",
            " 17  posted_by_collectives  4 non-null      object \n",
            " 18  migrated_from          34 non-null     object \n",
            " 19  protected_date         99 non-null     float64\n",
            " 20  community_owned_date   11 non-null     object \n",
            " 21  locked_date            3 non-null      float64\n",
            "dtypes: float64(9), object(13)\n",
            "memory usage: 4.2+ MB\n"
          ]
        }
      ],
      "source": [
        "df_unique = df.drop_duplicates(subset=['link'], keep='first') #remove duplicated posts\n",
        "df_unique = df_unique.reset_index(drop=True)\n",
        "df_unique.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aC0uabVZaK2r"
      },
      "outputs": [],
      "source": [
        "# df_unique.to_csv('nlp_questions_unique.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p8uLmfBPo8JC",
        "outputId": "216f67dc-8991-4ad5-ebd5-a519997e5279"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tags</th>\n",
              "      <th>owner</th>\n",
              "      <th>is_answered</th>\n",
              "      <th>view_count</th>\n",
              "      <th>closed_date</th>\n",
              "      <th>accepted_answer_id</th>\n",
              "      <th>answer_count</th>\n",
              "      <th>score</th>\n",
              "      <th>last_activity_date</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>...</th>\n",
              "      <th>closed_reason</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>content_license</th>\n",
              "      <th>last_edit_date</th>\n",
              "      <th>posted_by_collectives</th>\n",
              "      <th>migrated_from</th>\n",
              "      <th>protected_date</th>\n",
              "      <th>community_owned_date</th>\n",
              "      <th>locked_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['numpy', 'nlp', 'dependencies', 'google-colab...</td>\n",
              "      <td>{'account_id': 8652474, 'reputation': 687, 'us...</td>\n",
              "      <td>True</td>\n",
              "      <td>89</td>\n",
              "      <td>1.743076e+09</td>\n",
              "      <td>79523777.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.742494e+09</td>\n",
              "      <td>1.742481e+09</td>\n",
              "      <td>...</td>\n",
              "      <td>Duplicate</td>\n",
              "      <td>Trouble getting importing gensim to work in colab</td>\n",
              "      <td>&lt;p&gt;I am trying to import gensim into colab.&lt;/p...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['python', 'nlp', 'large-language-model']</td>\n",
              "      <td>{'account_id': 1230089, 'reputation': 5390, 'u...</td>\n",
              "      <td>True</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79501337.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.741709e+09</td>\n",
              "      <td>1.741705e+09</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Store images instead of showing in a server</td>\n",
              "      <td>&lt;p&gt;I am running the code found on this [site][...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['python', 'nlp', 'spacy', 'langchain', 'presi...</td>\n",
              "      <td>{'account_id': 22369526, 'reputation': 69, 'us...</td>\n",
              "      <td>True</td>\n",
              "      <td>210</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79495969.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.742056e+09</td>\n",
              "      <td>1.741041e+09</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Presidio with Langchain Experimental does not ...</td>\n",
              "      <td>&lt;p&gt;I am using presidio/langchain_experimental ...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>1741330413</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['nlp', 'opennlp']</td>\n",
              "      <td>{'account_id': 21332, 'reputation': 5495, 'use...</td>\n",
              "      <td>True</td>\n",
              "      <td>32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79475445.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.740744e+09</td>\n",
              "      <td>1.740240e+09</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OpenNLP POSTaggerME and ChunkerME synergy</td>\n",
              "      <td>&lt;p&gt;I'm trying to use the OpenNLP chunking API ...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>1740586328</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['python', 'python-3.x', 'nlp']</td>\n",
              "      <td>{'account_id': 3657839, 'reputation': 1081, 'u...</td>\n",
              "      <td>True</td>\n",
              "      <td>48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79461281.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.740317e+09</td>\n",
              "      <td>1.739980e+09</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>word/ sentence similarities</td>\n",
              "      <td>&lt;p&gt;I am trying to find if a given word/ set of...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>1740151158</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24771</th>\n",
              "      <td>['python', 'numpy', 'tensorflow', 'deep-learni...</td>\n",
              "      <td>{'account_id': 15718018, 'reputation': 49, 'us...</td>\n",
              "      <td>True</td>\n",
              "      <td>562</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65634693.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.610131e+09</td>\n",
              "      <td>1.610130e+09</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>train test split is not splitting correctly</td>\n",
              "      <td>&lt;p&gt;I am still a beginner in AI and deep learni...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>1610131142</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24772</th>\n",
              "      <td>['machine-learning', 'scikit-learn', 'deep-lea...</td>\n",
              "      <td>{'account_id': 15851108, 'reputation': 42, 'us...</td>\n",
              "      <td>True</td>\n",
              "      <td>5106</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65629414.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.640657e+09</td>\n",
              "      <td>1.610103e+09</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MultinomialNB or GaussianNB or CategoricalNB w...</td>\n",
              "      <td>&lt;p&gt;Let I have a input feature &lt;code&gt;X = {X1, X...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>1610206542</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24773</th>\n",
              "      <td>['python', 'deep-learning', 'pytorch', 'conv-n...</td>\n",
              "      <td>{'account_id': 17239237, 'reputation': 17, 'us...</td>\n",
              "      <td>True</td>\n",
              "      <td>607</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65635714.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.614703e+09</td>\n",
              "      <td>1.610103e+09</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Custom small CNN has better accuracy than the ...</td>\n",
              "      <td>&lt;p&gt;I have a dataset of laser welding images of...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>1610105061</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24774</th>\n",
              "      <td>['deep-learning', 'computer-vision', 'object-d...</td>\n",
              "      <td>{'account_id': 9126690, 'reputation': 406, 'us...</td>\n",
              "      <td>True</td>\n",
              "      <td>462</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65611595.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.610042e+09</td>\n",
              "      <td>1.610019e+09</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Creating a dataset of images for object detect...</td>\n",
              "      <td>&lt;p&gt;Even though I am quite familiar with the co...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>1610041831</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24775</th>\n",
              "      <td>['deep-learning', 'computer-vision']</td>\n",
              "      <td>{'account_id': 14251423, 'reputation': 3, 'use...</td>\n",
              "      <td>True</td>\n",
              "      <td>742</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65611051.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.610017e+09</td>\n",
              "      <td>1.610015e+09</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Object detection in RGB-D images</td>\n",
              "      <td>&lt;p&gt;Can you please recommend papers/github or s...</td>\n",
              "      <td>CC BY-SA 4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24774 rows Ã— 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    tags  \\\n",
              "0      ['numpy', 'nlp', 'dependencies', 'google-colab...   \n",
              "1              ['python', 'nlp', 'large-language-model']   \n",
              "2      ['python', 'nlp', 'spacy', 'langchain', 'presi...   \n",
              "3                                     ['nlp', 'opennlp']   \n",
              "4                        ['python', 'python-3.x', 'nlp']   \n",
              "...                                                  ...   \n",
              "24771  ['python', 'numpy', 'tensorflow', 'deep-learni...   \n",
              "24772  ['machine-learning', 'scikit-learn', 'deep-lea...   \n",
              "24773  ['python', 'deep-learning', 'pytorch', 'conv-n...   \n",
              "24774  ['deep-learning', 'computer-vision', 'object-d...   \n",
              "24775               ['deep-learning', 'computer-vision']   \n",
              "\n",
              "                                                   owner is_answered  \\\n",
              "0      {'account_id': 8652474, 'reputation': 687, 'us...        True   \n",
              "1      {'account_id': 1230089, 'reputation': 5390, 'u...        True   \n",
              "2      {'account_id': 22369526, 'reputation': 69, 'us...        True   \n",
              "3      {'account_id': 21332, 'reputation': 5495, 'use...        True   \n",
              "4      {'account_id': 3657839, 'reputation': 1081, 'u...        True   \n",
              "...                                                  ...         ...   \n",
              "24771  {'account_id': 15718018, 'reputation': 49, 'us...        True   \n",
              "24772  {'account_id': 15851108, 'reputation': 42, 'us...        True   \n",
              "24773  {'account_id': 17239237, 'reputation': 17, 'us...        True   \n",
              "24774  {'account_id': 9126690, 'reputation': 406, 'us...        True   \n",
              "24775  {'account_id': 14251423, 'reputation': 3, 'use...        True   \n",
              "\n",
              "      view_count   closed_date  accepted_answer_id  answer_count  score  \\\n",
              "0             89  1.743076e+09          79523777.0           1.0    0.0   \n",
              "1             26           NaN          79501337.0           1.0    0.0   \n",
              "2            210           NaN          79495969.0           2.0    4.0   \n",
              "3             32           NaN          79475445.0           1.0    1.0   \n",
              "4             48           NaN          79461281.0           1.0    1.0   \n",
              "...          ...           ...                 ...           ...    ...   \n",
              "24771        562           NaN          65634693.0           1.0    0.0   \n",
              "24772       5106           NaN          65629414.0           2.0    2.0   \n",
              "24773        607           NaN          65635714.0           1.0    0.0   \n",
              "24774        462           NaN          65611595.0           1.0    1.0   \n",
              "24775        742           NaN          65611051.0           1.0    0.0   \n",
              "\n",
              "       last_activity_date  creation_date  ...  closed_reason  \\\n",
              "0            1.742494e+09   1.742481e+09  ...      Duplicate   \n",
              "1            1.741709e+09   1.741705e+09  ...            NaN   \n",
              "2            1.742056e+09   1.741041e+09  ...            NaN   \n",
              "3            1.740744e+09   1.740240e+09  ...            NaN   \n",
              "4            1.740317e+09   1.739980e+09  ...            NaN   \n",
              "...                   ...            ...  ...            ...   \n",
              "24771        1.610131e+09   1.610130e+09  ...            NaN   \n",
              "24772        1.640657e+09   1.610103e+09  ...            NaN   \n",
              "24773        1.614703e+09   1.610103e+09  ...            NaN   \n",
              "24774        1.610042e+09   1.610019e+09  ...            NaN   \n",
              "24775        1.610017e+09   1.610015e+09  ...            NaN   \n",
              "\n",
              "                                                   title  \\\n",
              "0      Trouble getting importing gensim to work in colab   \n",
              "1            Store images instead of showing in a server   \n",
              "2      Presidio with Langchain Experimental does not ...   \n",
              "3              OpenNLP POSTaggerME and ChunkerME synergy   \n",
              "4                            word/ sentence similarities   \n",
              "...                                                  ...   \n",
              "24771        train test split is not splitting correctly   \n",
              "24772  MultinomialNB or GaussianNB or CategoricalNB w...   \n",
              "24773  Custom small CNN has better accuracy than the ...   \n",
              "24774  Creating a dataset of images for object detect...   \n",
              "24775                   Object detection in RGB-D images   \n",
              "\n",
              "                                                    body content_license  \\\n",
              "0      <p>I am trying to import gensim into colab.</p...             NaN   \n",
              "1      <p>I am running the code found on this [site][...    CC BY-SA 4.0   \n",
              "2      <p>I am using presidio/langchain_experimental ...    CC BY-SA 4.0   \n",
              "3      <p>I'm trying to use the OpenNLP chunking API ...    CC BY-SA 4.0   \n",
              "4      <p>I am trying to find if a given word/ set of...    CC BY-SA 4.0   \n",
              "...                                                  ...             ...   \n",
              "24771  <p>I am still a beginner in AI and deep learni...    CC BY-SA 4.0   \n",
              "24772  <p>Let I have a input feature <code>X = {X1, X...    CC BY-SA 4.0   \n",
              "24773  <p>I have a dataset of laser welding images of...    CC BY-SA 4.0   \n",
              "24774  <p>Even though I am quite familiar with the co...    CC BY-SA 4.0   \n",
              "24775  <p>Can you please recommend papers/github or s...    CC BY-SA 4.0   \n",
              "\n",
              "      last_edit_date posted_by_collectives migrated_from protected_date  \\\n",
              "0                NaN                   NaN           NaN            NaN   \n",
              "1                NaN                   NaN           NaN            NaN   \n",
              "2         1741330413                   NaN           NaN            NaN   \n",
              "3         1740586328                   NaN           NaN            NaN   \n",
              "4         1740151158                   NaN           NaN            NaN   \n",
              "...              ...                   ...           ...            ...   \n",
              "24771     1610131142                   NaN           NaN            NaN   \n",
              "24772     1610206542                   NaN           NaN            NaN   \n",
              "24773     1610105061                   NaN           NaN            NaN   \n",
              "24774     1610041831                   NaN           NaN            NaN   \n",
              "24775            NaN                   NaN           NaN            NaN   \n",
              "\n",
              "      community_owned_date  locked_date  \n",
              "0                      NaN          NaN  \n",
              "1                      NaN          NaN  \n",
              "2                      NaN          NaN  \n",
              "3                      NaN          NaN  \n",
              "4                      NaN          NaN  \n",
              "...                    ...          ...  \n",
              "24771                  NaN          NaN  \n",
              "24772                  NaN          NaN  \n",
              "24773                  NaN          NaN  \n",
              "24774                  NaN          NaN  \n",
              "24775                  NaN          NaN  \n",
              "\n",
              "[24774 rows x 22 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop question with Nan/null question_id and body (because we cannot retrieve its answer if question_id is null, and drop rows with null body because there's barely content for us to implement sentiment analysis)\n",
        "df_unique = df_unique.dropna(subset=['question_id', 'body'])\n",
        "df_unique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzMPBWjb2pwA"
      },
      "source": [
        "### Querying __accepted__ answers from fetched posts (because original fetched data only contains of only 1 accepted answer per post)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ51YwF-ppB9",
        "outputId": "e117944b-0cb4-407d-9d12-9bc8dfcb254b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24774\n"
          ]
        }
      ],
      "source": [
        "len_ques = len(df_unique['link'].unique()) #check if all questions in this dataframe is unique\n",
        "print(len_ques)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cgJyO-GV34pU"
      },
      "outputs": [],
      "source": [
        "cols = ['title', 'description', 'tags', 'accepted answer 1', 'accepted answer 2', 'creation date', 'view count', 'score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8nmYpTRPgn50"
      },
      "outputs": [],
      "source": [
        "#Method to get accepted answers from given question ID(s)\n",
        "def get_answers_for_question(question_ids):\n",
        "    url = f\"https://api.stackexchange.com/2.3/questions/{question_ids}/answers\"\n",
        "    res = []\n",
        "    has_more = True\n",
        "    params = {\n",
        "        'page_size': 30,\n",
        "        'order': 'desc',\n",
        "        'sort': 'votes',\n",
        "        'site': 'stackoverflow',\n",
        "        'filter': '!6WPIomp1bTBj5', #is_accepted filter\n",
        "        'key':'rl_GXP3yYDC5NCfRWViwHuhPwMAZ', # my key :3\n",
        "    }\n",
        "    page=0\n",
        "    # Loop over to get all answers until has_more == False\n",
        "    while has_more:\n",
        "        page+=1\n",
        "        params['page'] = page\n",
        "        response = requests.get(url, params=params)\n",
        "        # Update has_more variable\n",
        "        has_more = response.json().get('has_more', False)\n",
        "        res.extend(response.json().get('items', []))\n",
        "\n",
        "    return res\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsSR0oci2oSy",
        "outputId": "7e1dc4b4-7e3b-4616-8d5f-ee5e89c8a8d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1: fetching answer for questions from index 0 to 30...\n",
            "Iteration 2: fetching answer for questions from index 30 to 60...\n",
            "Iteration 3: fetching answer for questions from index 60 to 90...\n",
            "Iteration 4: fetching answer for questions from index 90 to 120...\n",
            "Iteration 5: fetching answer for questions from index 120 to 150...\n",
            "Iteration 6: fetching answer for questions from index 150 to 180...\n",
            "Iteration 7: fetching answer for questions from index 180 to 210...\n",
            "Iteration 8: fetching answer for questions from index 210 to 240...\n",
            "Iteration 9: fetching answer for questions from index 240 to 270...\n",
            "Iteration 10: fetching answer for questions from index 270 to 300...\n",
            "Iteration 11: fetching answer for questions from index 300 to 330...\n",
            "Iteration 12: fetching answer for questions from index 330 to 360...\n",
            "Iteration 13: fetching answer for questions from index 360 to 390...\n",
            "Iteration 14: fetching answer for questions from index 390 to 420...\n",
            "Iteration 15: fetching answer for questions from index 420 to 450...\n",
            "Iteration 16: fetching answer for questions from index 450 to 480...\n",
            "Iteration 17: fetching answer for questions from index 480 to 510...\n",
            "Iteration 18: fetching answer for questions from index 510 to 540...\n",
            "Iteration 19: fetching answer for questions from index 540 to 570...\n",
            "Iteration 20: fetching answer for questions from index 570 to 600...\n",
            "Iteration 21: fetching answer for questions from index 600 to 630...\n",
            "Iteration 22: fetching answer for questions from index 630 to 660...\n",
            "Iteration 23: fetching answer for questions from index 660 to 690...\n",
            "Iteration 24: fetching answer for questions from index 690 to 720...\n",
            "Iteration 25: fetching answer for questions from index 720 to 750...\n",
            "Iteration 26: fetching answer for questions from index 750 to 780...\n",
            "Iteration 27: fetching answer for questions from index 780 to 810...\n",
            "Iteration 28: fetching answer for questions from index 810 to 840...\n",
            "Iteration 29: fetching answer for questions from index 840 to 870...\n",
            "Iteration 30: fetching answer for questions from index 870 to 900...\n",
            "Iteration 31: fetching answer for questions from index 900 to 930...\n",
            "Iteration 32: fetching answer for questions from index 930 to 960...\n",
            "Iteration 33: fetching answer for questions from index 960 to 990...\n",
            "Iteration 34: fetching answer for questions from index 990 to 1020...\n",
            "Iteration 35: fetching answer for questions from index 1020 to 1050...\n",
            "Iteration 36: fetching answer for questions from index 1050 to 1080...\n",
            "Iteration 37: fetching answer for questions from index 1080 to 1110...\n",
            "Iteration 38: fetching answer for questions from index 1110 to 1140...\n",
            "Iteration 39: fetching answer for questions from index 1140 to 1170...\n",
            "Iteration 40: fetching answer for questions from index 1170 to 1200...\n",
            "Iteration 41: fetching answer for questions from index 1200 to 1230...\n",
            "Iteration 42: fetching answer for questions from index 1230 to 1260...\n",
            "Iteration 43: fetching answer for questions from index 1260 to 1290...\n",
            "Iteration 44: fetching answer for questions from index 1290 to 1320...\n",
            "Iteration 45: fetching answer for questions from index 1320 to 1350...\n",
            "Iteration 46: fetching answer for questions from index 1350 to 1380...\n",
            "Iteration 47: fetching answer for questions from index 1380 to 1410...\n",
            "Iteration 48: fetching answer for questions from index 1410 to 1440...\n",
            "Iteration 49: fetching answer for questions from index 1440 to 1470...\n",
            "Iteration 50: fetching answer for questions from index 1470 to 1500...\n",
            "Iteration 51: fetching answer for questions from index 1500 to 1530...\n",
            "Iteration 52: fetching answer for questions from index 1530 to 1560...\n",
            "Iteration 53: fetching answer for questions from index 1560 to 1590...\n",
            "Iteration 54: fetching answer for questions from index 1590 to 1620...\n",
            "Iteration 55: fetching answer for questions from index 1620 to 1650...\n",
            "Iteration 56: fetching answer for questions from index 1650 to 1680...\n",
            "Iteration 57: fetching answer for questions from index 1680 to 1710...\n",
            "Iteration 58: fetching answer for questions from index 1710 to 1740...\n",
            "Iteration 59: fetching answer for questions from index 1740 to 1770...\n",
            "Iteration 60: fetching answer for questions from index 1770 to 1800...\n",
            "Iteration 61: fetching answer for questions from index 1800 to 1830...\n",
            "Iteration 62: fetching answer for questions from index 1830 to 1860...\n",
            "Iteration 63: fetching answer for questions from index 1860 to 1890...\n",
            "Iteration 64: fetching answer for questions from index 1890 to 1920...\n",
            "Iteration 65: fetching answer for questions from index 1920 to 1950...\n",
            "Iteration 66: fetching answer for questions from index 1950 to 1980...\n",
            "Iteration 67: fetching answer for questions from index 1980 to 2010...\n",
            "Iteration 68: fetching answer for questions from index 2010 to 2040...\n",
            "Iteration 69: fetching answer for questions from index 2040 to 2070...\n",
            "Iteration 70: fetching answer for questions from index 2070 to 2100...\n",
            "Iteration 71: fetching answer for questions from index 2100 to 2130...\n",
            "Iteration 72: fetching answer for questions from index 2130 to 2160...\n",
            "Iteration 73: fetching answer for questions from index 2160 to 2190...\n",
            "Iteration 74: fetching answer for questions from index 2190 to 2220...\n",
            "Iteration 75: fetching answer for questions from index 2220 to 2250...\n",
            "Iteration 76: fetching answer for questions from index 2250 to 2280...\n",
            "Iteration 77: fetching answer for questions from index 2280 to 2310...\n",
            "Iteration 78: fetching answer for questions from index 2310 to 2340...\n",
            "Iteration 79: fetching answer for questions from index 2340 to 2370...\n",
            "Iteration 80: fetching answer for questions from index 2370 to 2400...\n",
            "Iteration 81: fetching answer for questions from index 2400 to 2430...\n",
            "Iteration 82: fetching answer for questions from index 2430 to 2460...\n",
            "Iteration 83: fetching answer for questions from index 2460 to 2490...\n",
            "Iteration 84: fetching answer for questions from index 2490 to 2520...\n",
            "Iteration 85: fetching answer for questions from index 2520 to 2550...\n",
            "Iteration 86: fetching answer for questions from index 2550 to 2580...\n",
            "Iteration 87: fetching answer for questions from index 2580 to 2610...\n",
            "Iteration 88: fetching answer for questions from index 2610 to 2640...\n",
            "Iteration 89: fetching answer for questions from index 2640 to 2670...\n",
            "Iteration 90: fetching answer for questions from index 2670 to 2700...\n",
            "Iteration 91: fetching answer for questions from index 2700 to 2730...\n",
            "Iteration 92: fetching answer for questions from index 2730 to 2760...\n",
            "Iteration 93: fetching answer for questions from index 2760 to 2790...\n",
            "Iteration 94: fetching answer for questions from index 2790 to 2820...\n",
            "Iteration 95: fetching answer for questions from index 2820 to 2850...\n",
            "Iteration 96: fetching answer for questions from index 2850 to 2880...\n",
            "Iteration 97: fetching answer for questions from index 2880 to 2910...\n",
            "Iteration 98: fetching answer for questions from index 2910 to 2940...\n",
            "Iteration 99: fetching answer for questions from index 2940 to 2970...\n",
            "Iteration 100: fetching answer for questions from index 2970 to 3000...\n",
            "Iteration 101: fetching answer for questions from index 3000 to 3030...\n",
            "Iteration 102: fetching answer for questions from index 3030 to 3060...\n",
            "Iteration 103: fetching answer for questions from index 3060 to 3090...\n",
            "Iteration 104: fetching answer for questions from index 3090 to 3120...\n",
            "Iteration 105: fetching answer for questions from index 3120 to 3150...\n",
            "Iteration 106: fetching answer for questions from index 3150 to 3180...\n",
            "Iteration 107: fetching answer for questions from index 3180 to 3210...\n",
            "Iteration 108: fetching answer for questions from index 3210 to 3240...\n",
            "Iteration 109: fetching answer for questions from index 3240 to 3270...\n",
            "Iteration 110: fetching answer for questions from index 3270 to 3300...\n",
            "Iteration 111: fetching answer for questions from index 3300 to 3330...\n",
            "Iteration 112: fetching answer for questions from index 3330 to 3360...\n",
            "Iteration 113: fetching answer for questions from index 3360 to 3390...\n",
            "Iteration 114: fetching answer for questions from index 3390 to 3420...\n",
            "Iteration 115: fetching answer for questions from index 3420 to 3450...\n",
            "Iteration 116: fetching answer for questions from index 3450 to 3480...\n",
            "Iteration 117: fetching answer for questions from index 3480 to 3510...\n",
            "Iteration 118: fetching answer for questions from index 3510 to 3540...\n",
            "Iteration 119: fetching answer for questions from index 3540 to 3570...\n",
            "Iteration 120: fetching answer for questions from index 3570 to 3600...\n",
            "Iteration 121: fetching answer for questions from index 3600 to 3630...\n",
            "Iteration 122: fetching answer for questions from index 3630 to 3660...\n",
            "Iteration 123: fetching answer for questions from index 3660 to 3690...\n",
            "Iteration 124: fetching answer for questions from index 3690 to 3720...\n",
            "Iteration 125: fetching answer for questions from index 3720 to 3750...\n",
            "Iteration 126: fetching answer for questions from index 3750 to 3780...\n",
            "Iteration 127: fetching answer for questions from index 3780 to 3810...\n",
            "Iteration 128: fetching answer for questions from index 3810 to 3840...\n",
            "Iteration 129: fetching answer for questions from index 3840 to 3870...\n",
            "Iteration 130: fetching answer for questions from index 3870 to 3900...\n",
            "Iteration 131: fetching answer for questions from index 3900 to 3930...\n",
            "Iteration 132: fetching answer for questions from index 3930 to 3960...\n",
            "Iteration 133: fetching answer for questions from index 3960 to 3990...\n",
            "Iteration 134: fetching answer for questions from index 3990 to 4020...\n",
            "Iteration 135: fetching answer for questions from index 4020 to 4050...\n",
            "Iteration 136: fetching answer for questions from index 4050 to 4080...\n",
            "Iteration 137: fetching answer for questions from index 4080 to 4110...\n",
            "Iteration 138: fetching answer for questions from index 4110 to 4140...\n",
            "Iteration 139: fetching answer for questions from index 4140 to 4170...\n",
            "Iteration 140: fetching answer for questions from index 4170 to 4200...\n",
            "Iteration 141: fetching answer for questions from index 4200 to 4230...\n",
            "Iteration 142: fetching answer for questions from index 4230 to 4260...\n",
            "Iteration 143: fetching answer for questions from index 4260 to 4290...\n",
            "Iteration 144: fetching answer for questions from index 4290 to 4320...\n",
            "Iteration 145: fetching answer for questions from index 4320 to 4350...\n",
            "Iteration 146: fetching answer for questions from index 4350 to 4380...\n",
            "Iteration 147: fetching answer for questions from index 4380 to 4410...\n",
            "Iteration 148: fetching answer for questions from index 4410 to 4440...\n",
            "Iteration 149: fetching answer for questions from index 4440 to 4470...\n",
            "Iteration 150: fetching answer for questions from index 4470 to 4500...\n",
            "Iteration 151: fetching answer for questions from index 4500 to 4530...\n",
            "Iteration 152: fetching answer for questions from index 4530 to 4560...\n",
            "Iteration 153: fetching answer for questions from index 4560 to 4590...\n",
            "Iteration 154: fetching answer for questions from index 4590 to 4620...\n",
            "Iteration 155: fetching answer for questions from index 4620 to 4650...\n",
            "Iteration 156: fetching answer for questions from index 4650 to 4680...\n",
            "Iteration 157: fetching answer for questions from index 4680 to 4710...\n",
            "Iteration 158: fetching answer for questions from index 4710 to 4740...\n",
            "Iteration 159: fetching answer for questions from index 4740 to 4770...\n",
            "Iteration 160: fetching answer for questions from index 4770 to 4800...\n",
            "Iteration 161: fetching answer for questions from index 4800 to 4830...\n",
            "Iteration 162: fetching answer for questions from index 4830 to 4860...\n",
            "Iteration 163: fetching answer for questions from index 4860 to 4890...\n",
            "Iteration 164: fetching answer for questions from index 4890 to 4920...\n",
            "Iteration 165: fetching answer for questions from index 4920 to 4950...\n",
            "Iteration 166: fetching answer for questions from index 4950 to 4980...\n",
            "Iteration 167: fetching answer for questions from index 4980 to 5010...\n",
            "Iteration 168: fetching answer for questions from index 5010 to 5040...\n",
            "Iteration 169: fetching answer for questions from index 5040 to 5070...\n",
            "Iteration 170: fetching answer for questions from index 5070 to 5100...\n",
            "Iteration 171: fetching answer for questions from index 5100 to 5130...\n",
            "Iteration 172: fetching answer for questions from index 5130 to 5160...\n",
            "Iteration 173: fetching answer for questions from index 5160 to 5190...\n",
            "Iteration 174: fetching answer for questions from index 5190 to 5220...\n",
            "Iteration 175: fetching answer for questions from index 5220 to 5250...\n",
            "Iteration 176: fetching answer for questions from index 5250 to 5280...\n",
            "Iteration 177: fetching answer for questions from index 5280 to 5310...\n",
            "Iteration 178: fetching answer for questions from index 5310 to 5340...\n",
            "Iteration 179: fetching answer for questions from index 5340 to 5370...\n",
            "Iteration 180: fetching answer for questions from index 5370 to 5400...\n",
            "Iteration 181: fetching answer for questions from index 5400 to 5430...\n",
            "Iteration 182: fetching answer for questions from index 5430 to 5460...\n",
            "Iteration 183: fetching answer for questions from index 5460 to 5490...\n",
            "Iteration 184: fetching answer for questions from index 5490 to 5520...\n",
            "Iteration 185: fetching answer for questions from index 5520 to 5550...\n",
            "Iteration 186: fetching answer for questions from index 5550 to 5580...\n",
            "Iteration 187: fetching answer for questions from index 5580 to 5610...\n",
            "Iteration 188: fetching answer for questions from index 5610 to 5640...\n",
            "Iteration 189: fetching answer for questions from index 5640 to 5670...\n",
            "Iteration 190: fetching answer for questions from index 5670 to 5700...\n",
            "Iteration 191: fetching answer for questions from index 5700 to 5730...\n",
            "Iteration 192: fetching answer for questions from index 5730 to 5760...\n",
            "Iteration 193: fetching answer for questions from index 5760 to 5790...\n",
            "Iteration 194: fetching answer for questions from index 5790 to 5820...\n",
            "Iteration 195: fetching answer for questions from index 5820 to 5850...\n",
            "Iteration 196: fetching answer for questions from index 5850 to 5880...\n",
            "Iteration 197: fetching answer for questions from index 5880 to 5910...\n",
            "Iteration 198: fetching answer for questions from index 5910 to 5940...\n",
            "Iteration 199: fetching answer for questions from index 5940 to 5970...\n",
            "Iteration 200: fetching answer for questions from index 5970 to 6000...\n",
            "Iteration 201: fetching answer for questions from index 6000 to 6030...\n",
            "Iteration 202: fetching answer for questions from index 6030 to 6060...\n",
            "Iteration 203: fetching answer for questions from index 6060 to 6090...\n",
            "Iteration 204: fetching answer for questions from index 6090 to 6120...\n",
            "Iteration 205: fetching answer for questions from index 6120 to 6150...\n",
            "Iteration 206: fetching answer for questions from index 6150 to 6180...\n",
            "Iteration 207: fetching answer for questions from index 6180 to 6210...\n",
            "Iteration 208: fetching answer for questions from index 6210 to 6240...\n",
            "Iteration 209: fetching answer for questions from index 6240 to 6270...\n",
            "Iteration 210: fetching answer for questions from index 6270 to 6300...\n",
            "Iteration 211: fetching answer for questions from index 6300 to 6330...\n",
            "Iteration 212: fetching answer for questions from index 6330 to 6360...\n",
            "Iteration 213: fetching answer for questions from index 6360 to 6390...\n",
            "Iteration 214: fetching answer for questions from index 6390 to 6420...\n",
            "Iteration 215: fetching answer for questions from index 6420 to 6450...\n",
            "Iteration 216: fetching answer for questions from index 6450 to 6480...\n",
            "Iteration 217: fetching answer for questions from index 6480 to 6510...\n",
            "Iteration 218: fetching answer for questions from index 6510 to 6540...\n",
            "Iteration 219: fetching answer for questions from index 6540 to 6570...\n",
            "Iteration 220: fetching answer for questions from index 6570 to 6600...\n",
            "Iteration 221: fetching answer for questions from index 6600 to 6630...\n",
            "Iteration 222: fetching answer for questions from index 6630 to 6660...\n",
            "Iteration 223: fetching answer for questions from index 6660 to 6690...\n",
            "Iteration 224: fetching answer for questions from index 6690 to 6720...\n",
            "Iteration 225: fetching answer for questions from index 6720 to 6750...\n",
            "Iteration 226: fetching answer for questions from index 6750 to 6780...\n",
            "Iteration 227: fetching answer for questions from index 6780 to 6810...\n",
            "Iteration 228: fetching answer for questions from index 6810 to 6840...\n",
            "Iteration 229: fetching answer for questions from index 6840 to 6870...\n",
            "Iteration 230: fetching answer for questions from index 6870 to 6900...\n",
            "Iteration 231: fetching answer for questions from index 6900 to 6930...\n",
            "Iteration 232: fetching answer for questions from index 6930 to 6960...\n",
            "Iteration 233: fetching answer for questions from index 6960 to 6990...\n",
            "Iteration 234: fetching answer for questions from index 6990 to 7020...\n",
            "Iteration 235: fetching answer for questions from index 7020 to 7050...\n",
            "Iteration 236: fetching answer for questions from index 7050 to 7080...\n",
            "Iteration 237: fetching answer for questions from index 7080 to 7110...\n",
            "Iteration 238: fetching answer for questions from index 7110 to 7140...\n",
            "Iteration 239: fetching answer for questions from index 7140 to 7170...\n",
            "Iteration 240: fetching answer for questions from index 7170 to 7200...\n",
            "Iteration 241: fetching answer for questions from index 7200 to 7230...\n",
            "Iteration 242: fetching answer for questions from index 7230 to 7260...\n",
            "Iteration 243: fetching answer for questions from index 7260 to 7290...\n",
            "Iteration 244: fetching answer for questions from index 7290 to 7320...\n",
            "Iteration 245: fetching answer for questions from index 7320 to 7350...\n",
            "Iteration 246: fetching answer for questions from index 7350 to 7380...\n",
            "Iteration 247: fetching answer for questions from index 7380 to 7410...\n",
            "Iteration 248: fetching answer for questions from index 7410 to 7440...\n",
            "Iteration 249: fetching answer for questions from index 7440 to 7470...\n",
            "Iteration 250: fetching answer for questions from index 7470 to 7500...\n",
            "Iteration 251: fetching answer for questions from index 7500 to 7530...\n",
            "Iteration 252: fetching answer for questions from index 7530 to 7560...\n",
            "Iteration 253: fetching answer for questions from index 7560 to 7590...\n",
            "Iteration 254: fetching answer for questions from index 7590 to 7620...\n",
            "Iteration 255: fetching answer for questions from index 7620 to 7650...\n",
            "Iteration 256: fetching answer for questions from index 7650 to 7680...\n",
            "Iteration 257: fetching answer for questions from index 7680 to 7710...\n",
            "Iteration 258: fetching answer for questions from index 7710 to 7740...\n",
            "Iteration 259: fetching answer for questions from index 7740 to 7770...\n",
            "Iteration 260: fetching answer for questions from index 7770 to 7800...\n",
            "Iteration 261: fetching answer for questions from index 7800 to 7830...\n",
            "Iteration 262: fetching answer for questions from index 7830 to 7860...\n",
            "Iteration 263: fetching answer for questions from index 7860 to 7890...\n",
            "Iteration 264: fetching answer for questions from index 7890 to 7920...\n",
            "Iteration 265: fetching answer for questions from index 7920 to 7950...\n",
            "Iteration 266: fetching answer for questions from index 7950 to 7980...\n",
            "Iteration 267: fetching answer for questions from index 7980 to 8010...\n",
            "Iteration 268: fetching answer for questions from index 8010 to 8040...\n",
            "Iteration 269: fetching answer for questions from index 8040 to 8070...\n",
            "Iteration 270: fetching answer for questions from index 8070 to 8100...\n",
            "Iteration 271: fetching answer for questions from index 8100 to 8130...\n",
            "Iteration 272: fetching answer for questions from index 8130 to 8160...\n",
            "Iteration 273: fetching answer for questions from index 8160 to 8190...\n",
            "Iteration 274: fetching answer for questions from index 8190 to 8220...\n",
            "Iteration 275: fetching answer for questions from index 8220 to 8250...\n",
            "Iteration 276: fetching answer for questions from index 8250 to 8280...\n",
            "Iteration 277: fetching answer for questions from index 8280 to 8310...\n",
            "Iteration 278: fetching answer for questions from index 8310 to 8340...\n",
            "Iteration 279: fetching answer for questions from index 8340 to 8370...\n",
            "Iteration 280: fetching answer for questions from index 8370 to 8400...\n",
            "Iteration 281: fetching answer for questions from index 8400 to 8430...\n",
            "Iteration 282: fetching answer for questions from index 8430 to 8460...\n",
            "Iteration 283: fetching answer for questions from index 8460 to 8490...\n",
            "Iteration 284: fetching answer for questions from index 8490 to 8520...\n",
            "Iteration 285: fetching answer for questions from index 8520 to 8550...\n",
            "Iteration 286: fetching answer for questions from index 8550 to 8580...\n",
            "Iteration 287: fetching answer for questions from index 8580 to 8610...\n",
            "Iteration 288: fetching answer for questions from index 8610 to 8640...\n",
            "Iteration 289: fetching answer for questions from index 8640 to 8670...\n",
            "Iteration 290: fetching answer for questions from index 8670 to 8700...\n",
            "Iteration 291: fetching answer for questions from index 8700 to 8730...\n",
            "Iteration 292: fetching answer for questions from index 8730 to 8760...\n",
            "Iteration 293: fetching answer for questions from index 8760 to 8790...\n",
            "Iteration 294: fetching answer for questions from index 8790 to 8820...\n",
            "Iteration 295: fetching answer for questions from index 8820 to 8850...\n",
            "Iteration 296: fetching answer for questions from index 8850 to 8880...\n",
            "Iteration 297: fetching answer for questions from index 8880 to 8910...\n",
            "Iteration 298: fetching answer for questions from index 8910 to 8940...\n",
            "Iteration 299: fetching answer for questions from index 8940 to 8970...\n",
            "Iteration 300: fetching answer for questions from index 8970 to 9000...\n",
            "Iteration 301: fetching answer for questions from index 9000 to 9030...\n",
            "Iteration 302: fetching answer for questions from index 9030 to 9060...\n",
            "Iteration 303: fetching answer for questions from index 9060 to 9090...\n",
            "Iteration 304: fetching answer for questions from index 9090 to 9120...\n",
            "Iteration 305: fetching answer for questions from index 9120 to 9150...\n",
            "Iteration 306: fetching answer for questions from index 9150 to 9180...\n",
            "Iteration 307: fetching answer for questions from index 9180 to 9210...\n",
            "Iteration 308: fetching answer for questions from index 9210 to 9240...\n",
            "Iteration 309: fetching answer for questions from index 9240 to 9270...\n",
            "Iteration 310: fetching answer for questions from index 9270 to 9300...\n",
            "Iteration 311: fetching answer for questions from index 9300 to 9330...\n",
            "Iteration 312: fetching answer for questions from index 9330 to 9360...\n",
            "Iteration 313: fetching answer for questions from index 9360 to 9390...\n",
            "Iteration 314: fetching answer for questions from index 9390 to 9420...\n",
            "Iteration 315: fetching answer for questions from index 9420 to 9450...\n",
            "Iteration 316: fetching answer for questions from index 9450 to 9480...\n",
            "Iteration 317: fetching answer for questions from index 9480 to 9510...\n",
            "Iteration 318: fetching answer for questions from index 9510 to 9540...\n",
            "Iteration 319: fetching answer for questions from index 9540 to 9570...\n",
            "Iteration 320: fetching answer for questions from index 9570 to 9600...\n",
            "Iteration 321: fetching answer for questions from index 9600 to 9630...\n",
            "Iteration 322: fetching answer for questions from index 9630 to 9660...\n",
            "Iteration 323: fetching answer for questions from index 9660 to 9690...\n",
            "Iteration 324: fetching answer for questions from index 9690 to 9720...\n",
            "Iteration 325: fetching answer for questions from index 9720 to 9750...\n",
            "Iteration 326: fetching answer for questions from index 9750 to 9780...\n",
            "Iteration 327: fetching answer for questions from index 9780 to 9810...\n",
            "Iteration 328: fetching answer for questions from index 9810 to 9840...\n",
            "Iteration 329: fetching answer for questions from index 9840 to 9870...\n",
            "Iteration 330: fetching answer for questions from index 9870 to 9900...\n",
            "Iteration 331: fetching answer for questions from index 9900 to 9930...\n",
            "Iteration 332: fetching answer for questions from index 9930 to 9960...\n",
            "Iteration 333: fetching answer for questions from index 9960 to 9990...\n",
            "Iteration 334: fetching answer for questions from index 9990 to 10020...\n",
            "Iteration 335: fetching answer for questions from index 10020 to 10050...\n",
            "Iteration 336: fetching answer for questions from index 10050 to 10080...\n",
            "Iteration 337: fetching answer for questions from index 10080 to 10110...\n",
            "Iteration 338: fetching answer for questions from index 10110 to 10140...\n",
            "Iteration 339: fetching answer for questions from index 10140 to 10170...\n",
            "Iteration 340: fetching answer for questions from index 10170 to 10200...\n",
            "Iteration 341: fetching answer for questions from index 10200 to 10230...\n",
            "Iteration 342: fetching answer for questions from index 10230 to 10260...\n",
            "Iteration 343: fetching answer for questions from index 10260 to 10290...\n",
            "Iteration 344: fetching answer for questions from index 10290 to 10320...\n",
            "Iteration 345: fetching answer for questions from index 10320 to 10350...\n",
            "Iteration 346: fetching answer for questions from index 10350 to 10380...\n",
            "Iteration 347: fetching answer for questions from index 10380 to 10410...\n",
            "Iteration 348: fetching answer for questions from index 10410 to 10440...\n",
            "Iteration 349: fetching answer for questions from index 10440 to 10470...\n",
            "Iteration 350: fetching answer for questions from index 10470 to 10500...\n",
            "Iteration 351: fetching answer for questions from index 10500 to 10530...\n",
            "Iteration 352: fetching answer for questions from index 10530 to 10560...\n",
            "Iteration 353: fetching answer for questions from index 10560 to 10590...\n",
            "Iteration 354: fetching answer for questions from index 10590 to 10620...\n",
            "Iteration 355: fetching answer for questions from index 10620 to 10650...\n",
            "Iteration 356: fetching answer for questions from index 10650 to 10680...\n",
            "Iteration 357: fetching answer for questions from index 10680 to 10710...\n",
            "Iteration 358: fetching answer for questions from index 10710 to 10740...\n",
            "Iteration 359: fetching answer for questions from index 10740 to 10770...\n",
            "Iteration 360: fetching answer for questions from index 10770 to 10800...\n",
            "Iteration 361: fetching answer for questions from index 10800 to 10830...\n",
            "Iteration 362: fetching answer for questions from index 10830 to 10860...\n",
            "Iteration 363: fetching answer for questions from index 10860 to 10890...\n",
            "Iteration 364: fetching answer for questions from index 10890 to 10920...\n",
            "Iteration 365: fetching answer for questions from index 10920 to 10950...\n",
            "Iteration 366: fetching answer for questions from index 10950 to 10980...\n",
            "Iteration 367: fetching answer for questions from index 10980 to 11010...\n",
            "Iteration 368: fetching answer for questions from index 11010 to 11040...\n",
            "Iteration 369: fetching answer for questions from index 11040 to 11070...\n",
            "Iteration 370: fetching answer for questions from index 11070 to 11100...\n",
            "Iteration 371: fetching answer for questions from index 11100 to 11130...\n",
            "Iteration 372: fetching answer for questions from index 11130 to 11160...\n",
            "Iteration 373: fetching answer for questions from index 11160 to 11190...\n",
            "Iteration 374: fetching answer for questions from index 11190 to 11220...\n",
            "Iteration 375: fetching answer for questions from index 11220 to 11250...\n",
            "Iteration 376: fetching answer for questions from index 11250 to 11280...\n",
            "Iteration 377: fetching answer for questions from index 11280 to 11310...\n",
            "Iteration 378: fetching answer for questions from index 11310 to 11340...\n",
            "Iteration 379: fetching answer for questions from index 11340 to 11370...\n",
            "Iteration 380: fetching answer for questions from index 11370 to 11400...\n",
            "Iteration 381: fetching answer for questions from index 11400 to 11430...\n",
            "Iteration 382: fetching answer for questions from index 11430 to 11460...\n",
            "Iteration 383: fetching answer for questions from index 11460 to 11490...\n",
            "Iteration 384: fetching answer for questions from index 11490 to 11520...\n",
            "Iteration 385: fetching answer for questions from index 11520 to 11550...\n",
            "Iteration 386: fetching answer for questions from index 11550 to 11580...\n",
            "Iteration 387: fetching answer for questions from index 11580 to 11610...\n",
            "Iteration 388: fetching answer for questions from index 11610 to 11640...\n",
            "Iteration 389: fetching answer for questions from index 11640 to 11670...\n",
            "Iteration 390: fetching answer for questions from index 11670 to 11700...\n",
            "Iteration 391: fetching answer for questions from index 11700 to 11730...\n",
            "Iteration 392: fetching answer for questions from index 11730 to 11760...\n",
            "Iteration 393: fetching answer for questions from index 11760 to 11790...\n",
            "Iteration 394: fetching answer for questions from index 11790 to 11820...\n",
            "Iteration 395: fetching answer for questions from index 11820 to 11850...\n",
            "Iteration 396: fetching answer for questions from index 11850 to 11880...\n",
            "Iteration 397: fetching answer for questions from index 11880 to 11910...\n",
            "Iteration 398: fetching answer for questions from index 11910 to 11940...\n",
            "Iteration 399: fetching answer for questions from index 11940 to 11970...\n",
            "Iteration 400: fetching answer for questions from index 11970 to 12000...\n",
            "Iteration 401: fetching answer for questions from index 12000 to 12030...\n",
            "Iteration 402: fetching answer for questions from index 12030 to 12060...\n",
            "Iteration 403: fetching answer for questions from index 12060 to 12090...\n",
            "Iteration 404: fetching answer for questions from index 12090 to 12120...\n",
            "Iteration 405: fetching answer for questions from index 12120 to 12150...\n",
            "Iteration 406: fetching answer for questions from index 12150 to 12180...\n",
            "Iteration 407: fetching answer for questions from index 12180 to 12210...\n",
            "Iteration 408: fetching answer for questions from index 12210 to 12240...\n",
            "Iteration 409: fetching answer for questions from index 12240 to 12270...\n",
            "Iteration 410: fetching answer for questions from index 12270 to 12300...\n",
            "Iteration 411: fetching answer for questions from index 12300 to 12330...\n",
            "Iteration 412: fetching answer for questions from index 12330 to 12360...\n",
            "Iteration 413: fetching answer for questions from index 12360 to 12390...\n",
            "Iteration 414: fetching answer for questions from index 12390 to 12420...\n",
            "Iteration 415: fetching answer for questions from index 12420 to 12450...\n",
            "Iteration 416: fetching answer for questions from index 12450 to 12480...\n",
            "Iteration 417: fetching answer for questions from index 12480 to 12510...\n",
            "Iteration 418: fetching answer for questions from index 12510 to 12540...\n",
            "Iteration 419: fetching answer for questions from index 12540 to 12570...\n",
            "Iteration 420: fetching answer for questions from index 12570 to 12600...\n",
            "Iteration 421: fetching answer for questions from index 12600 to 12630...\n",
            "Iteration 422: fetching answer for questions from index 12630 to 12660...\n",
            "Iteration 423: fetching answer for questions from index 12660 to 12690...\n",
            "Iteration 424: fetching answer for questions from index 12690 to 12720...\n",
            "Iteration 425: fetching answer for questions from index 12720 to 12750...\n",
            "Iteration 426: fetching answer for questions from index 12750 to 12780...\n",
            "Iteration 427: fetching answer for questions from index 12780 to 12810...\n",
            "Iteration 428: fetching answer for questions from index 12810 to 12840...\n",
            "Iteration 429: fetching answer for questions from index 12840 to 12870...\n",
            "Iteration 430: fetching answer for questions from index 12870 to 12900...\n",
            "Iteration 431: fetching answer for questions from index 12900 to 12930...\n",
            "Iteration 432: fetching answer for questions from index 12930 to 12960...\n",
            "Iteration 433: fetching answer for questions from index 12960 to 12990...\n",
            "Iteration 434: fetching answer for questions from index 12990 to 13020...\n",
            "Iteration 435: fetching answer for questions from index 13020 to 13050...\n",
            "Iteration 436: fetching answer for questions from index 13050 to 13080...\n",
            "Iteration 437: fetching answer for questions from index 13080 to 13110...\n",
            "Iteration 438: fetching answer for questions from index 13110 to 13140...\n",
            "Iteration 439: fetching answer for questions from index 13140 to 13170...\n",
            "Iteration 440: fetching answer for questions from index 13170 to 13200...\n",
            "Iteration 441: fetching answer for questions from index 13200 to 13230...\n",
            "Iteration 442: fetching answer for questions from index 13230 to 13260...\n",
            "Iteration 443: fetching answer for questions from index 13260 to 13290...\n",
            "Iteration 444: fetching answer for questions from index 13290 to 13320...\n",
            "Iteration 445: fetching answer for questions from index 13320 to 13350...\n",
            "Iteration 446: fetching answer for questions from index 13350 to 13380...\n",
            "Iteration 447: fetching answer for questions from index 13380 to 13410...\n",
            "Iteration 448: fetching answer for questions from index 13410 to 13440...\n",
            "Iteration 449: fetching answer for questions from index 13440 to 13470...\n",
            "Iteration 450: fetching answer for questions from index 13470 to 13500...\n",
            "Iteration 451: fetching answer for questions from index 13500 to 13530...\n",
            "Iteration 452: fetching answer for questions from index 13530 to 13560...\n",
            "Iteration 453: fetching answer for questions from index 13560 to 13590...\n",
            "Iteration 454: fetching answer for questions from index 13590 to 13620...\n",
            "Iteration 455: fetching answer for questions from index 13620 to 13650...\n",
            "Iteration 456: fetching answer for questions from index 13650 to 13680...\n",
            "Iteration 457: fetching answer for questions from index 13680 to 13710...\n",
            "Iteration 458: fetching answer for questions from index 13710 to 13740...\n",
            "Iteration 459: fetching answer for questions from index 13740 to 13770...\n",
            "Iteration 460: fetching answer for questions from index 13770 to 13800...\n",
            "Iteration 461: fetching answer for questions from index 13800 to 13830...\n",
            "Iteration 462: fetching answer for questions from index 13830 to 13860...\n",
            "Iteration 463: fetching answer for questions from index 13860 to 13890...\n",
            "Iteration 464: fetching answer for questions from index 13890 to 13920...\n",
            "Iteration 465: fetching answer for questions from index 13920 to 13950...\n",
            "Iteration 466: fetching answer for questions from index 13950 to 13980...\n",
            "Iteration 467: fetching answer for questions from index 13980 to 14010...\n",
            "Iteration 468: fetching answer for questions from index 14010 to 14040...\n",
            "Iteration 469: fetching answer for questions from index 14040 to 14070...\n",
            "Iteration 470: fetching answer for questions from index 14070 to 14100...\n",
            "Iteration 471: fetching answer for questions from index 14100 to 14130...\n",
            "Iteration 472: fetching answer for questions from index 14130 to 14160...\n",
            "Iteration 473: fetching answer for questions from index 14160 to 14190...\n",
            "Iteration 474: fetching answer for questions from index 14190 to 14220...\n",
            "Iteration 475: fetching answer for questions from index 14220 to 14250...\n",
            "Iteration 476: fetching answer for questions from index 14250 to 14280...\n",
            "Iteration 477: fetching answer for questions from index 14280 to 14310...\n",
            "Iteration 478: fetching answer for questions from index 14310 to 14340...\n",
            "Iteration 479: fetching answer for questions from index 14340 to 14370...\n",
            "Iteration 480: fetching answer for questions from index 14370 to 14400...\n",
            "Iteration 481: fetching answer for questions from index 14400 to 14430...\n",
            "Iteration 482: fetching answer for questions from index 14430 to 14460...\n",
            "Iteration 483: fetching answer for questions from index 14460 to 14490...\n",
            "Iteration 484: fetching answer for questions from index 14490 to 14520...\n",
            "Iteration 485: fetching answer for questions from index 14520 to 14550...\n",
            "Iteration 486: fetching answer for questions from index 14550 to 14580...\n",
            "Iteration 487: fetching answer for questions from index 14580 to 14610...\n",
            "Iteration 488: fetching answer for questions from index 14610 to 14640...\n",
            "Iteration 489: fetching answer for questions from index 14640 to 14670...\n",
            "Iteration 490: fetching answer for questions from index 14670 to 14700...\n",
            "Iteration 491: fetching answer for questions from index 14700 to 14730...\n",
            "Iteration 492: fetching answer for questions from index 14730 to 14760...\n",
            "Iteration 493: fetching answer for questions from index 14760 to 14790...\n",
            "Iteration 494: fetching answer for questions from index 14790 to 14820...\n",
            "Iteration 495: fetching answer for questions from index 14820 to 14850...\n",
            "Iteration 496: fetching answer for questions from index 14850 to 14880...\n",
            "Iteration 497: fetching answer for questions from index 14880 to 14910...\n",
            "Iteration 498: fetching answer for questions from index 14910 to 14940...\n",
            "Iteration 499: fetching answer for questions from index 14940 to 14970...\n",
            "Iteration 500: fetching answer for questions from index 14970 to 15000...\n",
            "Iteration 501: fetching answer for questions from index 15000 to 15030...\n",
            "Iteration 502: fetching answer for questions from index 15030 to 15060...\n",
            "Iteration 503: fetching answer for questions from index 15060 to 15090...\n",
            "Iteration 504: fetching answer for questions from index 15090 to 15120...\n",
            "Iteration 505: fetching answer for questions from index 15120 to 15150...\n",
            "Iteration 506: fetching answer for questions from index 15150 to 15180...\n",
            "Iteration 507: fetching answer for questions from index 15180 to 15210...\n",
            "Iteration 508: fetching answer for questions from index 15210 to 15240...\n",
            "Iteration 509: fetching answer for questions from index 15240 to 15270...\n",
            "Iteration 510: fetching answer for questions from index 15270 to 15300...\n",
            "Iteration 511: fetching answer for questions from index 15300 to 15330...\n",
            "Iteration 512: fetching answer for questions from index 15330 to 15360...\n",
            "Iteration 513: fetching answer for questions from index 15360 to 15390...\n",
            "Iteration 514: fetching answer for questions from index 15390 to 15420...\n",
            "Iteration 515: fetching answer for questions from index 15420 to 15450...\n",
            "Iteration 516: fetching answer for questions from index 15450 to 15480...\n",
            "Iteration 517: fetching answer for questions from index 15480 to 15510...\n",
            "Iteration 518: fetching answer for questions from index 15510 to 15540...\n",
            "Iteration 519: fetching answer for questions from index 15540 to 15570...\n",
            "Iteration 520: fetching answer for questions from index 15570 to 15600...\n",
            "Iteration 521: fetching answer for questions from index 15600 to 15630...\n",
            "Iteration 522: fetching answer for questions from index 15630 to 15660...\n",
            "Iteration 523: fetching answer for questions from index 15660 to 15690...\n",
            "Iteration 524: fetching answer for questions from index 15690 to 15720...\n",
            "Iteration 525: fetching answer for questions from index 15720 to 15750...\n",
            "Iteration 526: fetching answer for questions from index 15750 to 15780...\n",
            "Iteration 527: fetching answer for questions from index 15780 to 15810...\n",
            "Iteration 528: fetching answer for questions from index 15810 to 15840...\n",
            "Iteration 529: fetching answer for questions from index 15840 to 15870...\n",
            "Iteration 530: fetching answer for questions from index 15870 to 15900...\n",
            "Iteration 531: fetching answer for questions from index 15900 to 15930...\n",
            "Iteration 532: fetching answer for questions from index 15930 to 15960...\n",
            "Iteration 533: fetching answer for questions from index 15960 to 15990...\n",
            "Iteration 534: fetching answer for questions from index 15990 to 16020...\n",
            "Iteration 535: fetching answer for questions from index 16020 to 16050...\n",
            "Iteration 536: fetching answer for questions from index 16050 to 16080...\n",
            "Iteration 537: fetching answer for questions from index 16080 to 16110...\n",
            "Iteration 538: fetching answer for questions from index 16110 to 16140...\n",
            "Iteration 539: fetching answer for questions from index 16140 to 16170...\n",
            "Iteration 540: fetching answer for questions from index 16170 to 16200...\n",
            "Iteration 541: fetching answer for questions from index 16200 to 16230...\n",
            "Iteration 542: fetching answer for questions from index 16230 to 16260...\n",
            "Iteration 543: fetching answer for questions from index 16260 to 16290...\n",
            "Iteration 544: fetching answer for questions from index 16290 to 16320...\n",
            "Iteration 545: fetching answer for questions from index 16320 to 16350...\n",
            "Iteration 546: fetching answer for questions from index 16350 to 16380...\n",
            "Iteration 547: fetching answer for questions from index 16380 to 16410...\n",
            "Iteration 548: fetching answer for questions from index 16410 to 16440...\n",
            "Iteration 549: fetching answer for questions from index 16440 to 16470...\n",
            "Iteration 550: fetching answer for questions from index 16470 to 16500...\n",
            "Iteration 551: fetching answer for questions from index 16500 to 16530...\n",
            "Iteration 552: fetching answer for questions from index 16530 to 16560...\n",
            "Iteration 553: fetching answer for questions from index 16560 to 16590...\n",
            "Iteration 554: fetching answer for questions from index 16590 to 16620...\n",
            "Iteration 555: fetching answer for questions from index 16620 to 16650...\n",
            "Iteration 556: fetching answer for questions from index 16650 to 16680...\n",
            "Iteration 557: fetching answer for questions from index 16680 to 16710...\n",
            "Iteration 558: fetching answer for questions from index 16710 to 16740...\n",
            "Iteration 559: fetching answer for questions from index 16740 to 16770...\n",
            "Iteration 560: fetching answer for questions from index 16770 to 16800...\n",
            "Iteration 561: fetching answer for questions from index 16800 to 16830...\n",
            "Iteration 562: fetching answer for questions from index 16830 to 16860...\n",
            "Iteration 563: fetching answer for questions from index 16860 to 16890...\n",
            "Iteration 564: fetching answer for questions from index 16890 to 16920...\n",
            "Iteration 565: fetching answer for questions from index 16920 to 16950...\n",
            "Iteration 566: fetching answer for questions from index 16950 to 16980...\n",
            "Iteration 567: fetching answer for questions from index 16980 to 17010...\n",
            "Iteration 568: fetching answer for questions from index 17010 to 17040...\n",
            "Iteration 569: fetching answer for questions from index 17040 to 17070...\n",
            "Iteration 570: fetching answer for questions from index 17070 to 17100...\n",
            "Iteration 571: fetching answer for questions from index 17100 to 17130...\n",
            "Iteration 572: fetching answer for questions from index 17130 to 17160...\n",
            "Iteration 573: fetching answer for questions from index 17160 to 17190...\n",
            "Iteration 574: fetching answer for questions from index 17190 to 17220...\n",
            "Iteration 575: fetching answer for questions from index 17220 to 17250...\n",
            "Iteration 576: fetching answer for questions from index 17250 to 17280...\n",
            "Iteration 577: fetching answer for questions from index 17280 to 17310...\n",
            "Iteration 578: fetching answer for questions from index 17310 to 17340...\n",
            "Iteration 579: fetching answer for questions from index 17340 to 17370...\n",
            "Iteration 580: fetching answer for questions from index 17370 to 17400...\n",
            "Iteration 581: fetching answer for questions from index 17400 to 17430...\n",
            "Iteration 582: fetching answer for questions from index 17430 to 17460...\n",
            "Iteration 583: fetching answer for questions from index 17460 to 17490...\n",
            "Iteration 584: fetching answer for questions from index 17490 to 17520...\n",
            "Iteration 585: fetching answer for questions from index 17520 to 17550...\n",
            "Iteration 586: fetching answer for questions from index 17550 to 17580...\n",
            "Iteration 587: fetching answer for questions from index 17580 to 17610...\n",
            "Iteration 588: fetching answer for questions from index 17610 to 17640...\n",
            "Iteration 589: fetching answer for questions from index 17640 to 17670...\n",
            "Iteration 590: fetching answer for questions from index 17670 to 17700...\n",
            "Iteration 591: fetching answer for questions from index 17700 to 17730...\n",
            "Iteration 592: fetching answer for questions from index 17730 to 17760...\n",
            "Iteration 593: fetching answer for questions from index 17760 to 17790...\n",
            "Iteration 594: fetching answer for questions from index 17790 to 17820...\n",
            "Iteration 595: fetching answer for questions from index 17820 to 17850...\n",
            "Iteration 596: fetching answer for questions from index 17850 to 17880...\n",
            "Iteration 597: fetching answer for questions from index 17880 to 17910...\n",
            "Iteration 598: fetching answer for questions from index 17910 to 17940...\n",
            "Iteration 599: fetching answer for questions from index 17940 to 17970...\n",
            "Iteration 600: fetching answer for questions from index 17970 to 18000...\n",
            "Iteration 601: fetching answer for questions from index 18000 to 18030...\n",
            "Iteration 602: fetching answer for questions from index 18030 to 18060...\n",
            "Iteration 603: fetching answer for questions from index 18060 to 18090...\n",
            "Iteration 604: fetching answer for questions from index 18090 to 18120...\n",
            "Iteration 605: fetching answer for questions from index 18120 to 18150...\n",
            "Iteration 606: fetching answer for questions from index 18150 to 18180...\n",
            "Iteration 607: fetching answer for questions from index 18180 to 18210...\n",
            "Iteration 608: fetching answer for questions from index 18210 to 18240...\n",
            "Iteration 609: fetching answer for questions from index 18240 to 18270...\n",
            "Iteration 610: fetching answer for questions from index 18270 to 18300...\n",
            "Iteration 611: fetching answer for questions from index 18300 to 18330...\n",
            "Iteration 612: fetching answer for questions from index 18330 to 18360...\n",
            "Iteration 613: fetching answer for questions from index 18360 to 18390...\n",
            "Iteration 614: fetching answer for questions from index 18390 to 18420...\n",
            "Iteration 615: fetching answer for questions from index 18420 to 18450...\n",
            "Iteration 616: fetching answer for questions from index 18450 to 18480...\n",
            "Iteration 617: fetching answer for questions from index 18480 to 18510...\n",
            "Iteration 618: fetching answer for questions from index 18510 to 18540...\n",
            "Iteration 619: fetching answer for questions from index 18540 to 18570...\n",
            "Iteration 620: fetching answer for questions from index 18570 to 18600...\n",
            "Iteration 621: fetching answer for questions from index 18600 to 18630...\n",
            "Iteration 622: fetching answer for questions from index 18630 to 18660...\n",
            "Iteration 623: fetching answer for questions from index 18660 to 18690...\n",
            "Iteration 624: fetching answer for questions from index 18690 to 18720...\n",
            "Iteration 625: fetching answer for questions from index 18720 to 18750...\n",
            "Iteration 626: fetching answer for questions from index 18750 to 18780...\n",
            "Iteration 627: fetching answer for questions from index 18780 to 18810...\n",
            "Iteration 628: fetching answer for questions from index 18810 to 18840...\n",
            "Iteration 629: fetching answer for questions from index 18840 to 18870...\n",
            "Iteration 630: fetching answer for questions from index 18870 to 18900...\n",
            "Iteration 631: fetching answer for questions from index 18900 to 18930...\n",
            "Iteration 632: fetching answer for questions from index 18930 to 18960...\n",
            "Iteration 633: fetching answer for questions from index 18960 to 18990...\n",
            "Iteration 634: fetching answer for questions from index 18990 to 19020...\n",
            "Iteration 635: fetching answer for questions from index 19020 to 19050...\n",
            "Iteration 636: fetching answer for questions from index 19050 to 19080...\n",
            "Iteration 637: fetching answer for questions from index 19080 to 19110...\n",
            "Iteration 638: fetching answer for questions from index 19110 to 19140...\n",
            "Iteration 639: fetching answer for questions from index 19140 to 19170...\n",
            "Iteration 640: fetching answer for questions from index 19170 to 19200...\n",
            "Iteration 641: fetching answer for questions from index 19200 to 19230...\n",
            "Iteration 642: fetching answer for questions from index 19230 to 19260...\n",
            "Iteration 643: fetching answer for questions from index 19260 to 19290...\n",
            "Iteration 644: fetching answer for questions from index 19290 to 19320...\n",
            "Iteration 645: fetching answer for questions from index 19320 to 19350...\n",
            "Iteration 646: fetching answer for questions from index 19350 to 19380...\n",
            "Iteration 647: fetching answer for questions from index 19380 to 19410...\n",
            "Iteration 648: fetching answer for questions from index 19410 to 19440...\n",
            "Iteration 649: fetching answer for questions from index 19440 to 19470...\n",
            "Iteration 650: fetching answer for questions from index 19470 to 19500...\n",
            "Iteration 651: fetching answer for questions from index 19500 to 19530...\n",
            "Iteration 652: fetching answer for questions from index 19530 to 19560...\n",
            "Iteration 653: fetching answer for questions from index 19560 to 19590...\n",
            "Iteration 654: fetching answer for questions from index 19590 to 19620...\n",
            "Iteration 655: fetching answer for questions from index 19620 to 19650...\n",
            "Iteration 656: fetching answer for questions from index 19650 to 19680...\n",
            "Iteration 657: fetching answer for questions from index 19680 to 19710...\n",
            "Iteration 658: fetching answer for questions from index 19710 to 19740...\n",
            "Iteration 659: fetching answer for questions from index 19740 to 19770...\n",
            "Iteration 660: fetching answer for questions from index 19770 to 19800...\n",
            "Iteration 661: fetching answer for questions from index 19800 to 19830...\n",
            "Iteration 662: fetching answer for questions from index 19830 to 19860...\n",
            "Iteration 663: fetching answer for questions from index 19860 to 19890...\n",
            "Iteration 664: fetching answer for questions from index 19890 to 19920...\n",
            "Iteration 665: fetching answer for questions from index 19920 to 19950...\n",
            "Iteration 666: fetching answer for questions from index 19950 to 19980...\n",
            "Iteration 667: fetching answer for questions from index 19980 to 20010...\n",
            "Iteration 668: fetching answer for questions from index 20010 to 20040...\n",
            "Iteration 669: fetching answer for questions from index 20040 to 20070...\n",
            "Iteration 670: fetching answer for questions from index 20070 to 20100...\n",
            "Iteration 671: fetching answer for questions from index 20100 to 20130...\n",
            "Iteration 672: fetching answer for questions from index 20130 to 20160...\n",
            "Iteration 673: fetching answer for questions from index 20160 to 20190...\n",
            "Iteration 674: fetching answer for questions from index 20190 to 20220...\n",
            "Iteration 675: fetching answer for questions from index 20220 to 20250...\n",
            "Iteration 676: fetching answer for questions from index 20250 to 20280...\n",
            "Iteration 677: fetching answer for questions from index 20280 to 20310...\n",
            "Iteration 678: fetching answer for questions from index 20310 to 20340...\n",
            "Iteration 679: fetching answer for questions from index 20340 to 20370...\n",
            "Iteration 680: fetching answer for questions from index 20370 to 20400...\n",
            "Iteration 681: fetching answer for questions from index 20400 to 20430...\n",
            "Iteration 682: fetching answer for questions from index 20430 to 20460...\n",
            "Iteration 683: fetching answer for questions from index 20460 to 20490...\n",
            "Iteration 684: fetching answer for questions from index 20490 to 20520...\n",
            "Iteration 685: fetching answer for questions from index 20520 to 20550...\n",
            "Iteration 686: fetching answer for questions from index 20550 to 20580...\n",
            "Iteration 687: fetching answer for questions from index 20580 to 20610...\n",
            "Iteration 688: fetching answer for questions from index 20610 to 20640...\n",
            "Iteration 689: fetching answer for questions from index 20640 to 20670...\n",
            "Iteration 690: fetching answer for questions from index 20670 to 20700...\n",
            "Iteration 691: fetching answer for questions from index 20700 to 20730...\n",
            "Iteration 692: fetching answer for questions from index 20730 to 20760...\n",
            "Iteration 693: fetching answer for questions from index 20760 to 20790...\n",
            "Iteration 694: fetching answer for questions from index 20790 to 20820...\n",
            "Iteration 695: fetching answer for questions from index 20820 to 20850...\n",
            "Iteration 696: fetching answer for questions from index 20850 to 20880...\n",
            "Iteration 697: fetching answer for questions from index 20880 to 20910...\n",
            "Iteration 698: fetching answer for questions from index 20910 to 20940...\n",
            "Iteration 699: fetching answer for questions from index 20940 to 20970...\n",
            "Iteration 700: fetching answer for questions from index 20970 to 21000...\n",
            "Iteration 701: fetching answer for questions from index 21000 to 21030...\n",
            "Iteration 702: fetching answer for questions from index 21030 to 21060...\n",
            "Iteration 703: fetching answer for questions from index 21060 to 21090...\n",
            "Iteration 704: fetching answer for questions from index 21090 to 21120...\n",
            "Iteration 705: fetching answer for questions from index 21120 to 21150...\n",
            "Iteration 706: fetching answer for questions from index 21150 to 21180...\n",
            "Iteration 707: fetching answer for questions from index 21180 to 21210...\n",
            "Iteration 708: fetching answer for questions from index 21210 to 21240...\n",
            "Iteration 709: fetching answer for questions from index 21240 to 21270...\n",
            "Iteration 710: fetching answer for questions from index 21270 to 21300...\n",
            "Iteration 711: fetching answer for questions from index 21300 to 21330...\n",
            "Iteration 712: fetching answer for questions from index 21330 to 21360...\n",
            "Iteration 713: fetching answer for questions from index 21360 to 21390...\n",
            "Iteration 714: fetching answer for questions from index 21390 to 21420...\n",
            "Iteration 715: fetching answer for questions from index 21420 to 21450...\n",
            "Iteration 716: fetching answer for questions from index 21450 to 21480...\n",
            "Iteration 717: fetching answer for questions from index 21480 to 21510...\n",
            "Iteration 718: fetching answer for questions from index 21510 to 21540...\n",
            "Iteration 719: fetching answer for questions from index 21540 to 21570...\n",
            "Iteration 720: fetching answer for questions from index 21570 to 21600...\n",
            "Iteration 721: fetching answer for questions from index 21600 to 21630...\n",
            "Iteration 722: fetching answer for questions from index 21630 to 21660...\n",
            "Iteration 723: fetching answer for questions from index 21660 to 21690...\n",
            "Iteration 724: fetching answer for questions from index 21690 to 21720...\n",
            "Iteration 725: fetching answer for questions from index 21720 to 21750...\n",
            "Iteration 726: fetching answer for questions from index 21750 to 21780...\n",
            "Iteration 727: fetching answer for questions from index 21780 to 21810...\n",
            "Iteration 728: fetching answer for questions from index 21810 to 21840...\n",
            "Iteration 729: fetching answer for questions from index 21840 to 21870...\n",
            "Iteration 730: fetching answer for questions from index 21870 to 21900...\n",
            "Iteration 731: fetching answer for questions from index 21900 to 21930...\n",
            "Iteration 732: fetching answer for questions from index 21930 to 21960...\n",
            "Iteration 733: fetching answer for questions from index 21960 to 21990...\n",
            "Iteration 734: fetching answer for questions from index 21990 to 22020...\n",
            "Iteration 735: fetching answer for questions from index 22020 to 22050...\n",
            "Iteration 736: fetching answer for questions from index 22050 to 22080...\n",
            "Iteration 737: fetching answer for questions from index 22080 to 22110...\n",
            "Iteration 738: fetching answer for questions from index 22110 to 22140...\n",
            "Iteration 739: fetching answer for questions from index 22140 to 22170...\n",
            "Iteration 740: fetching answer for questions from index 22170 to 22200...\n",
            "Iteration 741: fetching answer for questions from index 22200 to 22230...\n",
            "Iteration 742: fetching answer for questions from index 22230 to 22260...\n",
            "Iteration 743: fetching answer for questions from index 22260 to 22290...\n",
            "Iteration 744: fetching answer for questions from index 22290 to 22320...\n",
            "Iteration 745: fetching answer for questions from index 22320 to 22350...\n",
            "Iteration 746: fetching answer for questions from index 22350 to 22380...\n",
            "Iteration 747: fetching answer for questions from index 22380 to 22410...\n",
            "Iteration 748: fetching answer for questions from index 22410 to 22440...\n",
            "Iteration 749: fetching answer for questions from index 22440 to 22470...\n",
            "Iteration 750: fetching answer for questions from index 22470 to 22500...\n",
            "Iteration 751: fetching answer for questions from index 22500 to 22530...\n",
            "Iteration 752: fetching answer for questions from index 22530 to 22560...\n",
            "Iteration 753: fetching answer for questions from index 22560 to 22590...\n",
            "Iteration 754: fetching answer for questions from index 22590 to 22620...\n",
            "Iteration 755: fetching answer for questions from index 22620 to 22650...\n",
            "Iteration 756: fetching answer for questions from index 22650 to 22680...\n",
            "Iteration 757: fetching answer for questions from index 22680 to 22710...\n",
            "Iteration 758: fetching answer for questions from index 22710 to 22740...\n",
            "Iteration 759: fetching answer for questions from index 22740 to 22770...\n",
            "Iteration 760: fetching answer for questions from index 22770 to 22800...\n",
            "Iteration 761: fetching answer for questions from index 22800 to 22830...\n",
            "Iteration 762: fetching answer for questions from index 22830 to 22860...\n",
            "Iteration 763: fetching answer for questions from index 22860 to 22890...\n",
            "Iteration 764: fetching answer for questions from index 22890 to 22920...\n",
            "Iteration 765: fetching answer for questions from index 22920 to 22950...\n",
            "Iteration 766: fetching answer for questions from index 22950 to 22980...\n",
            "Iteration 767: fetching answer for questions from index 22980 to 23010...\n",
            "Iteration 768: fetching answer for questions from index 23010 to 23040...\n",
            "Iteration 769: fetching answer for questions from index 23040 to 23070...\n",
            "Iteration 770: fetching answer for questions from index 23070 to 23100...\n",
            "Iteration 771: fetching answer for questions from index 23100 to 23130...\n",
            "Iteration 772: fetching answer for questions from index 23130 to 23160...\n",
            "Iteration 773: fetching answer for questions from index 23160 to 23190...\n",
            "Iteration 774: fetching answer for questions from index 23190 to 23220...\n",
            "Iteration 775: fetching answer for questions from index 23220 to 23250...\n",
            "Iteration 776: fetching answer for questions from index 23250 to 23280...\n",
            "Iteration 777: fetching answer for questions from index 23280 to 23310...\n",
            "Iteration 778: fetching answer for questions from index 23310 to 23340...\n",
            "Iteration 779: fetching answer for questions from index 23340 to 23370...\n",
            "Iteration 780: fetching answer for questions from index 23370 to 23400...\n",
            "Iteration 781: fetching answer for questions from index 23400 to 23430...\n",
            "Iteration 782: fetching answer for questions from index 23430 to 23460...\n",
            "Iteration 783: fetching answer for questions from index 23460 to 23490...\n",
            "Iteration 784: fetching answer for questions from index 23490 to 23520...\n",
            "Iteration 785: fetching answer for questions from index 23520 to 23550...\n",
            "Iteration 786: fetching answer for questions from index 23550 to 23580...\n",
            "Iteration 787: fetching answer for questions from index 23580 to 23610...\n",
            "Iteration 788: fetching answer for questions from index 23610 to 23640...\n",
            "Iteration 789: fetching answer for questions from index 23640 to 23670...\n",
            "Iteration 790: fetching answer for questions from index 23670 to 23700...\n",
            "Iteration 791: fetching answer for questions from index 23700 to 23730...\n",
            "Iteration 792: fetching answer for questions from index 23730 to 23760...\n",
            "Iteration 793: fetching answer for questions from index 23760 to 23790...\n",
            "Iteration 794: fetching answer for questions from index 23790 to 23820...\n",
            "Iteration 795: fetching answer for questions from index 23820 to 23850...\n",
            "Iteration 796: fetching answer for questions from index 23850 to 23880...\n",
            "Iteration 797: fetching answer for questions from index 23880 to 23910...\n",
            "Iteration 798: fetching answer for questions from index 23910 to 23940...\n",
            "Iteration 799: fetching answer for questions from index 23940 to 23970...\n",
            "Iteration 800: fetching answer for questions from index 23970 to 24000...\n",
            "Iteration 801: fetching answer for questions from index 24000 to 24030...\n",
            "Iteration 802: fetching answer for questions from index 24030 to 24060...\n",
            "Iteration 803: fetching answer for questions from index 24060 to 24090...\n",
            "Iteration 804: fetching answer for questions from index 24090 to 24120...\n",
            "Iteration 805: fetching answer for questions from index 24120 to 24150...\n",
            "Iteration 806: fetching answer for questions from index 24150 to 24180...\n",
            "Iteration 807: fetching answer for questions from index 24180 to 24210...\n",
            "Iteration 808: fetching answer for questions from index 24210 to 24240...\n",
            "Iteration 809: fetching answer for questions from index 24240 to 24270...\n",
            "Iteration 810: fetching answer for questions from index 24270 to 24300...\n",
            "Iteration 811: fetching answer for questions from index 24300 to 24330...\n",
            "Iteration 812: fetching answer for questions from index 24330 to 24360...\n",
            "Iteration 813: fetching answer for questions from index 24360 to 24390...\n",
            "Iteration 814: fetching answer for questions from index 24390 to 24420...\n",
            "Iteration 815: fetching answer for questions from index 24420 to 24450...\n",
            "Iteration 816: fetching answer for questions from index 24450 to 24480...\n",
            "Iteration 817: fetching answer for questions from index 24480 to 24510...\n",
            "Iteration 818: fetching answer for questions from index 24510 to 24540...\n",
            "Iteration 819: fetching answer for questions from index 24540 to 24570...\n",
            "Iteration 820: fetching answer for questions from index 24570 to 24600...\n",
            "Iteration 821: fetching answer for questions from index 24600 to 24630...\n",
            "Iteration 822: fetching answer for questions from index 24630 to 24660...\n",
            "Iteration 823: fetching answer for questions from index 24660 to 24690...\n",
            "Iteration 824: fetching answer for questions from index 24690 to 24720...\n",
            "Iteration 825: fetching answer for questions from index 24720 to 24750...\n",
            "Iteration 826: fetching answer for questions from index 24750 to 24774...\n",
            "Finished retrieving answers for all questions in our dataset!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data = []\n",
        "answers = None\n",
        "iter = 1  # first iteration\n",
        "\n",
        "while (iter - 1) * 30 < len_ques:\n",
        "    try:\n",
        "        print(f\"Iteration {iter}: fetching answer for questions from index {(iter - 1) * 30} to {min(30 * iter, len_ques)}...\")\n",
        "\n",
        "        # Get ID(s) for the current batch, join them with ';'\n",
        "        questions = df_unique.iloc[(iter - 1) * 30:min(30 * iter, len_ques)]\n",
        "\n",
        "        # Join all ids together to get answers of at max 30 questions at a time\n",
        "        ids = ';'.join(list(questions['question_id'].astype(int).astype(str)))\n",
        "\n",
        "        # Fetch answers for the batch\n",
        "        answers = get_answers_for_question(ids)\n",
        "\n",
        "        # Check if API response is valid\n",
        "        if not answers or not isinstance(answers, list):\n",
        "            print(\"Error: Received an invalid response from API. Stopping execution.\")\n",
        "            break\n",
        "\n",
        "        answers_df = pd.DataFrame(answers)\n",
        "        answers_df[\"question_id\"] = answers_df[\"question_id\"].astype(str)\n",
        "\n",
        "        for i in range(len(questions)):\n",
        "            ans = answers_df[answers_df['question_id'] == str(int(questions.iloc[i]['question_id']))]\n",
        "\n",
        "            accepted_ans_1, accepted_ans_2 = None, None\n",
        "\n",
        "            for idx, a in ans.iterrows():\n",
        "                if accepted_ans_1 and accepted_ans_2:\n",
        "                    break\n",
        "                if not accepted_ans_1:\n",
        "                    accepted_ans_1 = a['body']\n",
        "                elif not accepted_ans_2:\n",
        "                    accepted_ans_2 = a['body']\n",
        "\n",
        "            data.append([\n",
        "                questions.iloc[i]['title'], questions.iloc[i]['body'], questions.iloc[i]['tags'],\n",
        "                accepted_ans_1, accepted_ans_2, questions.iloc[i]['creation_date'],\n",
        "                questions.iloc[i]['view_count'], questions.iloc[i]['score']\n",
        "            ])\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        # Sleep to avoid API rate limiting\n",
        "        time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}. Retrying after a short delay...\")\n",
        "        time.sleep(5)  # Wait before retrying\n",
        "    # break\n",
        "\n",
        "print(\"Finished retrieving answers for all questions in our dataset!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXFmFDW1srAk"
      },
      "source": [
        "My dataset retrieved from StackExchange APIs has 24774 rows with 8 columns   \n",
        "8 columns in the dataset include:\n",
        "\n",
        "1.  **`title`**: The title of the Stack Overflow question.\n",
        "2.  **`description`**: The body/content of the question, likely containing details, code snippets, and formatting (as indicated by the `<p>` tags).\n",
        "3.  **`tags`**: A list of tags associated with the question on Stack Overflow, useful for categorization (e.g., 'python', 'nlp', 'spacy', 'deep-learning', 'tensorflow').\n",
        "4.  **`accepted_answer_1`**: Contains the body text of the first answer retrieved for the question (likely the highest-voted answer based on typical API usage). It may be `None` if no answer was found or processed.\n",
        "5.  **`accepted_answer_2`**: Contains the body text of the second answer retrieved (likely the second highest-voted). Also may be `None`.\n",
        "6.  **`creation_date`**: The timestamp indicating when the question was originally posted (appears to be in Unix epoch format).\n",
        "7.  **`view_count`**: The number of times the question has been viewed on Stack Overflow.\n",
        "8.  **`score`**: The score (net upvotes/downvotes) of the question on Stack Overflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "l5AduksX0nC6",
        "outputId": "83dbe2f9-fcf2-4228-f563-31b5395aebf4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "      <th>accepted answer 1</th>\n",
              "      <th>accepted answer 2</th>\n",
              "      <th>creation date</th>\n",
              "      <th>view count</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Trouble getting importing gensim to work in colab</td>\n",
              "      <td>&lt;p&gt;I am trying to import gensim into colab.&lt;/p...</td>\n",
              "      <td>['numpy', 'nlp', 'dependencies', 'google-colab...</td>\n",
              "      <td>&lt;p&gt;You have to restart the session for the und...</td>\n",
              "      <td>None</td>\n",
              "      <td>1.742481e+09</td>\n",
              "      <td>89</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Store images instead of showing in a server</td>\n",
              "      <td>&lt;p&gt;I am running the code found on this [site][...</td>\n",
              "      <td>['python', 'nlp', 'large-language-model']</td>\n",
              "      <td>&lt;p&gt;I can't test it but ...&lt;/p&gt;\\n&lt;p&gt;I checked &lt;...</td>\n",
              "      <td>None</td>\n",
              "      <td>1.741705e+09</td>\n",
              "      <td>26</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Presidio with Langchain Experimental does not ...</td>\n",
              "      <td>&lt;p&gt;I am using presidio/langchain_experimental ...</td>\n",
              "      <td>['python', 'nlp', 'spacy', 'langchain', 'presi...</td>\n",
              "      <td>&lt;p&gt;Presidio allows configuring the Analyzer (a...</td>\n",
              "      <td>&lt;p&gt;After some test I was able to find the solu...</td>\n",
              "      <td>1.741041e+09</td>\n",
              "      <td>210</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OpenNLP POSTaggerME and ChunkerME synergy</td>\n",
              "      <td>&lt;p&gt;I'm trying to use the OpenNLP chunking API ...</td>\n",
              "      <td>['nlp', 'opennlp']</td>\n",
              "      <td>&lt;h2&gt;Q1&lt;/h2&gt;\\n&lt;p&gt;Yes, the chosen tag set (UD, P...</td>\n",
              "      <td>None</td>\n",
              "      <td>1.740240e+09</td>\n",
              "      <td>32</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>word/ sentence similarities</td>\n",
              "      <td>&lt;p&gt;I am trying to find if a given word/ set of...</td>\n",
              "      <td>['python', 'python-3.x', 'nlp']</td>\n",
              "      <td>&lt;p&gt;Yes, itâ€™s definitely doable using NLP! The ...</td>\n",
              "      <td>None</td>\n",
              "      <td>1.739980e+09</td>\n",
              "      <td>48</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24769</th>\n",
              "      <td>train test split is not splitting correctly</td>\n",
              "      <td>&lt;p&gt;I am still a beginner in AI and deep learni...</td>\n",
              "      <td>['python', 'numpy', 'tensorflow', 'deep-learni...</td>\n",
              "      <td>&lt;p&gt;The &lt;code&gt;110/110&lt;/code&gt; you are seeing in ...</td>\n",
              "      <td>None</td>\n",
              "      <td>1.610130e+09</td>\n",
              "      <td>562</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24770</th>\n",
              "      <td>MultinomialNB or GaussianNB or CategoricalNB w...</td>\n",
              "      <td>&lt;p&gt;Let I have a input feature &lt;code&gt;X = {X1, X...</td>\n",
              "      <td>['machine-learning', 'scikit-learn', 'deep-lea...</td>\n",
              "      <td>&lt;p&gt;Each algorithm of NB expects different type...</td>\n",
              "      <td>&lt;p&gt;Transform your categorial feature X2 using ...</td>\n",
              "      <td>1.610103e+09</td>\n",
              "      <td>5106</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24771</th>\n",
              "      <td>Custom small CNN has better accuracy than the ...</td>\n",
              "      <td>&lt;p&gt;I have a dataset of laser welding images of...</td>\n",
              "      <td>['python', 'deep-learning', 'pytorch', 'conv-n...</td>\n",
              "      <td>&lt;p&gt;&lt;strong&gt;Here is my theory :&lt;/strong&gt;&lt;/p&gt;\\n&lt;...</td>\n",
              "      <td>None</td>\n",
              "      <td>1.610103e+09</td>\n",
              "      <td>607</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24772</th>\n",
              "      <td>Creating a dataset of images for object detect...</td>\n",
              "      <td>&lt;p&gt;Even though I am quite familiar with the co...</td>\n",
              "      <td>['deep-learning', 'computer-vision', 'object-d...</td>\n",
              "      <td>&lt;p&gt;Yes, you will need to do that.&lt;/p&gt;\\n&lt;p&gt;At t...</td>\n",
              "      <td>None</td>\n",
              "      <td>1.610019e+09</td>\n",
              "      <td>462</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24773</th>\n",
              "      <td>Object detection in RGB-D images</td>\n",
              "      <td>&lt;p&gt;Can you please recommend papers/github or s...</td>\n",
              "      <td>['deep-learning', 'computer-vision']</td>\n",
              "      <td>&lt;p&gt;Here is a good primer to start your researc...</td>\n",
              "      <td>None</td>\n",
              "      <td>1.610015e+09</td>\n",
              "      <td>742</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24774 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  \\\n",
              "0      Trouble getting importing gensim to work in colab   \n",
              "1            Store images instead of showing in a server   \n",
              "2      Presidio with Langchain Experimental does not ...   \n",
              "3              OpenNLP POSTaggerME and ChunkerME synergy   \n",
              "4                            word/ sentence similarities   \n",
              "...                                                  ...   \n",
              "24769        train test split is not splitting correctly   \n",
              "24770  MultinomialNB or GaussianNB or CategoricalNB w...   \n",
              "24771  Custom small CNN has better accuracy than the ...   \n",
              "24772  Creating a dataset of images for object detect...   \n",
              "24773                   Object detection in RGB-D images   \n",
              "\n",
              "                                             description  \\\n",
              "0      <p>I am trying to import gensim into colab.</p...   \n",
              "1      <p>I am running the code found on this [site][...   \n",
              "2      <p>I am using presidio/langchain_experimental ...   \n",
              "3      <p>I'm trying to use the OpenNLP chunking API ...   \n",
              "4      <p>I am trying to find if a given word/ set of...   \n",
              "...                                                  ...   \n",
              "24769  <p>I am still a beginner in AI and deep learni...   \n",
              "24770  <p>Let I have a input feature <code>X = {X1, X...   \n",
              "24771  <p>I have a dataset of laser welding images of...   \n",
              "24772  <p>Even though I am quite familiar with the co...   \n",
              "24773  <p>Can you please recommend papers/github or s...   \n",
              "\n",
              "                                                    tags  \\\n",
              "0      ['numpy', 'nlp', 'dependencies', 'google-colab...   \n",
              "1              ['python', 'nlp', 'large-language-model']   \n",
              "2      ['python', 'nlp', 'spacy', 'langchain', 'presi...   \n",
              "3                                     ['nlp', 'opennlp']   \n",
              "4                        ['python', 'python-3.x', 'nlp']   \n",
              "...                                                  ...   \n",
              "24769  ['python', 'numpy', 'tensorflow', 'deep-learni...   \n",
              "24770  ['machine-learning', 'scikit-learn', 'deep-lea...   \n",
              "24771  ['python', 'deep-learning', 'pytorch', 'conv-n...   \n",
              "24772  ['deep-learning', 'computer-vision', 'object-d...   \n",
              "24773               ['deep-learning', 'computer-vision']   \n",
              "\n",
              "                                       accepted answer 1  \\\n",
              "0      <p>You have to restart the session for the und...   \n",
              "1      <p>I can't test it but ...</p>\\n<p>I checked <...   \n",
              "2      <p>Presidio allows configuring the Analyzer (a...   \n",
              "3      <h2>Q1</h2>\\n<p>Yes, the chosen tag set (UD, P...   \n",
              "4      <p>Yes, itâ€™s definitely doable using NLP! The ...   \n",
              "...                                                  ...   \n",
              "24769  <p>The <code>110/110</code> you are seeing in ...   \n",
              "24770  <p>Each algorithm of NB expects different type...   \n",
              "24771  <p><strong>Here is my theory :</strong></p>\\n<...   \n",
              "24772  <p>Yes, you will need to do that.</p>\\n<p>At t...   \n",
              "24773  <p>Here is a good primer to start your researc...   \n",
              "\n",
              "                                       accepted answer 2  creation date  \\\n",
              "0                                                   None   1.742481e+09   \n",
              "1                                                   None   1.741705e+09   \n",
              "2      <p>After some test I was able to find the solu...   1.741041e+09   \n",
              "3                                                   None   1.740240e+09   \n",
              "4                                                   None   1.739980e+09   \n",
              "...                                                  ...            ...   \n",
              "24769                                               None   1.610130e+09   \n",
              "24770  <p>Transform your categorial feature X2 using ...   1.610103e+09   \n",
              "24771                                               None   1.610103e+09   \n",
              "24772                                               None   1.610019e+09   \n",
              "24773                                               None   1.610015e+09   \n",
              "\n",
              "       view count  score  \n",
              "0              89    0.0  \n",
              "1              26    0.0  \n",
              "2             210    4.0  \n",
              "3              32    1.0  \n",
              "4              48    1.0  \n",
              "...           ...    ...  \n",
              "24769         562    0.0  \n",
              "24770        5106    2.0  \n",
              "24771         607    0.0  \n",
              "24772         462    1.0  \n",
              "24773         742    0.0  \n",
              "\n",
              "[24774 rows x 8 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ans = pd.DataFrame(data, columns = cols)\n",
        "df_ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_ans.to_excel(\"ques_ans.xlsx\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ans = pd.read_excel(\"ques_ans.xlsx\", engine=\"openpyxl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **2. Pre-processing**   <a class=\"anchor\" id=\"second-bullet\"></a>  \n",
        "[Table of Contents](#toc)   \n",
        "Perform some pre-processing on each column of the dataset. For example, remove the punctuation marks, special symbols, convert to lower case, remove screenshots from the posts and answers, tokenization etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### __2.1 [Fix Encoding Issues](#bullet21)__  \n",
        "### __2.2 [Pre-process data](#bullet22)__  (Remove HTML tags, remove code blocks, lowercasing, remove special characters & numbers, tokenization, remove Stopwords, handling technical terms (e.g., module names, libraries, etc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### __2.1 Fix Encoding Issues <a class=\"anchor\" id=\"bullet21\"></a>__  ([Go back to 2. Preprocessing](#second-bullet)) \n",
        "(During preliminary analysis, I discovered several encoding issues in the fetched dataset that require handling before proceeding with further processing. Special characters and diacritical marks appear as garbled text (like \"Ã¢â‚¬Å“\" instead of quotation marks or \"ÃƒÂ©\" instead of \"Ã©\"), indicating a character encoding mismatch between the source data and our processing environment. These inconsistencies could potentially affect text searching, sentiment analysis, and other natural language processing tasks. I'll need to implement appropriate encoding conversion functions to ensure all text is properly normalized to UTF-8 before conducting any meaningful analysis on the dataset.)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_27252\\4048267712.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  mask = df_ans.applymap(lambda x: isinstance(x, str) and any(ord(char) > 127 for char in x))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                   title  \\\n",
            "0      Trouble getting importing gensim to work in colab   \n",
            "3              OpenNLP POSTaggerME and ChunkerME synergy   \n",
            "4                            word/ sentence similarities   \n",
            "6                           Can&#39;t compile Marian NMT   \n",
            "16     Using an AWS service to execute a python scrip...   \n",
            "...                                                  ...   \n",
            "24745             Run tensorflow on linux by python3 pip   \n",
            "24747  Which parameters of Mask-RCNN control mask rec...   \n",
            "24758  Keras Data Augmentation with ImageDataGenerato...   \n",
            "24761  Crossentropyloss Pytorch: Targetsize does not ...   \n",
            "24770  MultinomialNB or GaussianNB or CategoricalNB w...   \n",
            "\n",
            "                                             description  \\\n",
            "0      <p>I am trying to import gensim into colab.</p...   \n",
            "3      <p>I'm trying to use the OpenNLP chunking API ...   \n",
            "4      <p>I am trying to find if a given word/ set of...   \n",
            "6      <p>I'm using endeavouros. I'm trying to compil...   \n",
            "16     <p>I have a simple python script that is given...   \n",
            "...                                                  ...   \n",
            "24745  <p>I have installed python and tensorflow on m...   \n",
            "24747  <p>I'm interested in fine-tuning a Mask-RCNN m...   \n",
            "24758  <p>I am currently learning how to perform data...   \n",
            "24761  <p>I want to use the Crossentropyloss of pytor...   \n",
            "24770  <p>Let I have a input feature <code>X = {X1, X...   \n",
            "\n",
            "                                                    tags  \\\n",
            "0      ['numpy', 'nlp', 'dependencies', 'google-colab...   \n",
            "3                                     ['nlp', 'opennlp']   \n",
            "4                        ['python', 'python-3.x', 'nlp']   \n",
            "6                         ['gcc', 'cmake', 'nlp', 'g++']   \n",
            "16     ['python', 'amazon-web-services', 'aws-lambda'...   \n",
            "...                                                  ...   \n",
            "24745  ['python-3.x', 'linux', 'tensorflow', 'deep-le...   \n",
            "24747  ['deep-learning', 'pytorch', 'image-segmentati...   \n",
            "24758  ['tensorflow', 'image-processing', 'keras', 'd...   \n",
            "24761  ['machine-learning', 'deep-learning', 'pytorch...   \n",
            "24770  ['machine-learning', 'scikit-learn', 'deep-lea...   \n",
            "\n",
            "                                       accepted answer 1  \\\n",
            "0      <p>You have to restart the session for the und...   \n",
            "3      <h2>Q1</h2>\\n<p>Yes, the chosen tag set (UD, P...   \n",
            "4      <p>Yes, itâ€™s definitely doable using NLP! The ...   \n",
            "6      <p>The diagnostic that your build is tripping,...   \n",
            "16     <p>In such cases, I would normally think of tw...   \n",
            "...                                                  ...   \n",
            "24745  <p>This problem may refer to the instruction s...   \n",
            "24747  <p>A couple of notes:</p>\\n<ul>\\n<li><p>6 epoc...   \n",
            "24758  <p>The fact that, <strong>imagedatagenerator d...   \n",
            "24761  <p>Without further information about your mode...   \n",
            "24770  <p>Each algorithm of NB expects different type...   \n",
            "\n",
            "                                       accepted answer 2  creation date  \\\n",
            "0                                                    NaN     1742481362   \n",
            "3                                                    NaN     1740240371   \n",
            "4                                                    NaN     1739980065   \n",
            "6                                                    NaN     1736057099   \n",
            "16     <p>For your use case, AWS Lambda is a suitable...     1731669216   \n",
            "...                                                  ...            ...   \n",
            "24745                                                NaN     1610536834   \n",
            "24747                                                NaN     1610500353   \n",
            "24758                                                NaN     1610344409   \n",
            "24761                                                NaN     1610277943   \n",
            "24770  <p>Transform your categorial feature X2 using ...     1610103359   \n",
            "\n",
            "       view count  score  \n",
            "0              89      0  \n",
            "3              32      1  \n",
            "4              48      1  \n",
            "6              66      4  \n",
            "16             54      1  \n",
            "...           ...    ...  \n",
            "24745         176      0  \n",
            "24747        2075      2  \n",
            "24758        2305      3  \n",
            "24761         915      0  \n",
            "24770        5106      2  \n",
            "\n",
            "[3643 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "def detect_encoding_issues(df_ans):\n",
        "    mask = df_ans.applymap(lambda x: isinstance(x, str) and any(ord(char) > 127 for char in x))\n",
        "    corrupted_rows = df_ans[mask.any(axis=1)]\n",
        "    return corrupted_rows\n",
        "corrupted_rows = detect_encoding_issues(df_ans)\n",
        "print(corrupted_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is how a row with encoding error looks like, it has some characters which are non-ASCII, so I will write a function to handle this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenNLP POSTaggerME and ChunkerME synergy\n",
            "<p>I'm trying to use the OpenNLP chunking API to chunk a portuguese sentence. So, first I tokenized a sentence using <a href=\"https://opennlp.apache.org/docs/2.5.3/manual/opennlp.html#tools.tokenizer.api\" rel=\"nofollow noreferrer\">TokenizerME</a>, then I tagged it with <a href=\"https://opennlp.apache.org/docs/2.5.3/manual/opennlp.html#tools.postagger.tagging.api\" rel=\"nofollow noreferrer\">POSTaggerME</a>. For both I used the ready-made models provided by the project <a href=\"https://opennlp.apache.org/models.html\" rel=\"nofollow noreferrer\">here</a>.</p>\n",
            "<p>For the sentence Ã¢â‚¬Å“Ivo viu a uvaÃ¢â‚¬Â, POSTaggerME returns the tags [PROPN, VERB, DET, NOUN]. The model seems to be using the <a href=\"https://universaldependencies.org/u/pos/\" rel=\"nofollow noreferrer\">UD POS Tags</a>.</p>\n",
            "<p>As there is no ready-made model for ChunkerME in portuguese, I <a href=\"https://opennlp.apache.org/docs/2.5.3/manual/opennlp.html#tools.corpora.arvores-deitadas\" rel=\"nofollow noreferrer\">followed the instructions</a> and did the training first using the ChunkerConverter tool (to convert from &quot;arvore deitada&quot; to CoNLL2000) and then generating the model with ChunkerTrainerME tool. Everything worked well. For the sentence above, the chunker produced correct tags ([B-NP, B-VP, B-NP, I-NP]).</p>\n",
            "<p>But, for more complex sentences, it hasn't produced such good results.</p>\n",
            "<p>I was trying to identify what I could improve in chunker training, and one of the things I noticed is that there is a difference between the types of tags. The portuguese corpus (<a href=\"https://www.linguateca.pt/Floresta/corpus.html#download\" rel=\"nofollow noreferrer\">Bosque 8.0</a>) seems to be using portuguese tags. For example, instead of <strong>PROPN</strong>, the corpus uses <strong>prop</strong> and instead of <strong>DET</strong>, it uses <strong>art</strong>.</p>\n",
            "<p>It seems to me that this could lead to problems, especially since one of the parameters the chunker receives is an array with UD tags, but it has been trained with another type of tag...</p>\n",
            "<p>But before writing code creating a routine to convert from a portuguese notation to UD (or Penn) I wanted to ask, if</p>\n",
            "<ol>\n",
            "<li>this does indeed have an impact,</li>\n",
            "<li>there is a tool that already does this translation and</li>\n",
            "<li>there are any other suggestions for improving the chunker precision/recall.</li>\n",
            "</ol>\n",
            "\n",
            "['nlp', 'opennlp']\n",
            "<h2>Q1</h2>\n",
            "<p>Yes, the chosen tag set (UD, Penn, custom) has an impact. Conversion is not possible in a bi-directional manner:</p>\n",
            "<ul>\n",
            "<li>Penn -&gt; UD should work well.</li>\n",
            "<li>UD -&gt; Penn is not a good idea as it a lossy conversion. UD tag set are less detailed when compared to the &quot;classic' Penn tag set.</li>\n",
            "</ul>\n",
            "<p>Using a custom, language specific tag-set can work, but it is a matter of &quot;mapping&quot; from/to UD correctly. This might work for some tag sets and languages, for others it might be too complicated / lossy.</p>\n",
            "<h2>Q2</h2>\n",
            "<p>No, there isn't. The OpenNLP project takes code donations for upcoming releases, if you want to provide such a mapping/translation for PT lang.</p>\n",
            "<h2>Q3</h2>\n",
            "<p>This needs details/discussion on the Apache OpenNLP user and/or dev <a href=\"https://opennlp.apache.org/mailing-lists.html\" rel=\"nofollow noreferrer\">mailing lists</a>. Alternatively, feel free to open a <a href=\"https://issues.apache.org/jira/projects/OPENNLP\" rel=\"nofollow noreferrer\">Jira issue</a> if you can drill the topic down to a clear idea or proposed code addition.</p>\n",
            "\n",
            "nan\n",
            "1740240371\n",
            "32\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "for i in corrupted_rows.iloc[1]:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### The function fix_encoding(text) below corrects misencoded text using ftfy, decodes HTML entities, and removes all non-ASCII characters. For example, calling fix_encoding(\"Ã¢â‚¬Ëœ< >Ã¢â‚¬\") will return \"< >\", stripping out problematic encoding artifacts while keeping standard ASCII characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"'< >\""
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def fix_encoding(text):\n",
        "    \"\"\"Fixes encoding issues, removes unwanted artifacts, and decodes HTML entities.\"\"\"\n",
        "    if isinstance(text, str):\n",
        "        text = fix_text(text)  # Fixes misencoded text\n",
        "        text = html.unescape(text)  # Decodes HTML entities (e.g., &lt; â†’ <)\n",
        "\n",
        "        text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)  # Remove all non-ASCII characters\n",
        "        return text.strip()\n",
        "\n",
        "    return text\n",
        "fix_encoding( \"Ã¢â‚¬Ëœ< >Ã¢â‚¬\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_27252\\3756384132.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df_fixencoding = df_ans.applymap(fix_encoding)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "      <th>accepted answer 1</th>\n",
              "      <th>accepted answer 2</th>\n",
              "      <th>creation date</th>\n",
              "      <th>view count</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Trouble getting importing gensim to work in colab</td>\n",
              "      <td>&lt;p&gt;I am trying to import gensim into colab.&lt;/p...</td>\n",
              "      <td>['numpy', 'nlp', 'dependencies', 'google-colab...</td>\n",
              "      <td>&lt;p&gt;You have to restart the session for the und...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1742481362</td>\n",
              "      <td>89</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Store images instead of showing in a server</td>\n",
              "      <td>&lt;p&gt;I am running the code found on this [site][...</td>\n",
              "      <td>['python', 'nlp', 'large-language-model']</td>\n",
              "      <td>&lt;p&gt;I can't test it but ...&lt;/p&gt;\\n&lt;p&gt;I checked &lt;...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1741704631</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Presidio with Langchain Experimental does not ...</td>\n",
              "      <td>&lt;p&gt;I am using presidio/langchain_experimental ...</td>\n",
              "      <td>['python', 'nlp', 'spacy', 'langchain', 'presi...</td>\n",
              "      <td>&lt;p&gt;Presidio allows configuring the Analyzer (a...</td>\n",
              "      <td>&lt;p&gt;After some test I was able to find the solu...</td>\n",
              "      <td>1741040827</td>\n",
              "      <td>210</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OpenNLP POSTaggerME and ChunkerME synergy</td>\n",
              "      <td>&lt;p&gt;I'm trying to use the OpenNLP chunking API ...</td>\n",
              "      <td>['nlp', 'opennlp']</td>\n",
              "      <td>&lt;h2&gt;Q1&lt;/h2&gt;\\n&lt;p&gt;Yes, the chosen tag set (UD, P...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1740240371</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>word/ sentence similarities</td>\n",
              "      <td>&lt;p&gt;I am trying to find if a given word/ set of...</td>\n",
              "      <td>['python', 'python-3.x', 'nlp']</td>\n",
              "      <td>&lt;p&gt;Yes, it's definitely doable using NLP! The ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1739980065</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  Trouble getting importing gensim to work in colab   \n",
              "1        Store images instead of showing in a server   \n",
              "2  Presidio with Langchain Experimental does not ...   \n",
              "3          OpenNLP POSTaggerME and ChunkerME synergy   \n",
              "4                        word/ sentence similarities   \n",
              "\n",
              "                                         description  \\\n",
              "0  <p>I am trying to import gensim into colab.</p...   \n",
              "1  <p>I am running the code found on this [site][...   \n",
              "2  <p>I am using presidio/langchain_experimental ...   \n",
              "3  <p>I'm trying to use the OpenNLP chunking API ...   \n",
              "4  <p>I am trying to find if a given word/ set of...   \n",
              "\n",
              "                                                tags  \\\n",
              "0  ['numpy', 'nlp', 'dependencies', 'google-colab...   \n",
              "1          ['python', 'nlp', 'large-language-model']   \n",
              "2  ['python', 'nlp', 'spacy', 'langchain', 'presi...   \n",
              "3                                 ['nlp', 'opennlp']   \n",
              "4                    ['python', 'python-3.x', 'nlp']   \n",
              "\n",
              "                                   accepted answer 1  \\\n",
              "0  <p>You have to restart the session for the und...   \n",
              "1  <p>I can't test it but ...</p>\\n<p>I checked <...   \n",
              "2  <p>Presidio allows configuring the Analyzer (a...   \n",
              "3  <h2>Q1</h2>\\n<p>Yes, the chosen tag set (UD, P...   \n",
              "4  <p>Yes, it's definitely doable using NLP! The ...   \n",
              "\n",
              "                                   accepted answer 2  creation date  \\\n",
              "0                                                NaN     1742481362   \n",
              "1                                                NaN     1741704631   \n",
              "2  <p>After some test I was able to find the solu...     1741040827   \n",
              "3                                                NaN     1740240371   \n",
              "4                                                NaN     1739980065   \n",
              "\n",
              "   view count  score  \n",
              "0          89      0  \n",
              "1          26      0  \n",
              "2         210      4  \n",
              "3          32      1  \n",
              "4          48      1  "
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_fixencoding = df_ans.applymap(fix_encoding)\n",
        "df_fixencoding.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_27252\\4048267712.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  mask = df_ans.applymap(lambda x: isinstance(x, str) and any(ord(char) > 127 for char in x))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No encoding issues detected in the dataset.\n"
          ]
        }
      ],
      "source": [
        "_ =detect_encoding_issues(df_fixencoding)\n",
        "if _.empty:\n",
        "    print(\"No encoding issues detected in the dataset.\")\n",
        "else:\n",
        "    print(\"Encoding issues found:\", _)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<p>I am trying to import gensim into colab.</p>\n",
            "<pre><code>!pip install gensim\n",
            "</code></pre>\n",
            "<p>I get the following error:</p>\n",
            "<pre><code>/usr/local/lib/python3.11/dist-packages/numpy/__init__.py in __getattr__(attr)\n",
            "    365                 raise AssertionError()\n",
            "    366         except AssertionError:\n",
            "--> 367             msg = (\"The current Numpy installation ({!r}) fails to \"\n",
            "    368                    \"pass simple sanity checks. This can be caused for example \"\n",
            "    369                    \"by incorrect BLAS library being linked in, or by mixing \"\n",
            "\n",
            "ModuleNotFoundError: No module named 'numpy.char'\n",
            "</code></pre>\n",
            "<p>my numpy version is 2.02. If I downgrade numpy to another version like say 1.26.4 I get a different error but always a numpy string related issue. Thanks</p>\n"
          ]
        }
      ],
      "source": [
        "print(df_fixencoding.iloc[0]['description'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "      <th>accepted answer 1</th>\n",
              "      <th>accepted answer 2</th>\n",
              "      <th>creation date</th>\n",
              "      <th>view count</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Trouble getting importing gensim to work in colab</td>\n",
              "      <td>&lt;p&gt;I am trying to import gensim into colab.&lt;/p...</td>\n",
              "      <td>['numpy', 'nlp', 'dependencies', 'google-colab...</td>\n",
              "      <td>&lt;p&gt;You have to restart the session for the und...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1742481362</td>\n",
              "      <td>89</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Store images instead of showing in a server</td>\n",
              "      <td>&lt;p&gt;I am running the code found on this [site][...</td>\n",
              "      <td>['python', 'nlp', 'large-language-model']</td>\n",
              "      <td>&lt;p&gt;I can't test it but ...&lt;/p&gt;\\n&lt;p&gt;I checked &lt;...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1741704631</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Presidio with Langchain Experimental does not ...</td>\n",
              "      <td>&lt;p&gt;I am using presidio/langchain_experimental ...</td>\n",
              "      <td>['python', 'nlp', 'spacy', 'langchain', 'presi...</td>\n",
              "      <td>&lt;p&gt;Presidio allows configuring the Analyzer (a...</td>\n",
              "      <td>&lt;p&gt;After some test I was able to find the solu...</td>\n",
              "      <td>1741040827</td>\n",
              "      <td>210</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OpenNLP POSTaggerME and ChunkerME synergy</td>\n",
              "      <td>&lt;p&gt;I'm trying to use the OpenNLP chunking API ...</td>\n",
              "      <td>['nlp', 'opennlp']</td>\n",
              "      <td>&lt;h2&gt;Q1&lt;/h2&gt;\\n&lt;p&gt;Yes, the chosen tag set (UD, P...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1740240371</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>word/ sentence similarities</td>\n",
              "      <td>&lt;p&gt;I am trying to find if a given word/ set of...</td>\n",
              "      <td>['python', 'python-3.x', 'nlp']</td>\n",
              "      <td>&lt;p&gt;Yes, it's definitely doable using NLP! The ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1739980065</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24769</th>\n",
              "      <td>train test split is not splitting correctly</td>\n",
              "      <td>&lt;p&gt;I am still a beginner in AI and deep learni...</td>\n",
              "      <td>['python', 'numpy', 'tensorflow', 'deep-learni...</td>\n",
              "      <td>&lt;p&gt;The &lt;code&gt;110/110&lt;/code&gt; you are seeing in ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1610130256</td>\n",
              "      <td>562</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24770</th>\n",
              "      <td>MultinomialNB or GaussianNB or CategoricalNB w...</td>\n",
              "      <td>&lt;p&gt;Let I have a input feature &lt;code&gt;X = {X1, X...</td>\n",
              "      <td>['machine-learning', 'scikit-learn', 'deep-lea...</td>\n",
              "      <td>&lt;p&gt;Each algorithm of NB expects different type...</td>\n",
              "      <td>&lt;p&gt;Transform your categorial feature X2 using ...</td>\n",
              "      <td>1610103359</td>\n",
              "      <td>5106</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24771</th>\n",
              "      <td>Custom small CNN has better accuracy than the ...</td>\n",
              "      <td>&lt;p&gt;I have a dataset of laser welding images of...</td>\n",
              "      <td>['python', 'deep-learning', 'pytorch', 'conv-n...</td>\n",
              "      <td>&lt;p&gt;&lt;strong&gt;Here is my theory :&lt;/strong&gt;&lt;/p&gt;\\n&lt;...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1610102996</td>\n",
              "      <td>607</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24772</th>\n",
              "      <td>Creating a dataset of images for object detect...</td>\n",
              "      <td>&lt;p&gt;Even though I am quite familiar with the co...</td>\n",
              "      <td>['deep-learning', 'computer-vision', 'object-d...</td>\n",
              "      <td>&lt;p&gt;Yes, you will need to do that.&lt;/p&gt;\\n&lt;p&gt;At t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1610018959</td>\n",
              "      <td>462</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24773</th>\n",
              "      <td>Object detection in RGB-D images</td>\n",
              "      <td>&lt;p&gt;Can you please recommend papers/github or s...</td>\n",
              "      <td>['deep-learning', 'computer-vision']</td>\n",
              "      <td>&lt;p&gt;Here is a good primer to start your researc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1610014801</td>\n",
              "      <td>742</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24774 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  \\\n",
              "0      Trouble getting importing gensim to work in colab   \n",
              "1            Store images instead of showing in a server   \n",
              "2      Presidio with Langchain Experimental does not ...   \n",
              "3              OpenNLP POSTaggerME and ChunkerME synergy   \n",
              "4                            word/ sentence similarities   \n",
              "...                                                  ...   \n",
              "24769        train test split is not splitting correctly   \n",
              "24770  MultinomialNB or GaussianNB or CategoricalNB w...   \n",
              "24771  Custom small CNN has better accuracy than the ...   \n",
              "24772  Creating a dataset of images for object detect...   \n",
              "24773                   Object detection in RGB-D images   \n",
              "\n",
              "                                             description  \\\n",
              "0      <p>I am trying to import gensim into colab.</p...   \n",
              "1      <p>I am running the code found on this [site][...   \n",
              "2      <p>I am using presidio/langchain_experimental ...   \n",
              "3      <p>I'm trying to use the OpenNLP chunking API ...   \n",
              "4      <p>I am trying to find if a given word/ set of...   \n",
              "...                                                  ...   \n",
              "24769  <p>I am still a beginner in AI and deep learni...   \n",
              "24770  <p>Let I have a input feature <code>X = {X1, X...   \n",
              "24771  <p>I have a dataset of laser welding images of...   \n",
              "24772  <p>Even though I am quite familiar with the co...   \n",
              "24773  <p>Can you please recommend papers/github or s...   \n",
              "\n",
              "                                                    tags  \\\n",
              "0      ['numpy', 'nlp', 'dependencies', 'google-colab...   \n",
              "1              ['python', 'nlp', 'large-language-model']   \n",
              "2      ['python', 'nlp', 'spacy', 'langchain', 'presi...   \n",
              "3                                     ['nlp', 'opennlp']   \n",
              "4                        ['python', 'python-3.x', 'nlp']   \n",
              "...                                                  ...   \n",
              "24769  ['python', 'numpy', 'tensorflow', 'deep-learni...   \n",
              "24770  ['machine-learning', 'scikit-learn', 'deep-lea...   \n",
              "24771  ['python', 'deep-learning', 'pytorch', 'conv-n...   \n",
              "24772  ['deep-learning', 'computer-vision', 'object-d...   \n",
              "24773               ['deep-learning', 'computer-vision']   \n",
              "\n",
              "                                       accepted answer 1  \\\n",
              "0      <p>You have to restart the session for the und...   \n",
              "1      <p>I can't test it but ...</p>\\n<p>I checked <...   \n",
              "2      <p>Presidio allows configuring the Analyzer (a...   \n",
              "3      <h2>Q1</h2>\\n<p>Yes, the chosen tag set (UD, P...   \n",
              "4      <p>Yes, it's definitely doable using NLP! The ...   \n",
              "...                                                  ...   \n",
              "24769  <p>The <code>110/110</code> you are seeing in ...   \n",
              "24770  <p>Each algorithm of NB expects different type...   \n",
              "24771  <p><strong>Here is my theory :</strong></p>\\n<...   \n",
              "24772  <p>Yes, you will need to do that.</p>\\n<p>At t...   \n",
              "24773  <p>Here is a good primer to start your researc...   \n",
              "\n",
              "                                       accepted answer 2  creation date  \\\n",
              "0                                                    NaN     1742481362   \n",
              "1                                                    NaN     1741704631   \n",
              "2      <p>After some test I was able to find the solu...     1741040827   \n",
              "3                                                    NaN     1740240371   \n",
              "4                                                    NaN     1739980065   \n",
              "...                                                  ...            ...   \n",
              "24769                                                NaN     1610130256   \n",
              "24770  <p>Transform your categorial feature X2 using ...     1610103359   \n",
              "24771                                                NaN     1610102996   \n",
              "24772                                                NaN     1610018959   \n",
              "24773                                                NaN     1610014801   \n",
              "\n",
              "       view count  score  \n",
              "0              89      0  \n",
              "1              26      0  \n",
              "2             210      4  \n",
              "3              32      1  \n",
              "4              48      1  \n",
              "...           ...    ...  \n",
              "24769         562      0  \n",
              "24770        5106      2  \n",
              "24771         607      0  \n",
              "24772         462      1  \n",
              "24773         742      0  \n",
              "\n",
              "[24774 rows x 8 columns]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_fixencoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### __NLTK Resource Downloads__\n",
        "* NLTK requires specific data resources (models, corpora) for its functions to work. This code ensures two essential resources are downloaded:\n",
        "    * **`'punkt'`**: Contains pre-trained models that `word_tokenize` uses to intelligently split text into sentences and words, handling punctuation correctly.\n",
        "    * **`'stopwords'`**: Contains lists of common stopwords for various languages, including English, used by `stopwords.words('english')`.\n",
        "* These downloads typically only need to run once per environment. If the resources are already present, NLTK usually skips the download.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i4xNOPvEElGA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### __2.2 Pre-process data <a class=\"anchor\" id=\"bullet22\"></a>__  ([Go back to 2. Preprocessing](#second-bullet))  \n",
        "The preprocessing steps I mentioned above are essential for improving the quality of the input text for my text categorization task. Let me explain why each of these steps is important:\n",
        "\n",
        "##### **Remove Image References**  \n",
        "In most text categorization tasks, the model is concerned with understanding the content of the text itself, such as the meaning, intent, or topic. Image references usually donâ€™t carry any useful semantic information that helps the model understand the text.\n",
        "\n",
        "\n",
        "##### **Remove Code Blocks**\n",
        "Code snippets or technical commands (e.g., `!pip install gensim`) typically donâ€™t provide useful information for most text categorization tasks, unless we r categorizing code errors or issues. Removing code blocks focuses the model on understanding the general problem or context rather than trying to analyze code, which may not be necessary for categorization.  \n",
        "\n",
        "\n",
        "##### **Remove HTML Tags**\n",
        "HTML tags (`<p>`, `<pre>`, `<code>`, etc.) are used to format text on a webpage but do not provide meaningful information for text analysis. If left in the text, they can create noise and confuse my model. Removing HTML tags ensures that only the actual content (like the error message or description) is passed to the model for analysis. \n",
        "\n",
        "##### **Lowercasing**  \n",
        "Text is often case-sensitive, but for most text categorization tasks, capitalization doesn't add meaning (e.g., \"Python\" and \"python\" should be considered the same word). Converting all text to lowercase ensures consistency and prevents the model from treating variations in capitalization as different terms.\n",
        "\n",
        "##### **Remove Special Characters & Numbers**\n",
        "Special characters (like `/`, `->`, `:`) and numbers often donâ€™t add value in general text classification. For instance, a version number like `2.02` might be irrelevant in categorizing the error type. Removing or filtering out these elements helps the model focus on the actual words and meanings. For example, the word \"numpy\" is more important for categorization than a version number.\n",
        "\n",
        "##### **Tokenization**  \n",
        "Tokenization breaks text into smaller pieces (usually words or phrases), making it easier for a machine learning model to analyze the structure of the text. It helps us to analyze word frequency, relationships, and other features.  \n",
        "\n",
        "##### **Remove Stopwords**\n",
        "Stopwords are common words (e.g., \"the\", \"is\", \"and\", \"in\") that don't carry significant meaning in most text categorization tasks. Keeping them in the data can reduce the effectiveness of the model, especially when working with large datasets. By removing stopwords, I can eliminate unnecessary noise and make the model focus on the more meaningful words in the text. This is particularly important for tasks like sentiment analysis or topic categorization, where stopwords don't contribute to the outcome.  \n",
        "\n",
        "##### **Handling Technical Terms (e.g., module names)**\n",
        "Terms related to specific technologies, such as \"numpy\", \"gensim\", or \"colab\", can be important in technical text categorization tasks. These terms are keywords or labels that can help the model identify specific types of content or errors.  \n",
        "\n",
        "##### **Reasons why data pre processing is important:**\n",
        "- **Consistency**: ensure uniformity in the data by lowercasing, removing punctuation, and handling variations in format.\n",
        "- **Noise Reduction**: by removing irrelevant content (HTML tags, code, stopwords), we can reduce the distractions for the model and focus on meaningful information.\n",
        "- **Feature Extraction**: Tokenization and handling special terms help extract relevant features from the text that can be used by my model to make accurate predictions.\n",
        "- **Improved Model Performance**: Properly preprocessed text is cleaner and more structured, helping my machine learning model to better understand the data and improve classification accuracy.\n",
        "\n",
        "In short, preprocessing is about making the text model-friendly by simplifying, cleaning, and standardizing it. This results in better input for the machine learning model, leading to improved accuracy and more meaningful results from my categorization task.\n",
        "  \n",
        "------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**`detect_and_remove_image_references(text)` Function:**\n",
        "\n",
        "```python\n",
        "def detect_and_remove_image_references(text):\n",
        "    # ... (function body) ...\n",
        "    return text\n",
        "```\n",
        "\n",
        "* **Purpose**: Specifically targets and removes text patterns that commonly refer to images or screenshots within the posts (e.g., \"see screenshot below\", \"[image]\"). This doesn't remove actual image *files*, just the textual references.\n",
        "* **Input Check**: Similar check for string type.\n",
        "* **Regex Removals**: Uses `re.sub` with specific patterns:\n",
        "    * `r'screenshot\\s+\\w+'`: Removes \"screenshot\" followed by whitespace and another word (e.g., \"screenshot below\", \"screenshot attached\").\n",
        "    * `r'image\\s+\\w+'`: Removes \"image\" followed by whitespace and another word (e.g., \"image link\", \"image here\").\n",
        "    * `r'\\[image\\]|\\[screenshot\\]'`: Removes literal \"[image]\" or \"[screenshot]\".\n",
        "    * `flags=re.IGNORECASE`: Makes the matching case-insensitive, so it catches \"Screenshot\", \"screenshot\", \"IMAGE\", etc.\n",
        "* **Return Value**: Returns the text string with these specific references removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_and_remove_image_references(text):\n",
        "\n",
        "    \"\"\"\n",
        "     Detect and remove image/screenshot references in text\n",
        "     \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "         return \"\"\n",
        "     # Remove patterns that likely refer to images or screenshots\n",
        "    text = re.sub(r'screenshot\\s+\\w+', '', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'image\\s+\\w+', '', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\[image\\]|\\[screenshot\\]', '', text, flags=re.IGNORECASE)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess text by:\n",
        "    1. Remove code blocks\n",
        "    2. Remove HTML tags\n",
        "    3. Convert to lowercase\n",
        "    4. Remove URLs\n",
        "    5. Remove punctuation and special characters\n",
        "    6. Remove numbers\n",
        "    7. Remove extra whitespace\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Remove inline code (if needed)\n",
        "    text = re.sub(r'`.*?`', '', text)  # Remove inline code\n",
        "\n",
        "    # Remove block code (example: <pre><code>...</code></pre>)\n",
        "    text = re.sub(r'<pre><code>.*?</code></pre>', '', text, flags=re.DOTALL)\n",
        "    \n",
        "    # Remove comments and doctype\n",
        "    text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)  # Remove HTML comments\n",
        "    text = re.sub(r'<!DOCTYPE.*?>', '', text)  # Remove doctype declarations\n",
        "\n",
        "    # Ensure proper encoding and handle special characters\n",
        "    text = text.encode('utf-8', 'ignore').decode('utf-8')\n",
        "\n",
        "    # Remove HTML tags\n",
        "\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
        "    \n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)\n",
        "    \n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_text(text):\n",
        "\n",
        "    \"\"\"\n",
        "    Tokenize text into individual words and remove stopwords\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str) or not text:\n",
        "        return []\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def preprocess_excel_file(df, target = 'ques_ans_processed.xlsx'):\n",
        "    \"\"\"\n",
        "    Read and preprocess an Excel file with questions and answers\n",
        "    \"\"\"\n",
        "    # Read the Excel file\n",
        "    # df = pd.read_excel(file_path)\n",
        "    # Display the original data structure\n",
        "    print(\"Original Data Structure:\")\n",
        "    print(df.info())\n",
        "    print(\"\\nSample of original data:\")\n",
        "    print(df.head())\n",
        "    # Make a copy of the dataframe for preprocessing\n",
        "    processed_df = df.copy()\n",
        "    # Preprocess each text column in the dataframe\n",
        "    text_columns = df.select_dtypes(include=['object']).columns\n",
        "    for column in text_columns:\n",
        "        # Apply image reference removal\n",
        "        processed_df[column] = df[column].apply(detect_and_remove_image_references)\n",
        "        # Apply text preprocessing\n",
        "        processed_df[column] = processed_df[column].apply(preprocess_text)\n",
        "        # Create new tokenized columns (used to store tokens for each column of each row)\n",
        "        processed_df[f'{column}_tokens'] = processed_df[column].apply(tokenize_text)\n",
        "        # Count tokens ( count #tokens of each column of each row )\n",
        "        processed_df[f'{column}_token_count'] = processed_df[f'{column}_tokens'].apply(len)\n",
        "\n",
        "\n",
        "    # Calculate descriptive statistics for token counts\n",
        "    print(\"\\nToken Count Statistics:\")\n",
        "    for column in text_columns:\n",
        "        token_col = f'{column}_token_count'\n",
        "        if token_col in processed_df.columns:\n",
        "            print(f\"\\n{column} Token Count:\")\n",
        "        print(processed_df[token_col].describe())\n",
        "\n",
        "    # Display sample of processed data\n",
        "    print(\"\\nSample of processed data:\")\n",
        "    print(processed_df.head())\n",
        "\n",
        "    # Save the processed dataframe to a new file\n",
        "    # output_file = file_path.replace('.xlsx', '_processed.xlsx')\n",
        "    processed_df.to_excel(target, index=False)\n",
        "    print(f\"\\nProcessed data saved to {target}\")\n",
        "\n",
        "\n",
        "    return processed_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "processed_data = preprocess_excel_file(df_fixencoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "      <th>accepted answer 1</th>\n",
              "      <th>accepted answer 2</th>\n",
              "      <th>creation date</th>\n",
              "      <th>view count</th>\n",
              "      <th>score</th>\n",
              "      <th>title_tokens</th>\n",
              "      <th>title_token_count</th>\n",
              "      <th>description_tokens</th>\n",
              "      <th>description_token_count</th>\n",
              "      <th>tags_tokens</th>\n",
              "      <th>tags_token_count</th>\n",
              "      <th>accepted answer 1_tokens</th>\n",
              "      <th>accepted answer 1_token_count</th>\n",
              "      <th>accepted answer 2_tokens</th>\n",
              "      <th>accepted answer 2_token_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>trouble getting importing gensim to work in colab</td>\n",
              "      <td>i am trying to import gensim into colab i get ...</td>\n",
              "      <td>numpy nlp dependencies googlecolaboratory gensim</td>\n",
              "      <td>you have to restart the session for the underl...</td>\n",
              "      <td></td>\n",
              "      <td>1742481362</td>\n",
              "      <td>89</td>\n",
              "      <td>0</td>\n",
              "      <td>[trouble, getting, importing, gensim, work, co...</td>\n",
              "      <td>6</td>\n",
              "      <td>[trying, import, gensim, colab, get, following...</td>\n",
              "      <td>24</td>\n",
              "      <td>[numpy, nlp, dependencies, googlecolaboratory,...</td>\n",
              "      <td>5</td>\n",
              "      <td>[restart, session, underlying, runtime, notice...</td>\n",
              "      <td>53</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>store images instead of showing in a server</td>\n",
              "      <td>i am running the code found on this site in my...</td>\n",
              "      <td>python nlp largelanguagemodel</td>\n",
              "      <td>i cant test it but i checked source code and i...</td>\n",
              "      <td></td>\n",
              "      <td>1741704631</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>[store, images, instead, showing, server]</td>\n",
              "      <td>5</td>\n",
              "      <td>[running, code, found, site, server, would, li...</td>\n",
              "      <td>28</td>\n",
              "      <td>[python, nlp, largelanguagemodel]</td>\n",
              "      <td>3</td>\n",
              "      <td>[cant, test, checked, source, code, uses, matp...</td>\n",
              "      <td>24</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>presidio with langchain experimental does not ...</td>\n",
              "      <td>i am using presidiolangchainexperimental to an...</td>\n",
              "      <td>python nlp spacy langchain presidio</td>\n",
              "      <td>presidio allows configuring the analyzer and n...</td>\n",
              "      <td>after some test i was able to find the solutio...</td>\n",
              "      <td>1741040827</td>\n",
              "      <td>210</td>\n",
              "      <td>4</td>\n",
              "      <td>[presidio, langchain, experimental, detect, po...</td>\n",
              "      <td>6</td>\n",
              "      <td>[using, presidiolangchainexperimental, anonymi...</td>\n",
              "      <td>66</td>\n",
              "      <td>[python, nlp, spacy, langchain, presidio]</td>\n",
              "      <td>5</td>\n",
              "      <td>[presidio, allows, configuring, analyzer, nlp,...</td>\n",
              "      <td>32</td>\n",
              "      <td>[test, able, find, solution, output, look, lik...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>opennlp postaggerme and chunkerme synergy</td>\n",
              "      <td>im trying to use the opennlp chunking api to c...</td>\n",
              "      <td>nlp opennlp</td>\n",
              "      <td>q yes the chosen tag set ud penn custom has an...</td>\n",
              "      <td></td>\n",
              "      <td>1740240371</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>[opennlp, postaggerme, chunkerme, synergy]</td>\n",
              "      <td>4</td>\n",
              "      <td>[im, trying, use, opennlp, chunking, api, chun...</td>\n",
              "      <td>141</td>\n",
              "      <td>[nlp, opennlp]</td>\n",
              "      <td>2</td>\n",
              "      <td>[q, yes, chosen, tag, set, ud, penn, custom, i...</td>\n",
              "      <td>90</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>word sentence similarities</td>\n",
              "      <td>i am trying to find if a given word set of wor...</td>\n",
              "      <td>python pythonx nlp</td>\n",
              "      <td>yes its definitely doable using nlp the key he...</td>\n",
              "      <td></td>\n",
              "      <td>1739980065</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>[word, sentence, similarities]</td>\n",
              "      <td>3</td>\n",
              "      <td>[trying, find, given, word, set, words, simila...</td>\n",
              "      <td>33</td>\n",
              "      <td>[python, pythonx, nlp]</td>\n",
              "      <td>3</td>\n",
              "      <td>[yes, definitely, doable, using, nlp, key, don...</td>\n",
              "      <td>72</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  trouble getting importing gensim to work in colab   \n",
              "1        store images instead of showing in a server   \n",
              "2  presidio with langchain experimental does not ...   \n",
              "3          opennlp postaggerme and chunkerme synergy   \n",
              "4                         word sentence similarities   \n",
              "\n",
              "                                         description  \\\n",
              "0  i am trying to import gensim into colab i get ...   \n",
              "1  i am running the code found on this site in my...   \n",
              "2  i am using presidiolangchainexperimental to an...   \n",
              "3  im trying to use the opennlp chunking api to c...   \n",
              "4  i am trying to find if a given word set of wor...   \n",
              "\n",
              "                                               tags  \\\n",
              "0  numpy nlp dependencies googlecolaboratory gensim   \n",
              "1                     python nlp largelanguagemodel   \n",
              "2               python nlp spacy langchain presidio   \n",
              "3                                       nlp opennlp   \n",
              "4                                python pythonx nlp   \n",
              "\n",
              "                                   accepted answer 1  \\\n",
              "0  you have to restart the session for the underl...   \n",
              "1  i cant test it but i checked source code and i...   \n",
              "2  presidio allows configuring the analyzer and n...   \n",
              "3  q yes the chosen tag set ud penn custom has an...   \n",
              "4  yes its definitely doable using nlp the key he...   \n",
              "\n",
              "                                   accepted answer 2  creation date  \\\n",
              "0                                                        1742481362   \n",
              "1                                                        1741704631   \n",
              "2  after some test i was able to find the solutio...     1741040827   \n",
              "3                                                        1740240371   \n",
              "4                                                        1739980065   \n",
              "\n",
              "   view count  score                                       title_tokens  \\\n",
              "0          89      0  [trouble, getting, importing, gensim, work, co...   \n",
              "1          26      0          [store, images, instead, showing, server]   \n",
              "2         210      4  [presidio, langchain, experimental, detect, po...   \n",
              "3          32      1         [opennlp, postaggerme, chunkerme, synergy]   \n",
              "4          48      1                     [word, sentence, similarities]   \n",
              "\n",
              "   title_token_count                                 description_tokens  \\\n",
              "0                  6  [trying, import, gensim, colab, get, following...   \n",
              "1                  5  [running, code, found, site, server, would, li...   \n",
              "2                  6  [using, presidiolangchainexperimental, anonymi...   \n",
              "3                  4  [im, trying, use, opennlp, chunking, api, chun...   \n",
              "4                  3  [trying, find, given, word, set, words, simila...   \n",
              "\n",
              "   description_token_count                                        tags_tokens  \\\n",
              "0                       24  [numpy, nlp, dependencies, googlecolaboratory,...   \n",
              "1                       28                  [python, nlp, largelanguagemodel]   \n",
              "2                       66          [python, nlp, spacy, langchain, presidio]   \n",
              "3                      141                                     [nlp, opennlp]   \n",
              "4                       33                             [python, pythonx, nlp]   \n",
              "\n",
              "   tags_token_count                           accepted answer 1_tokens  \\\n",
              "0                 5  [restart, session, underlying, runtime, notice...   \n",
              "1                 3  [cant, test, checked, source, code, uses, matp...   \n",
              "2                 5  [presidio, allows, configuring, analyzer, nlp,...   \n",
              "3                 2  [q, yes, chosen, tag, set, ud, penn, custom, i...   \n",
              "4                 3  [yes, definitely, doable, using, nlp, key, don...   \n",
              "\n",
              "   accepted answer 1_token_count  \\\n",
              "0                             53   \n",
              "1                             24   \n",
              "2                             32   \n",
              "3                             90   \n",
              "4                             72   \n",
              "\n",
              "                            accepted answer 2_tokens  \\\n",
              "0                                                 []   \n",
              "1                                                 []   \n",
              "2  [test, able, find, solution, output, look, lik...   \n",
              "3                                                 []   \n",
              "4                                                 []   \n",
              "\n",
              "   accepted answer 2_token_count  \n",
              "0                              0  \n",
              "1                              0  \n",
              "2                             49  \n",
              "3                              0  \n",
              "4                              0  "
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "title vocabulary size: 13204\n",
            "\n",
            "Top 20 most common words in title:\n",
            "text: 2787\n",
            "using: 2506\n",
            "python: 2467\n",
            "model: 2079\n",
            "nltk: 1390\n",
            "words: 1384\n",
            "lstm: 1305\n",
            "error: 1181\n",
            "spacy: 1177\n",
            "word: 1106\n",
            "file: 1061\n",
            "keras: 1056\n",
            "data: 1015\n",
            "speech: 969\n",
            "list: 930\n",
            "use: 920\n",
            "get: 894\n",
            "input: 800\n",
            "r: 721\n",
            "training: 703\n",
            "\n",
            "description vocabulary size: 79293\n",
            "\n",
            "Top 20 most common words in description:\n",
            "using: 13884\n",
            "model: 13347\n",
            "code: 13046\n",
            "like: 12352\n",
            "im: 11108\n",
            "text: 10920\n",
            "want: 9684\n",
            "use: 9099\n",
            "get: 9029\n",
            "data: 8968\n",
            "would: 8675\n",
            "error: 8614\n",
            "words: 8022\n",
            "file: 7610\n",
            "output: 7265\n",
            "trying: 6908\n",
            "following: 6794\n",
            "word: 6548\n",
            "one: 6397\n",
            "example: 6322\n",
            "\n",
            "tags vocabulary size: 3449\n",
            "\n",
            "Top 20 most common words in tags:\n",
            "python: 12169\n",
            "nlp: 8508\n",
            "deeplearning: 3406\n",
            "nltk: 3308\n",
            "tensorflow: 2736\n",
            "machinelearning: 2685\n",
            "keras: 2499\n",
            "lstm: 2147\n",
            "spacy: 1751\n",
            "pytorch: 1506\n",
            "pythonx: 1460\n",
            "texttospeech: 1449\n",
            "chatbot: 1374\n",
            "textprocessing: 1247\n",
            "r: 1235\n",
            "textmining: 1181\n",
            "gensim: 1109\n",
            "huggingfacetransformers: 1053\n",
            "java: 986\n",
            "pandas: 866\n",
            "\n",
            "accepted answer 1 vocabulary size: 76150\n",
            "\n",
            "Top 20 most common words in accepted answer 1:\n",
            "use: 12721\n",
            "model: 9472\n",
            "using: 7923\n",
            "data: 7513\n",
            "like: 7491\n",
            "one: 6793\n",
            "words: 6727\n",
            "code: 6675\n",
            "need: 6510\n",
            "would: 5866\n",
            "want: 5736\n",
            "output: 5583\n",
            "example: 5525\n",
            "text: 5417\n",
            "also: 5362\n",
            "word: 5346\n",
            "get: 5119\n",
            "see: 4668\n",
            "input: 4610\n",
            "first: 4541\n",
            "\n",
            "accepted answer 2 vocabulary size: 26926\n",
            "\n",
            "Top 20 most common words in accepted answer 2:\n",
            "use: 3266\n",
            "using: 2068\n",
            "words: 1765\n",
            "like: 1750\n",
            "model: 1706\n",
            "code: 1641\n",
            "one: 1639\n",
            "data: 1593\n",
            "word: 1519\n",
            "would: 1417\n",
            "need: 1414\n",
            "text: 1377\n",
            "also: 1358\n",
            "want: 1333\n",
            "get: 1238\n",
            "example: 1232\n",
            "output: 1181\n",
            "list: 1170\n",
            "first: 1078\n",
            "file: 1034\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Additional analysis: Vocabulary size per column\n",
        "text_columns = processed_data.select_dtypes(include=['object']).columns\n",
        "for column in text_columns:\n",
        "    if f'{column}_tokens' in processed_data.columns:\n",
        "    # Calculate vocabulary size (unique tokens)\n",
        "        all_tokens = [token for token_list in processed_data[f'{column}_tokens'] if isinstance(token_list, list) for token in token_list]\n",
        "        unique_tokens = set(all_tokens)\n",
        "        print(f\"\\n{column} vocabulary size: {len(unique_tokens)}\")\n",
        "\n",
        "\n",
        "\n",
        "# Show most common words (top 20)\n",
        "\n",
        "        from collections import Counter\n",
        "\n",
        "        word_counts = Counter(all_tokens)\n",
        "\n",
        "        print(f\"\\nTop 20 most common words in {column}:\")\n",
        "\n",
        "        for word, count in word_counts.most_common(20):\n",
        "\n",
        "            print(f\"{word}: {count}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### __Discussion about the most common words in my dataset above:__  \n",
        "\n",
        "## Common Patterns Across All Columns\n",
        "\n",
        "It is observable that there is a consistent appearance of certain words across all columns (title, description, tags, and answers):\n",
        "\n",
        "1. **Meta-language dominates the content**: Words like \"use\", \"using\", \"model\", \"code\", \"like\", \"want\", \"get\" appear frequently in all columns. These are procedural words that describe how to approach problems rather than the problems themselves.\n",
        "\n",
        "2. **Programming terminology**: Words like \"python\", \"file\", \"data\", \"input\", \"output\" reflect the programming-centric nature of the content.\n",
        "\n",
        "3. **NLP-specific terms**: Words like \"text\", \"words\", \"word\" appear consistently, which makes sense given this is an __NLP-focused dataset__.\n",
        "\n",
        "## Differences Between Columns\n",
        "\n",
        "Despite the similarities, there are important differences between the columns:\n",
        "\n",
        "### Tags\n",
        "- **Most informative component**: The tags contain the cleanest, most domain-specific terminology\n",
        "- **Technical frameworks dominate**: \"python\", \"nlp\", \"deeplearning\", \"nltk\", \"tensorflow\", \"keras\", \"spacy\", \"pytorch\"\n",
        "- **Task-specific terms**: \"texttospeech\", \"chatbot\", \"textprocessing\", \"textmining\"\n",
        "- **Lowest vocabulary size** (3,449), which makes sense as tags are controlled vocabulary\n",
        "\n",
        "### Titles\n",
        "- **More concise and focused** than descriptions\n",
        "- **Directly state the problem domain**: \"text\", \"python\", \"nltk\", \"words\", \"lstm\", \"spacy\"\n",
        "- **Error-related terminology**: \"error\" ranks high (8th), suggesting many questions are about troubleshooting\n",
        "- **Moderate vocabulary size** (13,204), reflecting the concise nature of titles\n",
        "\n",
        "### Descriptions\n",
        "- **Narrative language**: Contains more first-person expressions (\"im\", \"trying\", \"want\") \n",
        "- **Largest vocabulary size** (79,293), reflecting the free-form, detailed nature of problem descriptions\n",
        "- **Context-setting words**: \"following\", \"example\", \"trying\" used to set up the problem scenario\n",
        "\n",
        "### Accepted answers (1 and 2)\n",
        "- **Solution-oriented language**: \"use\", \"model\", \"using\", \"need\", \"code\", \"example\"\n",
        "- **First answers vs. second answers**: Second answers have significantly smaller vocabulary (26,926 vs. 76,150), suggesting they're often shorter or more focused\n",
        "\n",
        "## Conclusion from this basic data preprocessing pipeline\n",
        "\n",
        "1. **Standard stopword lists are insufficient**: Generic English stopwords don't capture the domain-specific \"stopwords\" in technical discussions (like \"use\", \"model\", \"using\"). \n",
        "\n",
        "2. **N-grams would be more informative**: Single words don't capture meaningful technical concepts well. Phrases like \"word embeddings\", \"language model\", or \"neural network\" would be more revealing.\n",
        "\n",
        "3. **Tag information is valuable**: The tags contain the clearest signal about the domain topics. They could be used to guide topic modeling or classification.\n",
        "\n",
        "4. **Different sections serve different purposes**: \n",
        "   - Titles identify the problem\n",
        "   - Descriptions explain the context and attempts\n",
        "   - Answers provide solutions and explanations\n",
        "\n",
        "5. **Technical vocabulary vs. meta-language**: There's a clear separation between domain-specific technical terms (more prevalent in tags) and procedural language about how to solve problems (more prevalent in answers).\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "Based on these observations, I later on follow these steps below:  \n",
        "1. **Lemmatization** Adding lemmatization before the other preprocessing steps would significantly improve my word cloud by grouping different forms of the same word together. This is especially important for technical text where terms like \"token/tokens/tokenize/tokenization\" or \"embed/embedding/embeddings\" all represent related concepts.\n",
        "\n",
        "2. **Develop a custom stopword list** specifically for NLP/programming discussions\n",
        "\n",
        "3. **Focus on bi-grams and tri-grams** to capture meaningful technical concepts\n",
        "\n",
        "4. **Develop separate processing pipelines** for different components (titles, descriptions, tags, answers)\n",
        "\n",
        "5. **Use TF-IDF weighting** instead of raw counts to highlight distinctive terminology\n",
        "\n",
        "6. **Leverage tag information** as a source of ground truth for topic modeling\n",
        "\n",
        "7. **Consider Part-of-Speech patterns** to extract technical noun phrases and concepts\n",
        "\n",
        "These frequency distributions show that this is a rich dataset for NLP tasks, but care must be taken with preprocessing to extract meaningful information from the meta-language common in technical discussions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# __3. Graphical representation of the dataset<a class=\"anchor\" id=\"third-bullet\"></a>__  \n",
        "[Table of Contents](#toc)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "processed_data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
