{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on page 26: 400. Skipping this page.\n",
      "Error on page 27: 400. Skipping this page.\n",
      "Error on page 28: 400. Skipping this page.\n",
      "Error on page 29: 400. Skipping this page.\n",
      "Error on page 30: 400. Skipping this page.\n",
      "Error on page 31: 400. Skipping this page.\n",
      "Error on page 32: 400. Skipping this page.\n",
      "Error on page 33: 400. Skipping this page.\n",
      "Error on page 34: 400. Skipping this page.\n",
      "Error on page 35: 400. Skipping this page.\n",
      "Error on page 36: 400. Skipping this page.\n",
      "Error on page 37: 400. Skipping this page.\n",
      "Error on page 38: 400. Skipping this page.\n",
      "Error on page 39: 400. Skipping this page.\n",
      "Error on page 40: 400. Skipping this page.\n",
      "Error on page 41: 400. Skipping this page.\n",
      "Error on page 42: 400. Skipping this page.\n",
      "Error on page 43: 400. Skipping this page.\n",
      "Error on page 44: 400. Skipping this page.\n",
      "Error on page 45: 400. Skipping this page.\n",
      "Error on page 46: 400. Skipping this page.\n",
      "Error on page 47: 400. Skipping this page.\n",
      "Error on page 48: 400. Skipping this page.\n",
      "Error on page 49: 400. Skipping this page.\n",
      "Error on page 50: 400. Skipping this page.\n",
      "Error on page 51: 400. Skipping this page.\n",
      "Error on page 52: 503. Skipping this page.\n",
      "Error on page 53: 400. Skipping this page.\n",
      "Error on page 54: 400. Skipping this page.\n",
      "Error on page 55: 400. Skipping this page.\n",
      "Error on page 56: 400. Skipping this page.\n",
      "Error on page 57: 400. Skipping this page.\n",
      "Error on page 58: 400. Skipping this page.\n",
      "Error on page 59: 400. Skipping this page.\n",
      "Error on page 60: 400. Skipping this page.\n",
      "Error on page 61: 400. Skipping this page.\n",
      "Error on page 62: 503. Skipping this page.\n",
      "Error on page 63: 400. Skipping this page.\n",
      "Error on page 64: 400. Skipping this page.\n",
      "Error on page 65: 400. Skipping this page.\n",
      "Error on page 66: 400. Skipping this page.\n",
      "Error on page 67: 400. Skipping this page.\n",
      "Error on page 68: 400. Skipping this page.\n",
      "Error on page 69: 400. Skipping this page.\n",
      "Error on page 70: 400. Skipping this page.\n",
      "Error on page 71: 400. Skipping this page.\n",
      "Error on page 72: 400. Skipping this page.\n",
      "Error on page 73: 400. Skipping this page.\n",
      "Error on page 74: 400. Skipping this page.\n",
      "Error on page 75: 400. Skipping this page.\n",
      "Error on page 76: 400. Skipping this page.\n",
      "Error on page 77: 400. Skipping this page.\n",
      "Error on page 78: 400. Skipping this page.\n",
      "Error on page 79: 400. Skipping this page.\n",
      "Error on page 80: 400. Skipping this page.\n",
      "Error on page 81: 400. Skipping this page.\n",
      "Error on page 82: 400. Skipping this page.\n",
      "Error on page 83: 400. Skipping this page.\n",
      "Error on page 84: 400. Skipping this page.\n",
      "Error on page 85: 400. Skipping this page.\n",
      "Error on page 86: 400. Skipping this page.\n",
      "Error on page 87: 400. Skipping this page.\n",
      "Error on page 88: 400. Skipping this page.\n",
      "Error on page 89: 400. Skipping this page.\n",
      "Error on page 90: 400. Skipping this page.\n",
      "Error on page 91: 400. Skipping this page.\n",
      "Error on page 92: 400. Skipping this page.\n",
      "Error on page 93: 400. Skipping this page.\n",
      "Error on page 94: 400. Skipping this page.\n",
      "Error on page 95: 400. Skipping this page.\n",
      "Error on page 96: 400. Skipping this page.\n",
      "Error on page 97: 400. Skipping this page.\n",
      "Error on page 98: 400. Skipping this page.\n",
      "Error on page 99: 400. Skipping this page.\n",
      "Error on page 100: 400. Skipping this page.\n",
      "Error on page 101: 400. Skipping this page.\n",
      "Error on page 102: 400. Skipping this page.\n",
      "Error on page 103: 400. Skipping this page.\n",
      "Error on page 104: 400. Skipping this page.\n",
      "Error on page 105: 400. Skipping this page.\n",
      "Error on page 106: 400. Skipping this page.\n",
      "Error on page 107: 400. Skipping this page.\n",
      "Error on page 108: 400. Skipping this page.\n",
      "Error on page 109: 503. Skipping this page.\n",
      "Error on page 110: 400. Skipping this page.\n",
      "Error on page 111: 400. Skipping this page.\n",
      "Error on page 112: 400. Skipping this page.\n",
      "Error on page 113: 400. Skipping this page.\n",
      "Error on page 114: 400. Skipping this page.\n",
      "Error on page 115: 400. Skipping this page.\n",
      "Error on page 116: 400. Skipping this page.\n",
      "Error on page 117: 400. Skipping this page.\n",
      "Error on page 118: 400. Skipping this page.\n",
      "Error on page 119: 400. Skipping this page.\n",
      "Error on page 120: 400. Skipping this page.\n",
      "Error on page 121: 400. Skipping this page.\n",
      "Error on page 122: 400. Skipping this page.\n",
      "Error on page 123: 400. Skipping this page.\n",
      "Error on page 124: 400. Skipping this page.\n",
      "Error on page 125: 400. Skipping this page.\n",
      "Error on page 126: 400. Skipping this page.\n",
      "Error on page 127: 400. Skipping this page.\n",
      "Error on page 128: 400. Skipping this page.\n",
      "Error on page 129: 400. Skipping this page.\n",
      "Error on page 130: 400. Skipping this page.\n",
      "Error on page 131: 400. Skipping this page.\n",
      "Error on page 132: 400. Skipping this page.\n",
      "Error on page 133: 400. Skipping this page.\n",
      "Error on page 134: 400. Skipping this page.\n",
      "Error on page 135: 400. Skipping this page.\n",
      "Error on page 136: 400. Skipping this page.\n",
      "Error on page 137: 400. Skipping this page.\n",
      "Error on page 138: 400. Skipping this page.\n",
      "Error on page 139: 400. Skipping this page.\n",
      "Error on page 140: 400. Skipping this page.\n",
      "Error on page 141: 400. Skipping this page.\n",
      "Error on page 142: 400. Skipping this page.\n",
      "Error on page 143: 400. Skipping this page.\n",
      "Error on page 144: 400. Skipping this page.\n",
      "Error on page 145: 400. Skipping this page.\n",
      "Error on page 146: 400. Skipping this page.\n",
      "Error on page 147: 400. Skipping this page.\n",
      "Error on page 148: 400. Skipping this page.\n",
      "Error on page 149: 400. Skipping this page.\n",
      "Error on page 150: 400. Skipping this page.\n",
      "Error on page 151: 400. Skipping this page.\n",
      "Error on page 152: 400. Skipping this page.\n",
      "Error on page 153: 400. Skipping this page.\n",
      "Error on page 154: 400. Skipping this page.\n",
      "Error on page 155: 400. Skipping this page.\n",
      "Error on page 156: 400. Skipping this page.\n",
      "Error on page 157: 400. Skipping this page.\n",
      "Error on page 158: 400. Skipping this page.\n",
      "Error on page 159: 503. Skipping this page.\n",
      "Error on page 160: 400. Skipping this page.\n",
      "Error on page 161: 503. Skipping this page.\n",
      "Error on page 162: 400. Skipping this page.\n",
      "Error on page 163: 400. Skipping this page.\n",
      "Error on page 164: 400. Skipping this page.\n",
      "Error on page 165: 400. Skipping this page.\n",
      "Error on page 166: 400. Skipping this page.\n",
      "Error on page 167: 400. Skipping this page.\n",
      "Error on page 168: 400. Skipping this page.\n",
      "Error on page 169: 400. Skipping this page.\n",
      "Error on page 170: 400. Skipping this page.\n",
      "Error on page 171: 400. Skipping this page.\n",
      "Error on page 172: 400. Skipping this page.\n",
      "Error on page 173: 400. Skipping this page.\n",
      "Error on page 174: 400. Skipping this page.\n",
      "Error on page 175: 400. Skipping this page.\n",
      "Error on page 176: 400. Skipping this page.\n",
      "Error on page 177: 400. Skipping this page.\n",
      "Error on page 178: 400. Skipping this page.\n",
      "Error on page 179: 400. Skipping this page.\n",
      "Error on page 180: 400. Skipping this page.\n",
      "Error on page 181: 400. Skipping this page.\n",
      "Error on page 182: 400. Skipping this page.\n",
      "Error on page 183: 400. Skipping this page.\n",
      "Error on page 184: 400. Skipping this page.\n",
      "Error on page 185: 400. Skipping this page.\n",
      "Error on page 186: 400. Skipping this page.\n",
      "Error on page 187: 400. Skipping this page.\n",
      "Error on page 188: 400. Skipping this page.\n",
      "Error on page 189: 400. Skipping this page.\n",
      "Error on page 190: 400. Skipping this page.\n",
      "Error on page 191: 400. Skipping this page.\n",
      "Error on page 192: 400. Skipping this page.\n",
      "Error on page 193: 400. Skipping this page.\n",
      "Error on page 194: 400. Skipping this page.\n",
      "Error on page 195: 400. Skipping this page.\n",
      "Error on page 196: 400. Skipping this page.\n",
      "Error on page 197: 400. Skipping this page.\n",
      "Error on page 198: 400. Skipping this page.\n",
      "Error on page 199: 400. Skipping this page.\n",
      "Error on page 200: 400. Skipping this page.\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# BASE_URL = \"https://api.stackexchange.com/2.3/questions\"\n",
    "\n",
    "# params = {\n",
    "#     \"order\": \"desc\",\n",
    "#     \"sort\": \"creation\",\n",
    "#     \"tagged\": \"nlp\",\n",
    "#     \"site\": \"stackoverflow\",\n",
    "#     \"pagesize\": 100,\n",
    "\n",
    "# }\n",
    "\n",
    "# # def fetch_questions(pages=200):  # Adjust pages to get 20,000 posts\n",
    "# #     all_questions = []\n",
    "# #     for page in range(1, pages + 1):\n",
    "# #         params[\"page\"] = page\n",
    "# #         response = requests.get(BASE_URL, params=params)\n",
    "# #         if response.status_code != 200:\n",
    "# #             print(f\"Error on page {page}: {response.status_code}\")\n",
    "# #             #break\n",
    "# #         data = response.json()\n",
    "# #         all_questions.extend(data.get(\"items\", []))\n",
    "# #         time.sleep(1)  # Avoid rate limiting\n",
    "# #     return all_questions\n",
    "# def fetch_questions(pages=200):\n",
    "#     all_questions = []\n",
    "#     for page in range(1, pages + 1):\n",
    "#         params[\"page\"] = page\n",
    "#         response = requests.get(BASE_URL, params=params)\n",
    "#         if response.status_code != 200:\n",
    "#             print(f\"Error on page {page}: {response.status_code}. Skipping this page.\")\n",
    "#             continue  # Skip the problematic page\n",
    "#         data = response.json()\n",
    "#         all_questions.extend(data.get(\"items\", []))\n",
    "#         time.sleep(1)  # Avoid rate limiting\n",
    "#     return all_questions\n",
    "\n",
    "# questions = fetch_questions()\n",
    "# df = pd.DataFrame(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ASUS\\.conda\\envs\\myenv\\Lib\\site-packages\\requests\\models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.conda\\envs\\myenv\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.conda\\envs\\myenv\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.conda\\envs\\myenv\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 41\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_questions\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Fetch NLP questions\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m nlp_questions \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_stackoverflow_posts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnlp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 23\u001b[0m, in \u001b[0;36mfetch_stackoverflow_posts\u001b[1;34m(tag, page_size, max_pages)\u001b[0m\n\u001b[0;32m     12\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage\u001b[39m\u001b[38;5;124m'\u001b[39m: page,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpagesize\u001b[39m\u001b[38;5;124m'\u001b[39m: page_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwithbody\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Include question body\u001b[39;00m\n\u001b[0;32m     20\u001b[0m }\n\u001b[0;32m     22\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(base_url, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m---> 23\u001b[0m questions \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m questions:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\.conda\\envs\\myenv\\Lib\\site-packages\\requests\\models.py:978\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def fetch_stackoverflow_posts(tag, page_size=100, max_pages=200):\n",
    "    base_url = \"https://api.stackexchange.com/2.3/questions\"\n",
    "    \n",
    "    all_questions = []\n",
    "    \n",
    "    for page in range(1, max_pages + 1):\n",
    "        params = {\n",
    "            'page': page,\n",
    "            'pagesize': page_size,\n",
    "            'order': 'desc',\n",
    "            'sort': 'creation',\n",
    "            'tagged': tag,\n",
    "            'site': 'stackoverflow',\n",
    "            'filter': 'withbody'  # Include question body\n",
    "        }\n",
    "        \n",
    "        response = requests.get(base_url, params=params)\n",
    "        questions = response.json().get('items', [])\n",
    "        \n",
    "        if not questions:\n",
    "            break\n",
    "            \n",
    "        all_questions.extend(questions)\n",
    "        \n",
    "        # Respect API rate limits}\n",
    "        if response.json().get('has_more', False):\n",
    "            time.sleep(1)  # Wait between requests\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "\n",
    "\n",
    "# Fetch NLP questions\n",
    "nlp_questions = fetch_stackoverflow_posts('nlp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_answers_for_question(question_id):\n",
    "    url = f\"https://api.stackexchange.com/2.3/questions/{question_id}/answers\"\n",
    "    params = {\n",
    "        'order': 'desc',\n",
    "        'sort': 'votes',\n",
    "        'site': 'stackoverflow',\n",
    "        'filter': 'withbody'  # Include answer body\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json().get('items', [])\n",
    "\n",
    "\n",
    "# Create a DataFrame structure\n",
    "data = []\n",
    "\n",
    "for question in nlp_questions:\n",
    "    # Get answers for this question\n",
    "    answers = get_answers_for_question(question['question_id'])\n",
    "    \n",
    "    # Find accepted answer (if any)\n",
    "    accepted_answer = None\n",
    "    other_answers = []\n",
    "    \n",
    "    for answer in answers:\n",
    "        if answer.get('is_accepted', False):\n",
    "            accepted_answer = answer.get('body', '')\n",
    "        else:\n",
    "            other_answers.append(answer.get('body', ''))\n",
    "    \n",
    "    # Format the data\n",
    "    question_data = {\n",
    "        'title': question.get('title', ''),\n",
    "        'description': question.get('body', ''),\n",
    "        'tags': question.get('tags', []),\n",
    "        'accepted_answer': accepted_answer,\n",
    "        'other_answers': other_answers[:1],  # Just get the first additional answer if exists\n",
    "        'creation_date': datetime.fromtimestamp(question.get('creation_date', 0)),\n",
    "        'view_count': question.get('view_count', 0),\n",
    "        'score': question.get('score', 0)\n",
    "    }\n",
    "    \n",
    "    data.append(question_data)\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
