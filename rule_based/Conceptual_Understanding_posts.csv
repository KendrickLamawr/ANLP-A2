id,title,tags,answer
78639577,understanding the results of transformers learn in context with gradient descent,machinelearning nlp largelanguagemodel transformermodel metalearning,what data are you using in your replication as far as i can tell this paper does not mention explicitly the parameters of the data used for the particular result you are trying to replicate indeed it tests a variety of alpha values for the distributions used in figure it is feasible for the loss to be low even after one step of gd if the alpha value is low if you find the same trends in relative behavior of gd and transformer layers i dont think its important to match the exact loss values
78284866,what is the best functionstage to use tokenizer in pytorchs data processing,pytorch nlp,neither you want to tokenize your entire dataset in batch prior to training tokenizing during training slows it down and is wasteful if youre doing multiple epochs you will tokenize the same items multiple times you should tokenize your entire dataset first then do batching and padding in your collate function it sounds like youre using huggingface tokenizers you should also use huggingface datasets and the collate functions they provide
78241665,how to detect if two sentences are simmilar not in meaning but in syllableswords,search nlp fulltextsearch similarity sentencesimilarity,one way to approach this although might not be the best way is to first vectorize the words in the two sentences ie essentially giving a number to each word which would give you a vector for each sentence then compare those two vectors for similarity codewise you can do the following in python from sklearnfeatureextractiontext import countvectorizer from sklearnmetricspairwise import cosinesimilarity def sentencesimilaritysentence sentence tokenize sentences into ngrams ngramrange range can be adjusted vectorizer countvectorizerngramrangengramrange vectors vectorizerfittransformsentence sentence checking for similarity using cosine similarity ie dot product similaritymatrix cosinesimilarityvectors similarityscore similaritymatrix return similarityscore please note that you need to have scikit learn installed in order to perform the above imports you can do that by executing the following command in cmd or terminal pip install scikitlearn
77935492,what is the trec spam track public corpora format,nlp spamprevention,disclaimer before reading the answer please note that since i had not participated in the trec task nor am i the data creatorprovider i can do only some educated guess to the questions you have on the dataset educated guessed answers first reading the task paper helps next the right download link for future readers would be and now some summary trec spam track dataset is a set of chronologically ordered email messages a spam filter for classification four different forms of user feedback are modeled with immediate feedback the gold standard for each message is communicated to the filter immediately following classification delayed feedback the gold standard is communicated to the filter sometime later or potentially never so as to model a user reading email from time to time and perhaps not diligently reporting the filters errors partial feedback the gold standard for only a subset of email recipients is transmitted to the filter so as to model the case of some users never reporting filter errors active online learning the filter is allowed to request immediate feedback for a certain quota of messages which is considerably smaller than the total number q how are the above forms of feedback represented by the files in the dataset a all the actual textual data are actually found in the trecdata files and for the rest of the directories they are just a indices pointing to the subsets to emulate the different forms of evaluations q what does full mean in this case is it just the labels trecpfullindex the index of email lists that points to all the data points in trecpdata q what is the delay for eg datadelay fulldelay trecpfulldelayindex the indices that points to the delayed feedback evaluation trecphamdelayindex the indices that points to only the nonspam labelled emails in the delayed feedback evaluation trecpspamdelayindex the indices that points to only the spam labelled emails in the delayed feedback evaluation so essentially all the unique list of trecphamdelayindex trecpspamdelayindex trecpfulldelayindex q why is the datadelay folder empty for this i dont have an answer got to ask the data providercreator q is there any special way to parse the contents in the data folder now thats the fun coding part lets step back a little and think what we have essentially a list of emails in trecdata the spamham labels of each email in trecfullindex the spamspamhamham labels of a subset of emails in trecfulldelayindex so q what is the difference between ham ham spam and spam labels in the trecpdelayindex if we look carefully at the if dataid in fulldelaylabels assert labellower fulldelaylabelsdataidlower line we see that all the caps and the noncaps labels are the same q so why is there a difference a not sure best to ask data providercreator q is there a difference between the labels from trecpfulldelayindex and trecpfullindex dont seem like theres any q how do i just read it into a pandas dataframe given what we know above q but the input columns are still binaries can i somehow guess the encoding not really its pretty hard messy to guess the encoding of a binary file but you can try this though not all file specify charset in the content
77828572,what is sent to the llm when using a chat model,nlp langchain,you can use format method to format the chat template into a string here is the updated code prompt templateformat namebob userinputwhat is your name prompt output
77116207,what is the correct approach to evaluate huggingface models on the masked language modeling task,machinelearning nlp huggingfacetransformers huggingface,as pointed out in the linked post this is a warning to indicate that those weights are not used this is raised since youre loading a model that has its pooler weights initialised bertbasecased but arent used by a maskedlm model the bertpooler weights are typically used for classification tasks such as bertforsequenceclassification for bertbasecased the model was also trained on the next sentence prediction nsp task so the pooler weights are also trained as pointed out in this github comment after passing a sentence through the model the representation corresponding to the first token in the output is used for finetuning on tasks like squad and glue so the pooler layer does precisely that applies a linear transformation over the representation of the first token the linear transformation is trained while using the next sentence prediction nsp strategy in fact whenever initialising the model with the next sentence prediction task the warning isnt raised from transformers import automodelformaskedlm automodelfornextsentenceprediction automodelforpretraining raises a warning automodelformaskedlmfrompretrainedbertbasecased doesnt raise a warning automodelfornextsentencepredictionfrompretrainedbertbasecased doesnt raise a warning initialised with both mlm nsp automodelforpretrainingfrompretrainedbertbasecased since youre interested in masked language modelling mlm you can disregard the warning since this isnt used for this task for the masked language modelling task you should initialise using automodelformaskedlm since this includes the appropriate head to predict the masked token this forum post has further details about the differences in initialisations
76738928,understanding lstm for speech recognition,python nlp lstm speechrecognition recurrentneuralnetwork,the lstm will simply have input neurons the inputs are represented by weights and biases to the lstmcell
75989822,what is stanford corenlps recipe for tokenization,python nlp stanfordnlp tokenize,so ive just done some more digging and i found that stanfordnlps tokenizer class ptbtokenizer was roughly inspired by the penn treebank see there is an nltk solution for that one and it roughly gives the same tokenization behavior as i was expecting
75943880,what is the most efficient way to identify text similarity between items in large lists of strings in python,python text nlp cosinesimilarity hammingdistance,the following solution is based on your original code hamming distance which offers an almost order of magnitude speedup averaged across five runs of each as measured by lineprofiler using this solution as a base for parallel processing may get you closer to the total processing times you are after to use lineprofiler pip install lineprofiler and then run kernprof l v testpy after adding profile and calling the function to be profiled from main from itertools import ziplongest from bisect import insort lemmas do done purpose can be use for cannon amuse useful user become downtown develop fulminate deduce de bezant forms done done doing purposeful canonical becareful being berate best bezant full fulmination predict downgrade down developing deduct deducing distances profile def profiledistancecalcs lemmaslow lemmalower for lemma in lemmas formslow formlower for form in forms for form in formslow formdistances for lemma in lemmaslow charmatches c c for c c in ziplongestlemma form dist sumcharmatcheslencharmatches if dist insortformdistances dist lemma distancesform formdistances with openpotentiallemmashammingtxt w as f for form formdistances in distancesitems for dist lemma in reversedformdistances fwritefform lemma distn if name main profiledistancecalcs from the time profile breakdown below total time s you can get an idea of where the slowdowns are coming from the main culprit is obviously the distance computation which is why i switched the textdistancehammingnormalizedsimilarity for a much more efficient barebones manual calculation of the same thing based on the textdistance hamming and hammingnormalizedsimilarity source code i also believe using bisectinsort and maintaining a sorted list while inserting is faster than inserting all elements and then running heapqnlargest line hits time per hit time line contents profile def profiledistancecalcs lemmaslow lemmalower for lemma in lemmas formslow formlower for form in forms for form in formslow formdistances for lemma in lemmaslow charmatches c c for c c in ziplongestlemma form dist sumcharmatcheslencharmatches if dist insortformdistances dist lemma distancesform formdistances with openpotentiallemmashammingtxt w as f for form formdistances in distancesitems for dist lemma in reversedformdistances fwritefform lemma distn original code speed profile here is your original code for comparison i modified some aspects of it the main difference is the use of heapqnlargest as i believe you were after the most similar lemmas for each form and not the least similar which heapqnsmallest provided from textdistance import hamming cosine jarowinkler import heapq lemmas do done purpose can be use for cannon amuse useful user become downtown develop fulminate deduce de bezant forms done done doing purposeful canonical becareful being berate best bezant full fulmination predict downgrade down developing deduct deducing distances processedpairs set keep track of processed pairs profile def profiledistancecalcs for lemma in lemmas if lemma is none continue lemmalower lemmalower for form in forms if form is none continue formlower formlower pair lemmalower formlower if pair not in processedpairs processedpairsaddpair dist hammingnormalizedsimilaritylemmalower formlower if dist distancessetdefaultformlower appenddist lemmalower find the closest pairs closestpairs for form distlemmas in distancesitems closestpairsform heapqnlargest distlemmas with openpotentiallemmasorigtxt w as f for form pairs in closestpairsitems for dist lemma in pairs fwritefform lemma distn if name main profiledistancecalcs time profile breakdown for the original code total time s line hits time per hit time line contents profile def profiledistancecalcs for lemma in lemmas if lemma is none continue lemmalower lemmalower for form in forms if form is none continue formlower formlower pair lemmalower formlower if pair not in processedpairs processedpairsaddpair dist hammingnormalizedsimilaritylemmalower formlower if dist distancessetdefaultformlower appenddist lemmalower find the closest pairs closestpairs for form distlemmas in distancesitems closestpairsform heapqnlargest distlemmas with openpotentiallemmasorigtxt w as f for form pairs in closestpairsitems for dist lemma in pairs fwritefform lemma distn measuring natural language similarity measuring the similarity between two pieces of natural language text is a nontrivial task attempting to gauge spellingmorphologicalsemantic similarity based purely on rudimentary characterbased metrics eg hamming distance levenshtein distance etc wont suffice as these metrics fail to capture complex linguistic patterns hence why neural network methods are commonly used to pick up these patterns in large bodies of text with that being said one can begin to add their own rules to calculate more accurate similarity scores for example the code below modifies the normalised hamming similarity computation to track how many consecutive characters match and then scales the similarity score accordingly there is obviously scope for finetuning andor increasing the complexitynumber of rules used but with more complexity comes slower processing times this custom function avoids the issue of results like beatte beats and beatus certus instead scoring them as beatte beats and beatus certus def customhammingnormsimstra strb scale maxstrlen maxlenstra lenstrb maxscoreperchar maxstrlen penalty score for c c in ziplongeststra strb if c c penalty penalty scale score maxscoreperchar penalty else p penalty scale if p maxscoreperchar penalty p score maxscoreperchar penalty return score profile def profiledistancecalcs lemmaslow lemmalower for lemma in lemmas formslow formlower for form in forms for form in formslow formdistances for lemma in lemmaslow dist customhammingnormsimlemma form if dist insortformdistances dist lemma distancesform formdistances with openpotentiallemmashammingtxt w as f for form formdistances in distancesitems for dist lemma in reversedformdistances fwritefform lemma distn if name main profiledistancecalcs
75890430,what is the classification head of a hugging face automodelfortokenclassification model,python pytorch nlp huggingfacetransformers textclassification,the automodel is not pytorch model implementation it is an implemented factory pattern that means it returns an instance of a different class depending on the provided parameters for example from transformers import automodelfortokenclassification m automodelfortokenclassificationfrompretrainedrobertabase printtypem output you can check the head either with the official documentation of the class or with parameters output
75173490,how can i check similarity in meaning and not just having same words between two texts with spacy,python nlp spacy similarity semantics,the spacy library by default will use the average of the word embeddings of words in a sentence to determine semantic similarity this can be thought of as a naive sentence embedding approach such an approach could work but if you were to use it is recommended that you first filter nonmeaningful words eg common words to prevent them from undesirably influencing the final sentence embeddings the alternative and more reliable solution is to use a different pipeline within spacy that has been designed to use sentence embeddings created specifically with a dedicated sentence encoder eg the universal sentence encoder use by cer et al martino mensio created a package called spacyuniversalsentenceencoder that makes use of this model install it via the following command in your command prompt pip install spacyuniversalsentenceencoder then you can compute the semantic similarity between sentences as follows import spacyuniversalsentenceencoder load one of the models enusemd enuselg xxusemd xxuselg nlp spacyuniversalsentenceencoderloadmodelenuselg create two documents doc nlphi there how are you doc nlphello there how are you doing today use the similarity method to compare the full documents ie sentences printdocsimilaritydoc output or make the comparison using a predefined span of the second document printdocsimilaritydoc output as a side note when you run the nlp spacyuniversalsentenceencoderloadmodelenuselg command for the first time you may have to do so with administrator rights to allow tensorflow to create the models folder in cprogram filespythonlibsitepackagesspacyuniversalsentenceencoder and download the appropriate model if you dont it is possible that there will be a permissiondeniederror and the code will not run references cer d yang y kong sy hua n limtiaco n john rs constant n guajardocespedes m yuan s tar c and sung yh universal sentence encoder arxiv preprint arxiv
74428413,understanding dimensions in multiheadattention layer of tensorflow,tensorflow nlp transformermodel attentionmodel,yes for you can probe the weights by get the weights associated output shapes
74178604,explain regular expression in python,python nlp expression regularlanguage,for the regular expression aeiouaeiouyaeiouaeiou we can break it down into aeiouaeiou not a vowel y the letter y aeiouaeiou not a vowel specifically aeiou would be a set of all lowercase vowels so that matches on one character of aeiou the caret means not so aeiou would match on any character other than a lower case vowel therefore the regex matches the letter y with any character directly before and after it that is not a vowel
73656239,python how to automatically spellcheck and correct joined words such as reportthatexplains and havebeen,python nlp,use word ninja library for splitting long word into sub word
73339264,what is meant by define model class in pytorch documentation,python nlp pytorch,you need to define the model class as for example explained here reusing the example from the linked website as a random example a class for themodelclass could be defined as follows
73334654,what is better custom training the bert model or use the model with pretrained data,python nlp huggingfacetransformers nlpquestionanswering,the stateoftheart approach is to take a pretrained model that was pretrained on tasks that are relevant to your problem and finetune the model on your dataset so assuming you have your dataset in english you should take a pretrained model on natural language english you can then finetune it this will most likely work better than training from scratch but you can experiment on your own you can also load a model without the pretrained weights in huggingface
73311660,what is the difference between asssigning layer and assigning weight of layer,deeplearning nlp pytorch embedding,if you assign a layer weight the assigned layer weight has to have the same shape as the current layer weight if you assign a new layer you can assign any layer as long as it can handle the input tensor shape and return the correct output tensor shape
73146232,what is a regex expression that can prune down repeating identical characters down to a maximum of two repeats,python regex nlp datapreprocessing,the regexp should be w to match a character followed by at least repetitions thats or more when you include the initial character the replacement is then to replace with just two repetitions
73132769,what is the right way to get unit vector to index elasticsearch ann dotproduct,python elasticsearch nlp,i was confronted with the exact same problem and i found a solution after much experimentation in my case when indexing lots of embeddings to elasticsearch densevector with similarity parameter set to dotproduct most of them got indexed properly and a small percentage of them failed with the dotproduct similarity can only be used with unitlength vectors i found after intensive testing that the problem was that the unit vectors i was working with were of numerical types npfloat and this was causing the error working with npfloat as a numerical type in my workflow for my unit vectors solved the issue
72997028,how to understand the answerstart parameter of squad dataset for training bertqa model practical implications for creating custom dataset,nlp huggingfacetransformers bertlanguagemodel huggingfacedatasets squad,your question is a bit broad to give you a specific answer but i will try my best to point you in some directions the intuition behind how the model uses the answerstart when calculating the loss accuracy etc there are different types of qa tasksdatasets the ones you mentioned squad and adversarialqa belong to the field of extractive question answering there a model must select a span from a given context that answers the given question for example context second democrats have always elevated their minority floor leader to the speakership upon reclaiming majority status republicans have not always followed this leadership succession pattern in for instance republicans bypassed james r mann ril who had been minority leader for eight years and elected frederick gillett rma to be speaker mann had angered many republicans by objecting to their private bills on the floor also he was a protg of autocratic speaker joseph cannon ril and many members suspected that he would try to recentralize power in his hands if elected speaker more recently although robert h michel was the minority leader in when the republicans regained control of the house in the midterm elections he had already announced his retirement and had little or no involvement in the campaign including the contract with america which was unveiled six weeks before voting day questionhow did republicans feel about mann in answerangered starting at character a simple approach that is often used today is a linear layer that predicts the answer start and answer end from the last hidden state of a transformer encoder code example the last hidden state holds one vector for each input token token words and the linear layer is trained to assign high probabilities to tokens that could potentially be the start and end of the answer span to train a model with your data the loss function needs to know which tokens should get a high probability ie the answer and the start token if i need to go through the process of adding this to my custom dataset easier to run model evaluation code etc you should go through this process otherwise how should someone know where the answer starts in your context they can of course interfere with it programmatically but what if your answer string appears twice in the context providing an answer start position avoids confusion and allows your users to use it right away with one of the many extractive questions answering scripts that are already available out there if so is there a programmatic way to do this to avoid manual effort you could simply loop through your dataset and use strfind contextfindanswer output
72706958,what is the ideal size of the vector for each word in wordvec,python pythonx machinelearning nlp wordvec,each dimension of a dense vector is typically a bit float so storing tokenvectors of dimensions each will take at least vectors floats bytesfloat mb for the raw vector weights plus some overhead for remembering which token associates with which line lets say you were somehow changing each of your rows into a single summary vector of the same size perhaps by averaging together each of the token vectors into a single vector a simple baseline approach though there are many limitations of that approach other techniques that might be used in that case storing the million vectors will necessarily take about vectors floats bytesfloat mb for the raw vector weights plus some overhead to remember which row associates with which vector that neither of these is anywhere close to gb implies youre making some other choices expanding things significantly json is a poor choice for compactly representing dense floatingpoint numerical data but even that is unlikely to explain the full expansion your description that you saved these vectors for each data point in a json file isnt really clear what vectors are being saved or in what sort of json conventions perhaps youre storing the separate vectors for each row thatd give a raw baseline weightsonly size of rows tokensrow floats bytesfloat gb it is plausible inefficient json is expanding the storedsize by something like x so i guess youre doing something like this but in addition to the inefficiency of json given that the tokens from a vocabulary of k each given enough info to reconstitute any other perrow info thats solely a function of the tokens the k wordvectors theres not really any reason to expand the representations this way for example if the word apple is already in your dataset and appears many thousands of times theres no reason to rewrite the dimensions of apple many thousands of times the word apple alone is enough to callback those dimensions whenever you want them from the muchsmaller mb setofk tokenvectors thats easy to keep in ram so mainly ditch json dont unnecessarily expand each row into dimensions to your specific questions the optimal size will vary based on lots of things including your data other goals the only way to rationally choose is to figure out some way to score the trained vectors on your true end goals some repeatable way of comparing multiple alternate choices of vectorsize then you run it every plausible way pick the best barring that you take a random stab based on some precedent work that seems roughly similar in datagoals and hope that works ok until you have the chance to compare it against other choices the choice of skipgram or cbow wont affect the size of the model at all it might affect end result quality training times a bit but the only way to choose is to try both see which works better for your goals constraints json is an awful choice for storing dense binary data representing numbers as just text involves expansion the json formatting characters add extra overhead repeatedly on every tow thats redundant if every row is the exact same shape of raw data and typical later vector operations in ram usually work best on the same sort of maximallycompact raw inmemory representation that would also be best on disk in fat the best ondisk representation will often be data that exactly matches the format in memory so that data can be memorymapped from disk to ram in a quick direct operation that minimizes formatwrangling even defers accesses until reads needed gensim will efficiently save its models via their buildin save method into one or more often several related files on disk if your gensim wordvec model is in the variable wvmodel you can just save the whole model with wvmodelsaveyourfilename later reload it with wordvecloadyourfilename but if after training you only need the k wordvectors you can just save the wvmodelwv property just the vectors wvmodelwvsaveyourfilename then you can reload them as an instance of keyedvectors keyedvectorsloadyourfilename note in all cases the save may be spread over multiple files which if ever copiedmoved elsewhere should be kept together even though you only ever specify the root file of each set in saveload operations how whether youd want to store any vectorization of your million rows would depend on other things not yet specified including the character of the data and the kinds of classification applied later i doubt that you want to turn your rows into dimensions thatd be counter to some of the usual intended benefits of a wordvecbased analysis where the word apple has much the same significance no matter where it appears in a textual listofwords youd have to say more about your data classification goals to get a better recommendation here if you havent already done a bagofwords style representation of your rows no wordvec where every row is represented by a dimension onehot sparse vector and run a classifier on that id recommend that first as a baseline
71988281,is there a way to find the antonymword with the opposite meaning of a word with python do you know a dataset or an nlp toolkit,python nlp dataset,nltk is the main library for nlp and it includes many corpora see the code here how to generate a list of antonyms for adjectives in wordnet using python nltk documentation on using wordnet
71801656,extract meaningful words from spaceless texts,nlp nltk stanfordnlp spacy gensim,check out this thread where among other things a package is mentioned which does this generally an approach with a predefined list of common words can get you far your question has an overlap with the task of optical character recognition ocr post correction which you can find some pretrained models for although the problem being that strongly shifted towards one issue missing whitespace character probably leads to it not performing too great if you want to really get into this topic you could try to train a new model on this task i can imagine that recent popular transformer models which use subtokenlevel embeddings for unknown words could be trained to bring a decent performance on this task since there are models which go into a similar direction as grammar correction and sentence boundary correction there are also some older rulebased approach papers which call this problem word boundary detection or more specifcally agglutination check out eg but generally the amount of offtheshelf solutions you find for that problems is quite low
71679626,what is so special about special tokens,nlp tokenize huggingfacetransformers bertlanguagemodel huggingfacetokenizers,special tokens are called special because they are not derived from your input they are added for a certain purpose and are independent of the specific input what i dont understand is under what kind of capacity will you want to create a new special token any examples what we need it for and when we want to create a special token other than those default special tokens just an example in extractive conversational questionanswering it is not unusual to add the question and answer of the previous dialogturn to your input to provide some context for your model those previous dialog turns are separated with special tokens from the current question sometimes people use the separator token of the model or introduce new special tokens the following is an example with a new special token q first dialog turn no conversation history cls current question sep text eos second dialog turn with previous question to have some context cls previous question q current question sep text eos and i also dont quite understand the following description in the source documentation what difference does it do to our model if we set addspecialtokens to false from transformers import robertatokenizer t robertatokenizerfrompretrainedrobertabase tthis is an example inputids attentionmask tthis is an example addspecialtokensfalse inputids attentionmask as you can see here the input misses two tokens the special tokens those special tokens have a meaning for your model since it was trained with it the lasthiddenstate will be different due to the lack of those two tokens and will therefore lead to a different result for your downstream task some tasks like sequence classification often use the cls token to make their predictions when you remove them a model that was pretrained with a cls token will struggle
71634668,what is gensims simplepreprocess alternative in scikit learn,scikitlearn nlp gensim,i dont think scikitlearn provides a similar utility function but the whole logic of what gensims simplepreprocess is doing is only about lines of source code spread across functions simplepreprocess which relies on tokenize which relies on tounicode deaccent simpletokenize so if you wanted the same behavior without installing gensim you have the option to just copy paste or otherwise lightly adapt that source code
71607906,understanding gpu usage huggingface classification total optimization steps,python nlp gpu huggingfacetransformers,why optimization steps looking at the implementation of the transformers package we see that the trainer uses a variable called maxsteps when printing the total optimization steps message in the train method loggerinfo running training loggerinfof num examples numexamples loggerinfof num epochs numtrainepochs loggerinfof instantaneous batch size per device argsperdevicetrainbatchsize loggerinfof total train batch size w parallel distributed accumulation totaltrainbatchsize loggerinfof gradient accumulation steps argsgradientaccumulationsteps loggerinfof total optimization steps maxsteps permalink to the above snippet in the transformers repo the trainer has the following bit of code earlier in the train method class trainer def trainself none some irrelevant code ommited here totaltrainbatchsize argstrainbatchsize argsgradientaccumulationsteps argsworldsize if traindatasetissized numupdatestepsperepoch lentraindataloader argsgradientaccumulationsteps numupdatestepsperepoch maxnumupdatestepsperepoch if argsmaxsteps maxsteps argsmaxsteps numtrainepochs argsmaxsteps numupdatestepsperepoch int argsmaxsteps numupdatestepsperepoch may be slightly incorrect if the last batch in the training datalaoder has a smaller size but its the best we can do numtrainsamples argsmaxsteps totaltrainbatchsize else maxsteps mathceilargsnumtrainepochs numupdatestepsperepoch numtrainepochs mathceilargsnumtrainepochs numtrainsamples lenselftraindataset argsnumtrainepochs permalink to the above snippet in the transformers repo totaltrainbatchsize argstrainbatchsize argsgradientaccumulationsteps argsworldsize in your example will be equal to totaltrainbatchsize as expected then we have numupdatestepsperepoch lentraindataloader argsgradientaccumulationsteps which will give us numupdatestepsperepoch lentraindataloader now the length of a dataloader is equal to the number of batches in that dataloader since you have samples and we have a perdevicetrainbatchsize of this will give us batches going back to numupdatestepsperepoch we now have numupdatestepsperepoch python integer division takes the floor you dont have a number of max steps specified so then we get to maxsteps mathceilargsnumtrainepochs numupdatestepsperepoch which gives us maxsteps mathceil why does the padding operation get logged times in a transformers architecture you technically dont have to pad all your samples to be the same length what actually matters is that samples within a batch are the same length that length can differ from batch to batch this means that this message will appear for every batch that goes through a forward pass as to why the message appeared times even though batches have actually gone through a forward pass i can think of two possible reasons the logging of the padding operation and the logging of the progress bar are happening on two different threads and the former is lagging behind a bit extremely unlikely you had batches that did not need to be padded because all samples had the same length and that length was a multiple of already
71581197,what is the loss function used in trainer from the transformers library of hugging face,python machinelearning nlp artificialintelligence huggingfacetransformers,it depends especially given your relatively vague setup description it is not clear what loss will be used but to start from the beginning lets first check how the default computeloss function in the trainer class looks like you can find the corresponding function here if you want to have a look for yourself current version at time of writing is the actual loss that will be returned with default parameters is taken from the models output values loss outputsloss if isinstanceoutputs dict else outputs which means that the model itself is by default responsible for computing some sort of loss and returning it in outputs following this we can then look into the actual model definitions for bert source here and in particular check out the model that will be used in your sentiment analysis task i assume a bertforsequenceclassification model the code relevant for defining a loss function looks like this if labels is not none if selfconfigproblemtype is none if selfnumlabels selfconfigproblemtype regression elif selfnumlabels and labelsdtype torchlong or labelsdtype torchint selfconfigproblemtype singlelabelclassification else selfconfigproblemtype multilabelclassification if selfconfigproblemtype regression lossfct mseloss if selfnumlabels loss lossfctlogitssqueeze labelssqueeze else loss lossfctlogits labels elif selfconfigproblemtype singlelabelclassification lossfct crossentropyloss loss lossfctlogitsview selfnumlabels labelsview elif selfconfigproblemtype multilabelclassification lossfct bcewithlogitsloss loss lossfctlogits labels based on this information you should be able to either set the correct loss function yourself by changing modelconfigproblemtype accordingly or otherwise at least be able to determine whichever loss will be chosen based on the hyperparameters of your task number of labels label scores etc
71469605,understanding the winograd schema,nlp,the wikipedia page gives an example of a winograd schema with the two instances the city councilmen refused the demonstrators a permit because they feared violence the city councilmen refused the demonstrators a permit because they advocated violence the question is which noun group does they refer to in sentence it would be the city councilmen in sentence it would be the demonstrators how do you make that decision the syntactic structure of the two sentences is identical so it all hinges on the verbs to fear and to advocate in order to make the right choice you need to understand why councilmen fear violence and would thus refuse it if demonstrators advovate it this involves semantic and pragmatic knowledge which are weak areas in nlp it usually only works for limited domains as it requires a lot of world knowledge in this case about what you would expect from councilmen and demonstrators and what the role of permits is so while syntax is easy to handle for current nlp it is mostly irrelevant in resolving the winograd schema challenges
71318065,how to understand losslearning rate log scale plot using learnerlrplot in ktrain package,plot nlp loss learningrate ktrain,as the text from the lrfind method says you can visually inspect the plot and choose a learning rate in a range where the loss is falling prior to divergence a higher learning rate in this range will converge faster this is an idea called an lr range test from leslie smiths paper that became popular through the fastai library and was later adopted by other libraries like ktrain and amazons gluon library the red dot in this plot is just a numerical approximation of where the loss is dramatically falling that may be useful for automated scenarios but not necessarily the best in this plot the red dot represents the steepest part of the curve which is one strategy to automatically select a learning rate from the plot without visual inspection other automated strategies include taking the learning rate associated with the minimum loss and dividing by and finding the learning rate associated with the longest valley
70018491,what is this nlp task called,nlp,this is a semantic lookup where you look at specific terms in the text and find superordinates for them chlorpromazine is a medicine or a drug a diagnosis is a type of procedure and a patient is a living being you could do this with an ontology or a thesaurus some dictionaries also have information about superordinates often in the definition a horse is a mammal with four legs this is not named entity recognition in ner you identify something by its name and return a specific identifier so for chlorpromazine you would not say that it was a medicinedrug but you would get a serial number or reference for it which is distinct from any other drug
69907682,what are differences between automodelforsequenceclassification vs automodel,nlp textclassification huggingfacetransformers,the difference between automodel and automodelforsequenceclassification model is that automodelforsequenceclassification has a classification head on top of the model outputs which can be easily trained with the base model
69866866,what is the best way to compute metrics for the transformers results,python nlp huggingfacetransformers,in my opinion there is something wrong with the model dslimbertlargener youre using according to documents they have introduced an argument named aggregationstrategy for the exact same purpose full explanation but for some reason this is not working properly here now there are two options for the quick fix first change the model to one which is working fine output second translate the output to a more comfortable format to do the rest of the process probably with the aid of a state machine
69836422,bert outputs explained,python tensorflow deeplearning nlp bertlanguagemodel,the tensorflow docs provide a very good explanation to the outputs you are asking about the bert models return a map with important keys pooledoutput sequenceoutput encoderoutputs pooledoutput represents each input sequence as a whole the shape is batchsize h you can think of this as an embedding for the entire movie review sequenceoutput represents each input token in the context the shape is batchsize seqlength h you can think of this as a contextual embedding for every token in the movie review encoderoutputs are the intermediate activations of the l transformer blocks outputsencoderoutputsi is a tensor of shape batchsize seqlength with the outputs of the ith transformer block for here is another interesting discussion on the difference between the pooledoutput and sequenceoutput if you are interested the default output is equal to the pooledoutput which you can confirm here import tensorflow as tf import tensorflowhub as hub tfhubhandlepreprocess tfhubhandleencoder def buildclassifiermodelname textinput tfkeraslayersinputshape dtypetfstring namefeatures bertpreprocessmodel hubkeraslayertfhubhandlepreprocess namepreprocessing encoderinputs bertpreprocessmodeltextinput encoder hubkeraslayertfhubhandleencoder outputs encoderencoderinputs net outputsname return tfkerasmodeltextinput net sentence tfconstant improve the physical fitness of your goldfish by getting him a bicycle classifiermodel buildclassifiermodelnamedefault defaultoutput classifiermodelsentence classifiermodel buildclassifiermodelnamepooledoutput pooledoutput classifiermodelsentence printdefaultoutput pooledoutput
69726601,what is the best data structure for an emission probability table,python nlp viterbi,i would use dictionaries instead
69042028,what is the algorithm behind pairwise align in biopython,algorithm nlp biopython,the docstring of a private function in the code indicates that this is an implementation of the needlemanwunsch dynamic programming algorithm as modified by gotoh implementing affine gap penalties l of this code
68876169,what is the difference between nlpvocab and nlpvocabstrings,python nlp spacy,lennlpvocab is the number of cached lexemes which can therefore vary when you use the model on some words lennlpvocabstrings maps strings to hash values and vice versa it can give you the number of different strings for the model encorewebmd this would give you for example if you want to access the words try
68546867,meaning of outputtraining status of in stanford nlp ner,python nlp stanfordnlp namedentityrecognition,status is an exit code and nonzero exit codes mean your program failed this is not a stanford nlp convention its how all programs work on unixlinux there should be an error somewhere maybe you ran out of memory youll have to track that down to find out whats wrong
68337487,what is the correct way of encoding a large batch of documents with sentence transformerspytorch,python numpy machinelearning nlp pytorch,this line here sorts the input by text length before doing the encode i have no idea why so either comment those lines out or copy them to your code like then use the corpussorted to encode and map the output back using lengthsortedidx or just encode it one by one and you wont need to care about which output is from which text
68163759,what is the use of the bots name in python chatterbot,python nlp chatbot chatterbot,from what i have seen from their chatbotpy the constructor requires name as the only parameter i am unable to find anything in the documentation that addresses it and i can neither test it as of now but based on it appears that upon generating an answer it is used to define the persona parameter for the statement constructor upon looking into the stament constructor it seems that the persona parameter might be a string identifying who generated the statement
67788151,does adding a list of wordvec embeddings give a meaningful represenation,nlp wordvec embedding languagemodel,averaging is most typical when someone is looking for a supersimple way to turn a bagofwords into a single fixedlength vector you could try a simple sum as well but note that the key difference between the sum and average is that the average divides by the number of input vectors thus they both result in a vector thats pointing in the exact same direction just of different magnitude and the mostoftenused way of comparing such vectors cosinesimilarity is oblivious to magnitudes so for a lot of cosinesimilaritybased ways of later comparing the vectors sumvsaverage will give identical results on the other hand if youre comparing the vectors in other ways like via euclideandistances or feeding them into other classifiers sumvsaverage could make a difference similarly some might try unitlengthnormalizing all vectors before use in any comparisons after such a preuse normalization then euclideandistance smallest to largest cosinesimilarity largesttosmallest will generate identical lists of nearestneighbors averagevssum will result in different ending directions as the unitnormalization will have upped some vectors magnitudes and lowered others changing their relative contributions to the average what should you do theres no universally right answer depending on your dataset goals the ways your downstream steps use the vectors different choices might offer slight advantages in whatever final qualitydesirability evaluation you perform so its common to try a few different permutations along with varying other parameters separately the googlenews vectors were trained on news articles back around their word senses thus may not be optimal for an imagelabeling task if you have enough of your own data or can collect it training your own wordvectors might result in better results both the use of domainspecific data the ability to tune training parameters based on your own evaluations could offer benefits especially when your domain is unique or the tokens arent typical naturallanguage sentences there are other ways to create a single summary vector for a runoftokens not just arithmaticalcomboofwordvectors one thats a small variation on the wordvec algorithm often goes by the name docvec or paragraph vector it may also be worth exploring there are also ways to compare bagsoftokens leveraging wordvectors that dont collapse the bagoftokens to a single fixedlength vector st and while theyre more expensive to calculate sometimes offer better pairwise similaritydistance results than simple cosinesimilarity one such alternate comparison is called word movers distance at some point you may want to try that as well
67664837,problems understanding ndcg format in pytreceval,pythonx machinelearning nlp informationretrieval,in order to compute the ndcg you need to know what is the relevance of each document in a ranked list of results for this query this information is contained in qrels ranking means that you first need to sort retrieved documents in descending order of their score so you basically sort documents and then go rank by rank starting from the lowest rank ie the topscored document which is for each rank i you get the documents groundtruth relevance reli from qrels and then you divide this relevance by logi to get a term for this rank i you sum all these terms across all ranks and you get the discounted cumulative gain dcg for this query therefore pytreceval internally needs to create a sorted list from the dictionary mapping from doc id to score in order to get the ranks this is why the order of the documentscore pairs in the dictionary you pass as an input doesnt matter now as an additional detail to get the ndcg ie normalized dcg you divide the dcg by the ideal dcg which is the maximum dcg achievable by any model to get the idcg you sort the groundtruth as opposed to retrieved documents in descending order of their relevance score and compute the dcg again to get the groundtruth relevance scores you need qrels
67412925,what is the difference between lentokenizer and tokenizervocabsize,nlp tokenize huggingfacetransformers huggingfacetokenizers,from the huggingface docs if you search for the method vocabsize you can see in the docstring that it returns the size excluding the added tokens size of the base vocabulary without the added tokens and then by also calling the len method on the tokenizer object which itself calls the len method so you can clearly see that the former returns the size excluding the added tokens and the later includes the added tokens as it is essentially the former vocabsize plus the lenaddedtokensencoder
67352831,tensorflow and bert what are they exactly and whats the difference between them,nlp tensorflowx,tensorflow is an opensource library for machine learning that will let you build a deep learning modelarchitecture but the bert is one of the architectures itself you can build many models using tensorflow including rnn lstm and even the bert the transformers like the bert are a good choice if you just want to deploy a model on your data and you dont care about the deep learning field itself for this purpose i recommended the huggingface library that provides a straightforward way to employ a transformer model in just a few lines of code but if you want to take a deeper look at these models i will suggest you to learns about the wellknown deep learning architectures for text data like rnn lstm cnn etc and try to implement them using an ml library like tensorflow or pytorch
67292968,nlp understanding token ids,nlp,the token ids are indices in a vocabulary in your case indices in a subword vocabulary the ids themselves are not used during the training of a network rather the ids are transformed into vectors say you are inputting three words and their ids are and what is actually is given as input is three vectors say each of ndimension where each id is mapped to a unique vector these vectors could be onehot ie at the index for the token id and rest zeros or they could be pretrained embedding like glove
67282155,what is the simplest way to continue training a pretrained bert model on a specific domain,nlp textclassification bertlanguagemodel huggingfacetransformers pytorchlightning,lets clarify a couple of points first to reduce some ambiguity bert uses two pretraining objectives masked language modeling mlm and next sentence prediction you mentioned having a large unannotated dataset which you plan on using to finetune your bert model this is not how finetuning works in order to finetune your pretrained model you would need an annotated dataset ie document class pair for sequence classification downstream task so what can you do first extend your general domain tokenizer with your unannotated dataset consisting of domainspecific vocabulary then using this extended tokenizer you can continue pretraining on mlm andor nsp objectives to modify your word embeddings finally finetune your model using an annotated dataset
67097467,what is language modeling head in bertformaskedlm,nlp bertlanguagemodel huggingfacetransformers languagemodel,the bertformaskedlm as you have understood correctly uses a language modelinglm head generally as well as in this case lm head is a linear layer having input dimension of hidden state for bertbase it will be and output dimension of vocabulary size thus it maps to hidden state output of bert model to a specific token in the vocabulary the loss is calculated based on the scores obtained of a given token with respect to the target token
67096547,how to explain gensim wordvec output,python nlp gensim wordvec wordembedding,the wordvec algorithm is only useful valuable with large amounts of training data where every word of interest has a variety of realistic subtlycontrasting usage examples a toysized dataset wont show its value its always a bad idea to set mincount and its nonsensical to try to train dimensional wordvectors from a corpus of only words unique words and most of the words having the exact same neighbors try it on a more realistic dataset tensofthousands of unique words all with multiple usage examples and youll see more intuitivelycorrect similarity results
67021291,using nltk how to search for concepts in a text,pythonx text nlp nltk,i reorganised your code a little bit i assumed you had file per concept words and that prepstxt only contained the courage words but not the others i hope it is easy to understand import nltk from nltkcorpus import plaintextcorpusreader from nltk import wordtokenize from nltk import freqdist load the courage vocabulary with openprepstxt encodingutf as file content fileread preps refer to the file that has the list of words couragewords contentsplitn this is a list of words load freedom and development words in the same fashion load the corpus corpusroot usersmuhsamyfolderconcepts this is where the texts i want to study are located corpus plaintextcorpusreadercorpusroot count the number of word in the whole corpus that are also in the courage vocabulry couragefreq lenw for w in corpuswords if w in couragewords printcorpus contains courage wordsformatcouragefreq for each file in the corpus for fileid in corpusfileids count the number of word in the file that are also in courage word filefreq lenw for w in corpuswordsfileid if w in couragewords printfileid filefreq or better load concept vocabulary in different files in a python dictionary conceptvoc for filepath in couragetxt freedomtxt developmenttxt conceptname filepathreplacetxt with openfilepath as f voc freadsplitn conceptvocconceptname voc load concept vocabulary in a csv file each column is one vocabulary the first line is the name df pdreadcsvtodictcsv conveptvoc dftodictcolumns conceptvoccourage returns the list of courage words and then for each concept compute the frequency as before for concept in conceptvoc voc conceptvocconcept corpusfreq lenw for w in corpuswords if w in voc printconcept corpusfreq
66935911,understanding the output of lstm predictions,machinelearning nlp pytorch lstm textprocessing,the lstm function in pytorch returns not just the output of the last timestep but all outputs instead this is useful in some cases so in your example you seem to have exactly timesteps the amount of timesteps is just your sequence length but since you are doing classification you just care about the last output you can normally get it like this outputs selflstmembeddings shape batchsize x x output outputs shape batchsize x x
66608244,what is the best approach to measure a similarity between texts in multiple languages in python,python nlp multilingual similarity wordembedding,you could try milvus that adopted faiss to search similar vectors its easy to be installed with docker in windows os
66606563,use shap values to explain logisticregression classification,python scikitlearn nlp logisticregression shap,i was unable to find a solution with shap but i found a solution using lime the following code displays a very similar output where its easy to see how the model made its prediction and how much certain words contributed
66479607,i dont understand what is the purpose of text in spacy code,nlp spacy,note that doc is a token not a string using text is returning the string that your token object holds the token can have plenty of other attributes too when token objects are printed the representation is just the textsee the source code thats why they look the same when you print firsttoken and firsttokentext power user stuff skip if you want if you want to see why the behavior is different between token and string objects try concatenating two tokens with or comparing them for equality they dont have eq implemented so the comparison is just based on the tokens address in memory
66405896,tfidfidf what is meaning of this in the code,machinelearning scikitlearn nlp,
66350670,understanding tfidfvectorizer output,python scikitlearn nlp tfidf tfidfvectorizer,there are several issues with your calculations first there are multiple conventions on how to calculate tf see the wikipedia entry scikitlearn does not normalize it with the document length from the user guide the term frequency the number of times a term occurs in a given document so here tfapple document and not second regarding the idf definition from the docs if smoothidftrue the default the constant is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once which prevents zero divisions idft log n dft so here we will have hence third with the default setting norml there is an extra normalization taking place from the docs again normalization is c cosine when norml n none when normnone explicitly removing this extra normalization from your example ie gives for apple ie as already calculated manually for the details of how exactly the normalization affects the calculations when norml the default setting see the tfidf term weighting section of the user guide by their own admission the tfidfs computed in scikitlearns tfidftransformer and tfidfvectorizer differ slightly from the standard textbook notation
66279882,how does masking work in the scaleddotproductattention of language understanding transformers,tensorflow deeplearning neuralnetwork nlp,ok so the value e resembles negative infinity therefor the softmax function will produce a probability of to such elements and will be ignored when calculating the attention values
65645289,nlp limetextexplainer for bigrams,python nlp textclassification lime,at least i got an answer to the second question those are probabilities but not in the way i thought for instance predicted probability for class x is if now the word recognit would be removed from the underlying corpus the total predicted probability for the predicted class would shrink by probability class x equals then for detailed information about lime i highly reccomend why should i trust you explaining the predictions of any classifier riberio etal
64866067,understanding the role of the function buildvocab in docvec,nlp datascience gensim textclassification docvec,the docvec model needs to know several things about the training corpus before it is fully allocated initialized first foremost the model needs to know the words present their frequencies a working vocabulary so that it can determine the words that will remain after the mincount floor is applied and allocateinitialize wordvectors internal model structures for the relevant words the wordfrequencies will also be used to influence the random sampling of negativewordexamples for the default negativesampling mode and the downsampling of veryfrequent words per the sample parameter additionally the model needs to know the rough size of the overall training set in order to gradually decrement the internal alpha learningrate over the course of each epoch and give meaningful progressestimates in logging output at the end of buildvocab all memoryobjects needed for the model have been created per the needs of the underlying algorithm all vectors will have been initialized to lowmagnitude random vectors to ready the model for training it essentially wont use any more memory internally through training also after buildvocab the vocabulary is frozen any words presented during training or later inference that arent already in the model will be ignored
64805354,how to find singular in the plural when some letters change what is the best approach,javascript nlp diacritics,i once had to build a text processor that parsed many languages including very casual to very formal one of the things to identify was if certain words were related like a noun in the title which was related to a list of things sometimes labeled with a plural form iirc of singular plural word forms across all languages we supported had a levenshtein distance of less than or eventually several dictionaries were added to improve accuracy because distance alone produced many false positives another interesting find was that the longer the words the more likely a distance of or fewer meant a relationship in meaning heres an example of the libraries we used const fastlevenshtein requirefastlevenshtein consolelogdeburred distances consolelogscore fastlevenshteingetschliefcher schliefach consolelogscore fastlevenshteingetblumtach blumtcher consolelogscore fastlevenshteingetschliefcher schliessfaech consolelogscore fastlevenshteingetnotit schliessfaech consolelogscore fastlevenshteingetnotit schiesse additional strategy for dealing with other various languages deburr the strings to omit diacritics before checking the distance const deburr requirelodashdeburr consolelogdeburred distances consolelogscore deburrfastlevenshteingetschliefcher schliefach consolelogscore deburrfastlevenshteingetblumtach blumtcher consolelogscore deburrfastlevenshteingetschliefcher schliessfaech same in this case but helpful in other similar use cases
64675028,what are the cases where nltks wordtokenize differs from strsplit,python nlp nltk tokenize,wordtokenize documentation the nltk tokenize package documentation
63651263,what is the state of gpt for text classification in spanish,nlp textclassification,gpt is only available via an api and only to people who apply for the access the model is too big to run it locally on any reasonable hardware and finetuning is thus hardly an option given how well gpt works machine translation my guess is that it will work reasonably well for spanish by default however if your task is text classification you can do a much better job when using a pretrained bertlike model hugginfaces transformers already have several models for spanish
63410175,what is happening under the hood of fasttext supervised learning model,python machinelearning nlp fasttext,its still learning wordvectors for the input text but then averaging them all together a bit like an infinitewindow cbow mode then using that to predict the the labels as if the labels were the wordvecstyle predictedword
63216550,positional embedding in the transformer model does it change the words meaning,nlp transformermodel,wordvec and transformer treat tokens completely different wordvec is contextfree which means bank is always some fixed vector from the wordvec matrix in other words the vector of bank doesnt depend on the tokens position in the sentence on the other hand transformer as a input receives the tokes embeddings and positional embeddings to add a sense of position to the tokens otherwise it relates to the text as a bagofwords and not as a sequence
63096909,how to interpret output from gensims wordvec most similar method and understand how its coming up with the output values,python nlp gensim wordvec wordembedding,wordvec is going to give you ndimensional vectors that represent each of the diseases based on their cooccurrence this means that you are representing each of the symptoms as a vector one row now you can represent each row in the data by taking the average of the wordvec such as now you have a length feature vector and a class for each row in your dataset next you can treat it like any other machine learning problem if you want to predict the disease then just use a classification model after traintest split that way you can validate the data using cosine similarity to the wordvec vectors only yields similar symptoms it will not let you build a disease recommendation model because then you will be recommending a symptom based on other similar symptoms
63007807,equate strings based on meaning,python nlp,as you say packages like fuzzywuzzy or difflib will be limited because they compute similarities based on the spelling of the strings not on their meaning you could use word embeddings word embeddings are vector representations of the words computed in a way that allows to represent their meaning to a certain extend there are different methods for generating word embeddings but the most common one is to train a neural network on one or a set of wordlevel nlp tasks and use the penultimate layer as a representation of the word this way the final representation of the word is supposed to have accumulated enough information to complete the task and this information can be interpreted as an approximation for the meaning of the word i recommend that you read a bit about wordvec which is the method that made word embeddings popular as it is simple to understand but representative for what word embeddings are here is a good introductory article the similarity between two words can be computed then using usually the cosine distance between their vector representations of course you dont need to train word embeddings yourself as there exist plenty of pretrained vectors available glove wordvec fasttext spacy the choice of which embedding you will use depend on the observed performance and your understanding of how fit they are for the task you want to perform here is an example with spacys word vectors where the sentence vector is computed by averaging the word vectors this will print as you can see the similarity with word vectors reflects better the similarity in the meaning of the documents however this is really just a starting point as there can be plenty of caveats here is a list of some of the things you should watch out for word and document vectors do not represent the meaning of the word or document per se they are a way to approximate it that implies that they will hit a limitation at some point and you cannot take for granted that they will allow you to differentiate all nuances of the language what we expect to be the similarity in meaning between two wordssentences varies according to the task we have as an example what would be the ideal similarity between maximum temperature and minimum temperature high because they refer to an extreme state of the same concept or low because they refer to opposite states of the same concept with word embeddings you will usually get a high similarity for these sentences because as maximum and minimum often appear in the same contexts the two words will have similar vectors in the example given is still not a very high similarity this comes probably from the usage of abbreviated words in the example depending on how word embeddings have been generated they might not handle abbreviation well in a general manner it is better to have syntactically and grammatically correct inputs to nlp algorithms depending on how your dataset looks like and your knowledge of it doing some cleaning beforehand can be very helpful here is an example with grammatically correct sentences that highlights the similarity in meaning better anyway word embeddings are probably what you are looking for but you need to take the time to learn about them i would recommend that you read about word and sentence and document embeddings and that you play a bit around with different pretrained vectors to get a better understanding of how they can be used for the task you have
62948595,what is use case of tokenization and lemmatization in nlp when we have countvectorizer and tfidfvectorizer,machinelearning scikitlearn nlp lemmatization tfidfvectorizer,tokenization and lematization are the basic building blocks in nlp using tokenization you break the string into tokenswords tokenization depends on the language of the text how the text is formed etc for example tokenizing a chinese text is different from that of english and is different from a tweet so there exist different kinds of tokenizers countvectorizer and tfidfvectorizer are used to vectorize a block of text which rely on the words with in the text so they need a mechanism to tokenize the words and they support the mechanism to send in our tokenizers via a callable methods passed as argument if we dont pass in any tokenizer it uses naive way of splitting over spaces see the docs of countvectorizer tokenizer callable defaultnone override the string tokenization step while preserving the preprocessing and ngrams generation steps only applies if analyzer word so they allow us to pass in our own tokenizers same applies for leamatization
62895997,nlp what is exactly a grammar dependence tag attr,pythonx nlp spacy dependencyparsing,attribute is a label of dependency relation that seems to be obsolete now see page of this manual this dependency relation seems to be used to link the copula verb with its np argument in attributive constructs for example daniel is professor she is smart consult page of interestingly the current annotation guidelines for universal dependencies have attributive constructs annotated quite differently there is a cop label involved and surprisingly the attributive npadjp is linked directly to its subject so these labels are likely to be changed in the future i believe
62669885,what is negative sampling method use sigmoid or softmax,machinelearning nlp wordvec,it can be called a small abuse of notation on the authors part but its totally fine sometimes people use the softmax and sigmoid interchangeably however in this case it is indeed a sigmoid function because of binary class problem
62487778,module error in code cannot figure out what is wrong,python nlp,you seem to be using predefined module as a variable name the problem here is this will import tqdm module you have to import it as follows
62400205,what is the correct way of using rasas api rasacoreprocessor encountered an exception,python nlp pythonrequests rasacore rasa,i end up figuring out that this is how you request the end point the documentation should be clearer
62037709,i want to collect counts over the tokens and see what is the most frequent token my code that i written does not work so i commented my code,python nlp spacy,the code creates a list of lists of tokens what you want is a list if tokens try
62036185,how to find and remove invalid meaningless text in python,python pandas nlp nltk corpus,you can compare values to some dictonary here from ntlk and if not match remove values but still is possible some values are removed like mom if not exist in dictionary ntlk
62035766,unable to understand the output shapes in lstm network below,python tensorflow keras neuralnetwork nlp,i believe that the explanation for this result is the bidirectional nature of the lstm layers in which you have added to your neural network the size of the layer you have added is doubled for the layer to also learn the sequence backwards i hope you can understand if you have any questions you can ask me in the comments
61876623,meaning of high sparsity matrix from sklearn countvectorizer,scikitlearn nlp countvectorizer,in fact or even of zeros does not mean high sparsity so in your case it is safe enough to just ignore the fact of sparsity and treat your matrix as if it was a dense one really high sparsity is something like of zeros it occurs in problems like recommender systems when there are thousands or even millions of items but each user has interacted only with a few of them another case is when we have very short texts eg tweets or dialogue turns and a very large vocabulary maybe even a multilingual one if the feature matrix has really high sparsity it means that if you want to store your matrix efficiently or make fast calculations with it you may want to use an algorithm that explicitly supports scipys sparse matrices the feature space is probably highdimensional and probably some features are highly correlated with each other therefore you might find dimensionality reduction useful to make your model more tractable and generalize better you can use matrix decomposition techniques eg pca or a neural embedding layer to implement this dimensionality reduction or maybe you can use pretrained word embeddings and somehow aggregate them to represent your document in general the optimal way to represent your document depends on the ultimate problem you are trying to solve for some problems eg text classification with a large training set a highdimensional sparse representation might be optimal for others eg similarity of small texts or text classification with a small labeled training set a lowdimensional dense representation would be better
61448908,how to extract sentences which has similar meaningintent compared against a example list of sentences,pythonx nlp gensim docvec sentencesimilarity,there could be multiple ways for doing this in multiple steps calculating sentence vectors a using pretrained word embeddingsglove wordvec fasttext etc and calculating word embeddings for each word and then average it across words of the sentence to calculate the sentence embedding b use universal sentence encoder to get the sentence embeddings calculate similarity match a calculate the distance between between the target and all other n sentences using euclidean or cosine or any other distance metric that works best for your problem b train a knn model with n sentence vectors you have and apply knn prediction with the target sentence to get k most similar sentences to get even better results you can use deep learning based techniques and sota architectures such as transformers and the architectures built over it you can checkout this repository which solves your task using transformers also to play with different architectures and other nlp tasks you can checkout the hugging face repository
61446106,what is the difference between parsing and part of speech tagging,parsing nlp stanfordnlp partofspeech,they are two distinct procedures pos tagging each token gets assigned a label which reflects its word class parsing each sentence gets assigned a structure often a tree which reflects how its components are related to each other pos tagging takes a tokenised sequence of words and returns a list of annotated tokens where each token has a word class label this is often disambiguated by looking at the context surrounding the token there is also chunking which groups tokens into related groups such as noun phrases chunks are nonoverlapping sequences parsing commonly results in a parse tree for a sentence often there can be many possible trees in case of ambiguous sentences pos tagging is usually a preparatory step in parsing as a parser typically operates on word classes though there are some parsing algorithms that work with tokens directly or a mixture of tags and tokens
61280748,meaning of inqsize and outqsize in gensim wordvec log files,python nlp gensim,inqsize and outqsize are the lengths of two internal queues used by the code to send work to the workerthreads and receive results their names in the source code are jobqueue and progressqueue but you can also find that and more about them by searching through the source code for the lines that print inqsize and outqsize in general they are a sufficiently internal detail that most users wont need to care about their values unless debugging some atypical performance issues in some cases it could add a little more understanding to how different choices of corpuspreparation workers value or other parameters are affecting througput but in general such optimization can just involve trying lots of different values to see which in practice achieves the best throughput without caring about those internal queue sizes
61165068,what is the meaning of heads in spacy training data,python json nlp nltk spacy,in your example the task is to reconstruct a tree of syntactic dependencies this tree shows for each word the corresponding head word to which it is attached and the type of attachment one particular format in which such trees are described is called conllu in your example eg great word if we count from is attached to wifi word and great is a quality of wifi therefore the th entry of heads equals and the th entry of deps equals quality
61134275,difficulty in understanding the tokenizer used in roberta model,nlp pytorch huggingfacetransformers bertlanguagemodel,this question is extremely broad so im trying to give an answer that focuses on the main problem at hand if you feel the need to have other questions answered please open another question focusing on one question at a time see the helpontopic rules for stackoverflow essentially as youve correctly identified bpe is central to any tokenization in modern deep networks i highly recommend you to read the original bpe paper by sennrich et al in which they also highlight a bit more of the history of bpes in any case the tokenizers for any of the huggingface models are pretrained meaning that they are usually generated from the training set of the algorithm beforehand common implementations such as sentencepiece also give a bit better understanding of it but essentially the task is framed as a constrained optimization problem where you specify a maximum number of k allowed vocabulary words the constraint and the algorithm tries to then keep as many words intact without exceeding k if there are not enough words to cover the whole vocabulary smaller units are used to approximate the vocabulary which results in the splits observed in the example you gave roberta uses a variant called bytelevel bpe the best explanation is probably given in this study by wang et al the main benefit is that it results in a smaller vocabulary while maintaining the quality of splits from what i understand the second part of your question is easier to explain while bert highlights the merging of two subsequent tokens with robertas tokenizer instead highlights the start of a new token with a specific unicode character in this case u the g with a dot the best reason i could find for this was this thread which argues that it basically avoids the use of whitespaces in training
60847291,confusion in understanding the output of bertfortokenclassification class from transformers library,nlp pytorch huggingfacetransformers bertlanguagemodel,if you check the source code specifically bertencoder you can see that the returned states are initialized as an empty tuple and then simply appended per iteration of each layer the final layer is appended as the last element after this loop see here so we can safely assume that hiddenstates is the final vectors
60537187,starspace what is the interpretation of the labeldoc fileformat,facebook nlp wordembedding,the way starspace uses the labels highly depends on the trainmode you are using the labeldoc format is useful when you go for a trainmode that just relies on labels trainmode through where it may be the same thing to use a fasttext format specifying the label prefix but some trainmodes benefit from labeldoc format ie trainmode or to use a whole sentence as a label element for that trainmode so to clarify that if you are performing a text classification taskas explained in this example labeldoc wouldnt have any input recognized but on the other hand as you stated using fasttext format will breakdown all nonlabeled text as input and learn to predict the label tags and an example for labeldoc format would be developing a content based recommender system as explained in this example every tab separated sentence is used at lhs or rhs during training time but if you go on a collaborative approach the content of the articles or wherever you sentences come from is not taken in account it can be trained either with fasttext specifying the label prefix or labeldoc file format as labels are picked randomly during training time for lhs or rhs this second example is explained here
60382793,what are the inputs to the transformer encoder and decoder in bert,python deeplearning nlp huggingfacetransformers,ah but you see bert does not include a transformer decoder it is only the encoder part with a classifier added on top for masked word prediction the classifier acts as a decoder of sorts trying to reconstruct the true identities of the masked words classifying nonmasked is not included in the classification task and does not effect loss bert is also trained on predicting whether a pair of sentences really does precedes one another or not i do not remember how the two losses are weighted i hope this draws a clearer picture
59991499,how to classify derived words that share meaning as the same tokens,python nlp nltk textmining,i propose a two steps approach first find synonyms by comparing word embeddings only nonstopwords this should remove similar written words which mean something else such as gasolineand gaseous then check if synonyms share some of their stem essentially if gas is in gasolin and the other way around this shall suffice because you only compare your synonyms then you can count your synonym candidates based on their appearances in the text note i chose the threshold for synonyms with by chance you would probably test which threshold suits your task also my code is just a quick and dirty example this could be done a lot cleaner
59877385,what is the difference between sentence encodings and contextualized word embeddings,nlp wordembedding elmo bertlanguagemodel,a contextualized word embeding is a vector representing a word in a special context the traditional word embeddings such as wordvec and glove generate one vector for each word whereas a contextualized word embedding generates a vector for a word depending on the context consider the sentences the duck is swimmingand you shall duck when someone shoots at you with traditional word embeddings the word vector for duckwould be the same in both sentences whereas it should be a different one in the contextualized case while word embeddings encode words into a vector representation there is also the question on how to represent a whole sentence in a way a computer can easily work with these sentence encodings can embedd a whole sentence as one vector docvec for example which generate a vector for a sentence but also bert generates a representation for the whole sentence the clstoken so in short a conextualized word embedding represents a word in a context whereas a sentence encoding represents a whole sentence
59347811,what are some examples of the partofspeech tag listitemmarker,nlp spacy partofspeech,lists of items with periods is the way ive seen ls items heres an example import spacy nlpspacyloadencorewebsm doc nlpthe system shall reprogram software reprogram data readwrite to memory lockunlock flash memory clear memory range check printn printtoken attributes n tokentext tokenpos tokentag tokendep tokenorth for token in doc print the text and the predicted partofspeech tag printformattokentext tokenpos tokentag tokendep tokenorth outputs
59285376,what is the process to create an faq bot using spacy,pythonx machinelearning nlp chatbot namedentityrecognition,one way to achieve your faq bot is to transform the problem into a classification problem you have questions and the answers can be the labels i suppose that you always have multiple training questions which map to the same answer you can encode each answer in order to get smaller labels for instance you can map the text of the answer to an id then you can use your training data the questions and your labels the encoded answers and feed a classifier after the training your classifier can predict the label of unseen questions of course this is a supervised approach so you will need to extract features from your training sentences the questions in this case you can use as a feature the bagofword representations and even include the named entities an example of how to do text classification in spacy is available here
59261462,natural language processing techniques for understanding contextual words,machinelearning deeplearning nlp wordembedding linguistics,what youre trying to do is called word sense disambiguation its been a subject of research for many years and while probably not the most popular problem it remains a topic of active research even now just picking the most common sense of a word is a strong baseline word embeddings may be useful but their use is orthogonal to what youre trying to do here heres a bit of example code from pywsd a python library with implementations of some classical techniques the methods are mostly kind of old and i cant speak for their quality but its a good starting point at least word senses are usually going to come from wordnet
58891402,how to identify words with the same meaning in order to reduce number of tagscategoriesclasses in a dataset,nlp dataset spacy,i dont know that there is a standard solution but i can suggest a couple of approaches ranked by increasing depth of knowledge or going from the surface form to the meaning string matching lemmatisationstemming word embedding vector distance string matching is based on the calculating the difference between strings as a measure of how many characters they share or how many editing steps it takes to transform one into the other levenshtein distance is one of the most common ones however depending on the size of your data it might be a bit inefficient to use this is a really cool approach to find most similar strings in a large data set however it might not be the most suitable one for your particular data set as your similarities seem more semantic and less bound to the surface form of the words lemmatisationstemming goes beyond the surface by analysing the words apart based on their morphology in your example gaming and games both have the same stem game so you could base your similarity measure on matching stems this can be better than pure string matching as you can see that go and went are related word embeddings go beyond the surface form by encoding meaning as the context in which words appear and as such might find a semantic similarity between health and fitness that is not apparent from the surface at all the similarity is measured as the cosine distancesimilarity between two word vectors which is basically the angle between the two vectors it seems to me that the third approach might be most suitable for your data
58876392,what is the difference between token and span a slice from a doc in spacy,python nlp token spacy,token vs span from spacys documentation a token represents a single word punctuation symbol whitespace etc from a document while a span is a slice from the document in other words a span is an ordered sequence of tokens why spans spacys matcher gives a spanlevel information rather than tokenlevel because it allows a sequence of tokens to be matched in the same way that a span can be composed of just token this isnt necessarily the case consider the following example where we match for the token hello on its own the token world on its own and the span composed of the tokens hello world import spacy nlp spacyloaden from spacymatcher import matcher matcher matchernlpvocab matcheradd none lower hello matcheradd none lower world matcheradd none lower hello lower world for hello world all of these patterns match document nlphello world tokenidx token for token in document hello world matcherdocument however the rd pattern doesnt match for hello world since hello world arent contiguous tokens because of the token so they dont form a span document nlphello world tokenidx token for token in document hello world matcherdocument accessing tokens from spans despite this you should be able to get tokenlevel information from the span by iterating over the span the same way you could iterate over tokens in a doc document nlphello world span typespan hello world tokenidx token typetoken for token in span hello world
58832191,understanding shapes of keras layers,python machinelearning deeplearning nlp convneuralnetwork,please see the answers below input inputlayer none is the total number of features that is input neurons per data point is the total number of documents or data points yes modelfittrainxtrainxtrainx arraytrainlabels epochs batchsize says that you want the network to train times for epochs on the whole training dataset in batches of size this means that every data points the backpropagation algorithm will be launched and the weights will update this will happen times and will be called an epoch is the number of neurons in the first layer embedding embedding none embedding layer is as featureswords and each feature is a vector of dimension is the size of the input numbers of neurons in the previous layer and is the size length of the embedding vector the number of parameters here is vocabularysize as for each v in vocabulary you need to train parameters embedding layer is in fact a matrix built with vocabularysize vectors of size where each row represents a vector representation of each word from the vocabulary convd convd none convd is of kernel size is it filter which is used times then how the dimension became none with parameters becomes because of the size of kernel imagine the following input of size to simplify with kernel of size look the kernel cant move any further to the right so for the input size and kernel size the output shape would be in general for input shape of n and kernel shape of k the output shape would be n k so for n k the result is the amount of the parameters is equal to because the number of parameters is equal to outputchannels inputchannels windowsize in your case its maxpoolingd maxpoolingd none with maxpoolingdpoolsize how the dimension became none the maxpooling takes every two consecutive numbers and replaces them with a max of them so you end up with originalsizepoolsize values flatten flatten none this is just multiplication of yes this is just a multiplication of and its because the flatten operation does the following so it takes all values from all dimensions and put it into a onedimensional vector does every epoch trains data points at once no it takes them in batches of as pointed out in the first answer each epoch takes data points in a random order in batches of data points an epoch is a term which means a period in time after which well start reading data again edit i will clarify the place where d convolutional layers are applied to embedding layers the output of the embedding layers you should interpret as a vector of width and channels similarly to d images where you have an rgb three channels at the input its shape is width height when you apply a convolutional layer built of filters filter size is irrelevant the convolution operation is applied simultaneously to all channels and the output shape will be newwidth newheight notice the output shape is the same as the number of filters back to your example treat the output shape from the embedding layer as width channels so then the d convolutional layer with filters and kernel size equals to is applied to vector and depth as result you will get the output of shape
58484403,how to find the semantic meaning similarity of two string in python,python machinelearning nlp,it is something that is really hard to do it is also difficult to know that do you mean as accurate semantic similarity between two phrases you need to find a good metric to do so anyway if you a have a limited context you dont have to do a general purpose semantic similiraty calculator a very basic approach could be to build a text classifier with machine learning in which you define the principal classes that you want to use for example for your example phrases you could have the two text classes asking about hyperthreading asking about food than you train your model with a lot of phrases and your model output probabilities for your example phrases as such what are the types of hyper threading asking about hyperthreading asking about food is there any categories in hyper threading asking about hyperthreading asking about food both phrases are classified as asking about hyperthreading because they have the higher score in these classes and then one can assume that they are similar one could use also the probabilities scores to do something more sofisticated using score differences etc
58334235,what is currently the best way to add a custom dictionary to a neural machine translator that uses the transformer architecture,neuralnetwork nlp transformermodel machinetranslation seqseq,i am afraid you cannot easily do that you cannot easily add new words to the vocabulary because you dont know what embedding it would get during training you can try to remove some words or alternatively you can manually change the bias in the final softmax layer to prevent some words from appearing in the translation anything else would be pretty difficult to do what you want to do is called domain adaptation to get an idea of how domain adaptation is usually done you can have a look at a survey paper the most commonly used approaches are probably model finetuning or ensembling with a language model if you want to have parallel data in your domain you can try to finetune your model on that parallel data with simple sgd small learning rate if you only have monolingual data in the target language you train a language model on that data during the decoding you can mix the probabilities from the domainspecific language and the translation model unfortunately i dont know of any tool that could do this out of the box
58122336,what is the best method to find the text under a heading,python regex pythonx nlp nltk,these regex can work for you you would just have to take care of checking the different capture groups check them here the same would apply to age
58094043,stop words changed negative review to positive ones what is a good way to remove stop words in text summarization process,pythonx nlp stopwords,removing words from text inherently changes the vector representations which i assume your summary application is using the best thing to do would be to create your own custom stop words list also keep in mind that for some texts the change in meaning will be undesired but that these may be outliers
57987235,what are the means to compute relevance score between questionanswer pairs,nlp informationretrieval nlpquestionanswering,without deep learning could we invent an algorithm like bm to compute the relevance score of questionanswer pair yes there are many ways to do it to make your question a little more directed lets answer which are the possible ways to compute the relevance of questionanswer pair without using question answering some examples and explanations tfidf that you mentioned is actually a feature extraction technique with it you retrieve which words from the context are presentimportant for each document with this you can compare two similarly worded thats what bm does another technique is to use pagerank which is the algorithm used by google you can actually attempt to replicate it since it is not too complex one other way is to use graphs to do it i did it in my masters research and you can read my dissertation here aside from that id advise you to check on this papers for other examples of questionanswering you can get to questionanswer matching easily if you understand the concepts and also keep checking acl state of the art question answering techniques for the most updated results and techniques
57848435,text classification what can you do vs what are your capabilities,nlp classification stanfordnlp textclassification azurelanguageunderstanding,what you are trying to solve is called semantic textual similarity and is a known and well studied field there are many different ways to solve this even if your data is tagged or not for example google has published the universal sentence encoder code example which is intended to tell if two sentences are similar like in your case another example would be any solution you can find in quora question pairs kaggle competition there are also datasets for this problem for example you can look for semeval sts sts for semantic textual similarity or the paws dataset
57632084,what is the correct way to use ohe lookup table for a pytorch rnn,python nlp pytorch lstm,the method you are looking for is torchnnfunctionalonehot it was added to pytorch later so its hard to find when you google for it
57523387,what are the ways to calculate polarity of a sentence when using supervised learning algorithms,machinelearning nlp nltk logisticregression,predictproba gives you a probability score if your case is a binary classification case then you can set a threshold say or you can find the best optimal threshold say p then veeve polaritybased on the data but thats a different case altogether for calculating the best threshold curve see f score or roc
57370524,meaning of drop in spacy custom ner model training,python nlp spacy namedentityrecognition,according to the documentation here the spacy entity recognizer is a neural network that should implement the thincneuralmodel api the drop argument that you are talking about is something called dropout rate which is a way to optimize a neural network the recommended value is based on my experience which means that about of the neurons used in this model will be dropped randomly during training
57282671,wordsentence similarity what is the best approach,python nlp,i have found two great solutions by using cosine similarity and levenshtein distance im my case cosine similarity worked better because i easily found part of the brand name into the text so getting a score of of accuracy matrix replacing levenshtein was also good but i good some errors due to very similar words in the dataset
57135347,what is the the parent word on which the currentword depend,nlp spacy,as ongenz said head is the solution
56888321,what are the difference between textblob and nltk classifiers,nlp nltk,there is absolutely no difference in implementation because textblobs classifiers are literally just a wrapper around nltk classifiers this is very simple to see from the textblob source code for example textblobclassifiersnaivebayesclassifier wraps nltkclassifynaivebayesclassifier and the first line of its docstring is a classifier based on the naive bayes algorithm as implemented in nltk
56845015,how to remove meaningless words from corpus,r text nlp datacleaning,i would do it as following tokenstoremove could just be also an english dictionary and then instead of setdiff you could just use intersect
56821101,can someone explain me what is the meaning of all the code inside these parentheses regexptokenizerrws,python nlp nltk,heres a great tool for interpreting regex my response is directly excerpted from this page this tool is a great playground for modifying your regex to see how it behaves differently in realtime rws w matches any word character equal to azaz quantifier matches between one and unlimited times as many times as possible giving back as needed asserts position at the end of a line match a single character present in the list below quantifier matches between one and unlimited times as many times as possible giving back as needed greedy a single character in the range between index and index case sensitive s matches any nonwhitespace character equal to rntfv quantifier matches between one and unlimited times as many times as possible giving back as needed greedy matches the character literally case sensitive global pattern flags g modifier global all matches dont return after first match m modifier multi line causes and to match the beginend of each line not only beginend of string
56732102,what are some common ways to get sentence vector from corresponding word vectors,nlp wordvec,sentence representations can simply be the columnwise mean of all the word vectors in your sentence there are also implementation of this like docvec where a document is just a collection of words like a sentence or paragraph
56641691,what are the purposes of each step in trainevaluatepredict in tensorflow,tensorflow machinelearning nlp,training evaluation and prediction are the three main steps of training a model basically in any ml framework and to move a model from researchdevelopment to production training a suitable ml architecture is selected based on the problem which needs to be solved hyperparameter optimization is carried out to finetune the model the model is then trained on the data for a certain number of epochs metrics such as loss accuracy mse are monitored evaluation we need to move the model to production the model in the production stage will only make inferences and hence we require the best model possible so in order to evaluate or test the model based on some predefined levels the evaluation phase is carried out evaluation is mostly carried out on the data which is a subset of the original dataset training and evaluations splits are made while preprocessing the data metrics are calculated in order to check the performance of the model on the evaluation dataset the evaluation data has been never seen by the model as it is not trained on it hence the models best performance is expected here prediction after the testing of the model we can move it to production in the production phase models only make an inference predictions on the data given to them no training takes place here even after a thorough examination the model tends to make mispredictions hence in the production stage we can receive interactive feedback from the users about the performance of the model now but what is the purpose of the evaluation step what is it supposed to do how is that different from the prediction phase evaluation is to make the model better for most cases through which it will come across predictions are made to check for other problems which are not related to performance
56522664,is there a way to use stanfordnlppostagger in a net project in uwp if not what are the alternatives,uwp nlp stanfordnlp,try upgrading your uwp project to target at least sdk fall creators update this way the library could be referenced unfortunately it means you will not be able to support windows mobile rightclick your uwp project in solution explorer and select properties there you select the min and target versions to at least
56415464,what are document and corpus in tfidf,machinelearning nlp vectorization tfidf tfidfvectorizer,in your particular case if the sentences are unrelated call each sentence a document in some more detail tf means a term is frequent in the current sample to avoid the term document df indicates that a term is frequent in every sample the quotient tfdf then returns a high number for terms which are rare in the entire collection suggesting they are significant and a low number for terms which are common
56337615,what is the best way to do french text analysis in python,python nlp,spacy library and treetagger tool that you can use through treetaggerwrapper library have good french support example using spacy prints treetagger is more difficult to install but this can help you and here is the documentation of the python wrapper
56075919,understanding embedding vectors dimension,machinelearning neuralnetwork deeplearning nlp recurrentneuralnetwork,these word embeddings also called distributed word embedding is based on you know a word by the company it keeps as quoted by john rupert firth so we know the meaning of a word by its context you can think of each scalar in the vector of a word represents its strength for a concept this slide from prof pawan goyal explains it all so you want good vector size to capture decent amount of concepts but you do not want a too huge vector because it will then become the bottleneck in training of models where these embeddings are used also the vector size is mostly fixed as most do not train their own embedding but rather use openly available embeddings as they are trained for many hours on huge data so using them will force us to use an embedding layers with dimensions as given by the openly available embedding you are using wordvec glove etc distributed word embeddings is a major milestone in the area of deep learning in nlp they give better accuracy as compared of tfidf based embeddings
55923298,understanding gensim model inference output,nlp gensim,a wordvec model learns a vector embedding for each word in the vocabulary which is created from the corpus given for the model embedding size is a hyper parameter hence it is users choice to know more about the wordvec or vector representation of words read here when you execute modelfirst it returns the embedding of the word first which by default will have dimensions each values does not have any specific meaning into it but as a complete vector it holds the information about a particular word
55657802,what are some of the data preparation steps or techniques one needs to follow when dealing with multilingual data,nlp wordembedding,hi chandana i hope youre doing well i would look into using the library spacy the man that created it has a youtube video in which he discusses the implementation of of nlp in other languages below you will find code that will lemmatize and remove stopwords as far as punctuation you can always set specific characters such as accent marks to ignore personally i use knime which is free and open source to do preprocessing you will have to install nlp extentions but what is nice is that they have different extensions for different languages you can install here the stop word filter since and the snowball stemmer node can be applied for spanish language make sure to select the right language in the dialog of the node unfortunately there is no part of speech tagger node for spanish so far create functions to lemmatize stem and preprocess turn beautiful beautifuly beautified into stem beauti def lemmatizestemmingtext stemmer porterstemmer return stemmerstemwordnetlemmatizerlemmatizetext posv parse docs into individual words ignoring words that are less than letters long and stopwords him her them for there ect since their is not a topic then append the tolkens into a list def preprocesstext result for token in gensimutilssimplepreprocesstext newstopwords yourstopword yourstopword if token not in gensimparsingpreprocessingstopwords and token not in newstopwords and lentoken nltkbigramstoken resultappendlemmatizestemmingtoken return result i hope this helps let me know if you have any questions
55584776,the meaning of hyperparameters in glove,nlp hyperparameters glove,verbose is a regular parameter for model training nowadays its value tells the function how much information to print while training the model usually means no intermediate information means minimal and means a lot more detail check for more details about what are printed memory im not quite sure about this but i think it has to do with the memory usage for the model training feel free to correct update windowsize yes its the context size check binary its a switch option for file output type for text file for binary and for both check
55576334,what are the stateofart algorithms for resolving words polysemyhomonymy,nlp wordnet,you can start with spacys implementation of sensevec it is based on the original sensevec paper from the abstract this paper presents a novel approach which addresses these concerns by modeling multiple embeddings for each word based on supervised disambiguation which provides a fast and accurate way for a consuming nlp model to select a sensedisambiguated embedding we demonstrate that these embeddings can disambiguate both contrastive senses such as nominal and verbal senses as well as nuanced senses such as sarcasm
55467132,what are ngrams,machinelearning nlp speechrecognition ngram,ngrams is present for the sentence with at least n noof words so in your case dog that barks does not bite has words so you can frame grams at most grams and not more than that so the result would be gram dog that barks does that barks does not barks does not bite gram dog that barks does not that barks does not bite gram dog that barks does not bite
55443298,remove meaningless words from dataframe column,python nlp textprocessing,you apply the fuction to a column of sequencies of words whilst the actual data is column of strings sequencies of symbols you also should remove sum since it is totally redundant rewrite the function you apply in the form this works
55403920,concepts to measure text relevancy to a subject,python machinelearning nlp datascience,framing the problem when starting a novel machine learning project like this there are a few fundamental questions to think through that can help you refine the problem and lit review experiment more effectively do you have the right data to build a model you have articles that will be your model input however to use a supervised learning approach you will need trustworthy labels for all articles that will be used in model training it sounds like you already have done this what metrics to use to quantify success how can you measure if your model is doing what you want in your specific case this sounds like a binary classification problem you want to be able to label articles as relevant or not you could measure your success using a standard binary classification metric like area under the roc or since you have a specific issue with false positives you could choose a metric like precision how well can you do with a random or naive approach once a dataset and metric have been established you can quantify how well you can do at your task with a basic approach this could be a simple as calculating your metric for a model that chooses at random but in your case you have your keyword parser model which is a perfect way to set a bench mark quantify how well your keyword parsing approach does for your dataset so you can determine when a machine learning model is doing well sorry if this was obvious and basic to you but i wanted to make sure it was in the answer in an innovative open ended project like this diving straight into machine learning experiments without thinking through these fundamentals can be inefficient machine learning approaches as suggested by evan mata and stefan g the best approach is to first reduce your articles into features this could be done without machine learning eg vector space model or with machine learning wordvec and other examples you cited for your problem i think something like bow makes sense to try as a starting point once you have a feature representation of your articles you are almost done and there are a number of binary classification models that will do well experiment from here to find the best solution wikipedia has a nice example of a simple way to use this two step approach in spam filtering an analogous problem see the example usage section of the article good luck sounds like a fun project
55056303,what is the most efficient data structure to build a large wordtoindextoword dictionary,python dictionary datastructures trie nlp,as per what data structure to use to have olog n key and value lookup you need two synchronized data structures for key and value lookups each holding references to the others leaf nodes the structure for the id lookup can be anything with sufficient efficientcy a balanced tree a hash table another trie to be able to extract the value from a leaf node reference a trie needs to allow leaf node references themselves not necessarily a real python reference anything that its api can use walking up the trie to extract the word from that reference note that a reference is effectively a unique integer so if your ids are not larger than an integer it makes sense to reuse something as ids eg the trie node references themselves then if the trie api can validate such a reference ie tell if it has a used node with such a reference this will act as the id lookup and you dont need the nd structure at all this way the ids will be nonpersistent though cuz reference values effectively memory addresses change between processes and runs
55038360,what is the difference between and in nltk regex pattern,python pythonx nlp nltk,heres a list of the penn treebank pos tags as youll see nn does not encompass nns nnp and nnps it only represents singular and mass nouns nn noun singular or mass nns noun plural nnp proper noun singular nnps proper noun plural means any of nn nns nnp nnps repeated or more times from the outer whereas would mean only repeated or more times
54992220,text classification beyond the keyword dependency and inferring the actual meaning,python textclassification nlp,if the data you posted is representative of the classes youre trying to distinguish keyword based features might not be the most effective it looks like some terms that are sometimes treated as stopwords will be very good cues as to what is private and what is public you mention pronouns i think thats likely still a good avenue forward if youre using unigrambagofwords kinds of features make sure your vectorizer is not removing them doing a count of instances of first person pronouns i my ive mine gives for the private case and for the public case the public example has second person pronouns eg you where the first example doesnt so maybe features about counts or smoothed ratios of first to second person pronouns would be effective if you have syntactic structure or are keeping track of positional information through ngrams or a similar representation then features involving firstperson pronouns and your keywords may be effective also verbinitial sentence structures dont be having an are characteristic of secondperson directed language and may show up more in the public than the private text one last speculative thought the sentiment of the two passages is pretty different so if you have access to sentiment analysis that might provide additional cues i would expect the public class would be more neutral that the private class plugging your public example into the watson tone analyzer demo gives this notable result the public statement also contains a feartagged sentence but its not scored as highly is accompanied by other annotations and contains an explicit negation in the sentence so it might be worthwhile to leverage those as features as well
54947258,understanding elmos number of presentations,python nlp pytorch allennlp elmo,see section of the original paper elmo is a task specific combination of the intermediate layer representations in the bilm for each token a llayer bilm computes a set of l representations previously in section it is said that recent stateoftheart neural language models compute a contextindependent token representation via token embeddings or a cnn over characters then pass it through l layers of forward lstms at each position k each lstm layer outputs a contextdependent representation the top layer lstm output is used to predict the next token with a softmax layer to answer your question the representations are these l lstmbased contextdependent representations
54580260,understanding gensim wordvecs mostsimilar,python pythonx nlp gensim wordvec,you can view exactly what mostsimilar does in its source code its not quite find points in the vector space that are as close as possible to the positive vectors and as far away as possible from the negative ones rather as described in the original wordvec papers it performs vector arithmetic adding the positive vectors subtracting the negative then from that resulting position listing the knownvectors closest to that angle that is sufficient to solve man king woman style analogies via a call like you can think of this as start at kingvector add womanvector subtract manvector from where you wind up report ranked wordvectors closest to that point while leaving out any of the query vectors
54557783,comparing texts based on their meanings,nlp azuremachinelearningservice azurecognitiveservices,i would recommend looking into tfidf approaches if the documents are of a technical nature tfidfs look at the frequencies of terms tf in a document and multiply it with the inverse document frequency idf a measure of the scarcity of the term in the overall corpus the thinking there is a word that you use often but is very scarcely used in the overall corpus is likely to make it an important term for the meaning of the document a similarity measure such as cosine similarity is then applied to the tfidf to find documents with a similar profile in terms of tfidf scores ie a similar overusage of the relatively unique terms if the texts are less technical in nature you could take a look at word embedding approaches such as documentvec basically they use trained sets with multidimensional vectors these multidimensional vectors try to capture the meaning of a word which means you are not dependent on the same keywords being used which is the case with tfidf existing implementations are around especially python based but azure can probably facilitate these technologies as well cf hdinsight you can also look up elasticsearch that does some of these things out of the box
54428601,kaldis objects explained in laymans term,nlp speechrecognition kaldi,youd better ask one question at a time also it is better to read the book to understand the theory first instead of trying to grasp all at once finalmdl is the acoustic model and contains the probability of transitioning from one phone to another the main component of the acoustic model model finalmdl is the acoustic detectors not transitioning probabilities it is either a set of gmms for phones or a neural network the acoustic model also contain the transition probabilities from one hmm state to another what builds hmm model for a single phone the transition probabilities between phones are encoded in the graph hclgfst hclgfst is a graph that given a sequence of phones it will generate the most likely word sequence based on the lexicon grammar and language model not quite that hclg fst is a finite state transducer that gives you probability of a state sequence based on lexicon and language model phone sequences are not really used in graph they are accounted on graph construction not quite sure what adding a selfloop is is it similar to the kleene operator speech hmm has selfloops for every state it allows the state to last for several input frames you can find the hmm topology in the book to see the loops lattice contain alternative wordsequence for an utterance this is correct but it also contains times and acoustic and language model scores
54305070,lime explainer shows prediction probabilities different to the classifier prediction sentiment analysis,python machinelearning nlp sentimentanalysis lime,you are not providing a lot of details so my answer is going to be similarly general you original model is making a wrong prediction then lime is making a linear approximation of the model because of the approximative nature of the linear model this is not exactly as the original model and deviates from the original model in your case the original model gives a wrong prediction and the deviation of the linear approximation is by chance in the direction of the right answer so that you get by chance the right answer from the approximation although the original model was wrong
54165109,what is the stochastic aspect of wordvec,nlp gensim wordvec,this is wellcovered in the gensim faq which i quote here q ive trained my wordvecdocvecetc model repeatedly using the exact same text corpus but the vectors are different each time is there a bug or have i made a mistake vec training nondeterminism answer the vec models wordvec fasttext docvec begin with random initialization then most modes use additional randomization during training for example the training windows are randomly truncated as an efficient way of weighting nearer words higher the negative examples in the default negativesampling mode are chosen randomly and the downsampling of highlyfrequent words as controlled by the sample parameter is driven by random choices these behaviors were all defined in the original wordvec papers algorithm description even when all this randomness comes from a pseudorandomnumbergenerator thats been seeded to give a reproducible stream of random numbers which gensim does by default the usual case of multithreaded training can further change the exact trainingorder of text examples and thus the final model state further in python x the hashing of strings is randomized each relaunch of the python interpreter changing the iteration ordering of vocabulary dicts from run to run and thus making even the same stringofrandomnumberdraws pick different words in different launches so it is to be expected that models vary from run to run even trained on the same data theres no single right place for any wordvector or docvector to wind up just positions that are at progressively moreuseful distances directions from other vectors cotrained inside the same model in general only vectors that were trained together in an interleaved session of contrasting uses become comparable in their coordinates suitable training parameters should yield models that are roughly as useful from runtorun as each other testing and evaluation processes should be tolerant of any shifts in vector positions and of small jitter in the overall utility of models that arises from the inherent algorithm randomness if the observed quality from runtorun varies a lot there may be other problems too little data poorlytuned parameters or errorsweaknesses in the evaluation method you can try to force determinism by using workers to limit training to a single thread and if in python x using the pythonhashseed environment variable to disable its usual string hash randomization but training will be much slower than with more threads and youd be obscuring the inherent randomnessapproximateness of the underlying algorithms in a way that might make results more fragile and dependent on the luck of a particular setup its better to tolerate a little jitter and use excessive jitter as an indicator of problems elsewhere in the data or model setup rather than impose a superficial determinism
54072496,explaining cnn keras outputs with lime,python tensorflow keras nlp lime,i managed to solve the problem now here comes the solution for those who might have an interest in it in short the trick was to pick the right columns from the numpy arrays in getpredictprobafnofclass while i had five independent classification scores that do not add up to one i had to add the negative scores for every labels classification scores in a new column eg for i added and then pick the original and new column
53623432,understanding word embeddings convolutional layer and max pooling layer in lstms and rnns for nlp text classification,python tensorflow nlp lstm wordembedding,the simplest way to understand a convolution is to think of it as a mapping that tells a neural network to which features pixels in the case of where you would use a d convolution or words before or after a given word for text where you would use a d convolution are nearby without this the network has no way of knowing that words just before or just after a given word are more relevant than words that are much further away it typically also results in information being presented in a much more densely packed format thereby greatly reducing the number of parameters in your case down from million to thousand i find that this answer explains the technicality of how it works rather well max pooling is a method that downsamples your data it is often used directly after convolutions and achieves two things it again reduces the number of parameters in your case it will represent four values with a single value the max of the four values it does this by taking the first four values then taking a stride of size four and taking the next four values etc in other words there will be no overlap between the pools this is what keras does by default but you could also set the stride to for example secondly because it takes the max value in theory in sharpens the contrast between the pools by taking the maximum value instead of for example taking the average max pooling is not learnt it is just a simple arithmetic calculation that is why the number of parameters is given as zero the same for dropout an lstm expects a three dimensional input of shape number of samples number of timesteps number of features having performed the previous convolution and max pooling steps youve reduced the representation of your initial embedding to number of timesteps and number of features the first value number of samples none is a placeholder for the batch size you plan to use by initializing an lstm with units also known as hidden states you are parameterizing the size of the memory of the lstm essentially the accumulation of its input output and forget gates through time
53444377,what is differece between tokenlevel and segmentlevel in nlp task,python tensorflow nlp,segmentlevel classification means that each segment will have one label for example a classifier which categorises a movie review as good or bad there is only one output label for the entire input sequence tokenlevel classification means that each token will be given a label for example a partofspeech tagger will classify each word as one particular part of speech each token element in the sequence will have a corresponding label in the output if youre not sure what a token is you can start by thinking of it as each word in a sentence but to be more correct look at depending on how you tokenise and preprocess your text tokens can be words punctuation symbols special markers subwordlevel symbols etc
53417258,what is workers parameter in wordvec in nlp,python machinelearning nlp wordvec,workers use this many worker threads to train the model faster training with multicore machines if your system is having cores and if you specify workers then data will be trained in two parallel ways by default worker ie no parallelization
53301916,pythongensim what is the meaning of syn and synnorm,python deeplearning nlp gensim wordembedding,these names were inherited from the original google wordvecc implementation upon which the gensim wordvec class was based i believe syn only exists in recent versions for backwardcompatbility the syn array essentially holds raw wordvectors from the perspective of the neuralnetwork used to train wordvectors these vectors are a projection layer that can convert a onehot encoding of a word into a dense embeddingvector of the right dimensionality similarity operations tend to be done on the unitnormalized versions of the wordvectors that is vectors that have all been scaled to have a magnitude of this makes the cosinesimilarity calculation easier the synnorm array is filled with these unitnormalized vectors the first time theyre needed this synnorm will be empty until either you do an operation like mostsimilar that requires it or you explicitly do an initsims call if you explicitly do an initsimsreplacetrue call youll actually clobber the raw vectors inplace with the unitnormed vectors this saves the memory that storing both vectors for every word would otherwise require however some wordvector uses may still be interested in the original raw vectors of varying magnitudes so only do this when youre sure mostsimilar cosinesimilarity operations are all youll need the syn or synneg in the more common case of negativesampling training properties when they exist on a full model and not for a plain keyedvectors object of only wordvectors are the model neural networks internal hidden weights leading to the output nodes theyre needed during model training but not a part of the typical wordvectors collected after training i believe the syn prefix is just a convention from neuralnetwork variablenaming likely derived from synapse
53017947,what are the preprocessing steps to be taken before passing text into stanford ner tagger,python nlp stanfordnlp,the only thing stanfordner needs is clean text by clean i mean no html or any other kind of document metatags also you shouldnt remove stopwords these might be useful for the model in deciding which label to give to a certain word just have a file with clean text then you will call stanfordnerjar a pass it a trained model eg classifiersenglishallclassdistsimcrfsergz and an input file eg testfiletxt like this this should output something like this as you can see you dont even need to handle tokenisation eg find each unique tokenword in the sentence stanfordner does that for you another useful feature is to set up stanfordner as a webservice then you can simple telnet or post a sentence a get it back tagged
52734659,meaning of the hidden state in keras lstm,python tensorflow keras nlp lstm,short answer if you are more familiar with convolutional networks you can thick of the size of the lstm layer is the equivalent to the size of a convolutional layer the only means that the size of your input lenght of your sequence is longer answer you can check this article for more detail article about rnns in the left image a lstm layer is represented with xt as the input with output ht the feedback arrow shows that there is some kind of memory inside the cell in practice in keras right image this model is unrolled to give the whole input xt in parallel to our layer so when your summary is lstm lstm none it means that your input sequence is xxxx and that the size of your lstm is will be the dimension of your output ht
52400735,what is vector for specific word in cbow wordvec,nlp wordvec,with regard to the diagram youve shown each row in the wi matrix is a wordvector after training when you ask the model for a word like cat it will find out which slot from to v stores cat then return that row of the wi matrix wi is initialized with random lowmagnitude vectors wo is left as zeros at the beginning of training during training various rows of wo and wi are repeatedly improved via backpropagation corrective nudges to make the networks output layer more predictive of each contextword training example for skipgram you can think of the inputlayer in this diagram as a onehot encoding of the single context inputword for cbow you can think of the input layer in this diagram as having the count of each word in the multiword context as the xi values most zero sparse in practice in cbow each word is looked up in wi and their wordvectors are averaged to create the hiddenlayer activation both skipgram and cbow work ok to create useful wordvectors inside wi
52393591,nltk lemmatizer extract meaningful words,pythonx nlp nltk lemmatization,tldr its an xy problem of a lemmatizer failing to meet your expectation when the lemmatizer youre using is to solved a different problem in long q what is a lemma lemmatisation or lemmatization in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item identified by the words lemma or dictionary form wikipedia q what is the dictionary form nltk is using the morphy algorithm which is using wordnet as the basis of dictionary forms see also how does spacy lemmatizer works note spacy has additional hacks put in to handle more irregular words q why moisture moisture and moisturizing moisturizing because there are synset sort of dictionary form for moisture and moisturizing q how could i get moisture moist not really useful but maybe try a stemmer but dont expect too much of it q then how do i get moisuturizingmoisuture moist theres no wellfounded way to do that but before even trying to do that what is the eventual purpose of doing moisuturizingmoisuture moist is it really necessary to do that if you really want you can try word vectors and try to look for most similar words but theres a whole other world of caveats that comes with word vectors q wait a minute but heard heard is ridiculous yeah the pos tagger isnt tagging the heard correctly most probably because the sentence is not a proper sentence so the pos tags are wrong for the words in the sentence we see that heard is tagged as nns a noun if we lemmatized it as a verb q then how do i get a correct pos tag probably with spacy you get heard verb but note in this case spacy got moisturize noun and nltk got moisturize vb q but cant i get moisturize moist with spacy lets not go back to the start where we define what is a lemma in short see also how does spacy lemmatizer works again q okay fine i cant get moisturize moist and pos tag is not perfect for heard hear but why cant i get jflying fly back to the question of why do you need to convert jflying fly there are counter examples of why you wouldnt want to separate something that looks like a compound for example should classicalsounding go to sound should xfitting go to fit should crashlanding go to landing depends on whats the ultimate purpose of your application converting a token to your desired form may or may not be necessary q then what is a good way to extract meaningful words i sound like a broken record but it depends on whats your ultimate goal if you goal is really to understand the meaning of words then you have to ask yourself the question what is the meaning of meaning does individual word has a meaning out of its context or would it have the sum of meanings from all the possible context it could occur in au currant the stateofart basically treats all meanings as an array of floats and comparisons between array of floats are what give meaning its meaning but is that really meaning or just an means to an end pun intended q why am i get more questions than answers welcome to the world of computational linguistics which has its roots from philosophy like computer science natural language processing is commonly known as the application of computational linguistics food for thought q is a lemmatizer better than a stemmer a no definite answer cf stemmers vs lemmatizers
51719033,what is the pythoninc way to replace multiple new line with single and single new line with one space,python pythonx nlp,a pythonic solution first you split the string where nn occurs then you substitute n for in each element of the the list and finally you join everything together with n another solution i would use a temporal helper string that allows me to temporarily replace the double new line then replace the single newlines with spaces and then the temporal helper string by newlines lets say your string is s
51610905,what is the semantic relationship expected between word vectors which are scalar multiples of each other in wordvec,machinelearning nlp pca wordvec linguistics,the words that most cosinesimilar to to wvqueen will be the exact same that are most cosinesimilar to n wvqueen for any n because cosinesimilarity is unaffected by vector magnitude so your assumption is wrong if you were to use euclideandistance instead of cosinesimilarity on the raw not unitnormalized word vectors you might find some other interesting relationships but thats not a typical way to usecompare wordvectors so youd have to experiment i have no expectations of what you might find or whether it would be useful in general the raw nonunitnormalized wordvectors tend to have a highermagnitude for words that have a single narrow sense all contexts they appear in are very similar while words with many senses and varied contexts tend to have smaller magnitudes but im not sure you can count on this from much once wordvectors are normalized to unitlength and thus all words are on the same unit sphere then the rank order of nearestneighbors will be same by either cosinedistance or euclideandistance even though the magnitudes of the distancesimilarity numbers wont be identical or proportionate at each rank
51363605,mnemonic generation using lstms how do i make sure my model generates meaningful sentence using a loss function,machinelearning keras nlp deeplearning,first i have a couple of unrelated suggestions i do not think you should output the glove vector of each word why wordvec approaches are meant to encapsulate word meanings and would probably not contain information about their spelling however the meaning is also helpful in order to produce a meaningful sentence thus i would instead have the lstm produce its own hidden state after reading the first two letters of each word just as you currently do i would then have that sequence be unrolled as you currently do into sequences of dimension one indexes into a index to word map i would then take that output process it through an embedding layer that maps the word indexes to their glove embeddings and i would run that through another output lstm to produce more indexes you can stack this as much as you want but or levels will probably be good enough even with these changes it is unlikely you will see any success in generating easytoremember sentences for that main issue i think there are generally two ways you can go the first is to augment your loss with some sense that the resulting sentence being a valid english sentence you can do this with some accuracy programtically by pos tagging the output sentence and adding loss relative to whether it follows a standard sentence structure subject predicate adverbs directobjects etc though this result might be easier than the following alternative it might not yield actually natural results i would recommend in addition to training your model in its current fashion to use a gan to judge if the output sentences are natural sentences there are many resources of keras gans so i do not think you need specific code in this answer however here is an outline of how your model should train logically augment your current training with two additional phases first train the discriminator to judge whether or not the output sentence is natural you can do this by having an lstm model read sentences and giving a sigmoid output to whether or not they are natural you can then train this model on some dataset of real sentences with labels and your sentences with labels at roughly a split then in addition to the current loss function for actually generating the mnemonics add the loss that is the binary crossentropy score for your generated sentences with true labels be sure to obviously freeze the discriminator model while doing this continue iterating over these two steps training each for epoch at a time until you start to see more reasonable results you may need to play with how much each loss term is weighted in the generator your model in order to get the correct tradeoff between a correct mnemonic and an easytoremember sentence
50800803,how to compare meaningful level of a set of phrase that describe same concept in nlp,python nlp,the question you ask is very broad see here but here are some hints for starting points wordnet word embeddings wordvec glove the meaning difference you are looking into is quite peculiar so i suggest starting with wordnet there are wordnets for other languages as well the code that uses wordnet to calculate meaning differences using wordnet you can find here good framework to start an nlp journey is nltk
50598129,what is the default smartirs for gensim tfidfmodel,python nlp gensim informationretrieval tfidf,the default value of smartirs is none but if you follow the code it is equal to ntc but how first when you call model tfidfmodelcorpus it calculates idf of the corpus with a function called wglobal which explained in docs as wglobal is function for global weighting the default value is dfidf dfidf is a function that computes idf for a term with the given document frequency the default arguman and formula for dfidf is which implemented as one of the smartirs is determined document frequency weighting is inversedocumentfrequency or idf wlocals by default is identity function term frequency of the corpus passed through the identify function which nothing happened and the corpus itself return hence another parameter of smartirs term frequency weighing is natural or n now that we have term frequency and inversedocumentfrequency we can compute tfidf normalize by default is true that means after computing tfidf it normalizes the tfidf vectors the normalization is done with lnorm euclidean unit norm which means our last smartirs is cosine or c this part implemented as when you call modelcorpus or modelgetitem the following things happen getitem has a eps argument which is a threshold value that will remove all entries that have tfidfvalue less than eps by default this value is e as a result when you print the vectors only some of them appeared
50347481,i cannot understand the skipgrams function in keras,python machinelearning nlp keras textprocessing,thats because your vocabulary is very small its the same love i money words thats why random word from the vocabulary is always from the same sentence and moreover from the same context as an experiment do this basically let the tokenizer know that there are more words in the text you should see that the negative examples are now generated mostly from the second sentence for example
49856775,understanding character level featureextraction using tfidfvectorizer,python machinelearning nlp tfidfvectorizer,the shape is as is the size of your whole ngram vocabulary when you call transform on a list of text the output shape will still be if you called it on texts it would be the tuple in your output means that the gram at index x in your vocabulary is a gram that is in your word the float is the inverse document frequency also i think you misunderstand the way the ngramrange parameter works you ask why it increases and doesnt decrease when you input rather than this is because when you input it stores both unigrams bigrams and trigrams in the vocabulary
49783265,launch tool is missing in ibm watson natural understanding when creating custom model,nlp ibmwatson watsonnlu watsonknowledgestudio,your first pic looks watson knowledge studio watson knowledge studio is a different service you can also create ibm cloud catalog please check it
49444055,what is the best way to implement a reply logic for a chatbot,nlp chatbot witai,the request flow with witai as follows first request is made by the user using the message providerie facebook messanger slack ect this request is received by the witai then the all the required information is extracted by the witai then all the request parameters is sent to the webhook you specified in the witai in the webhook you process the input parameters and respond to it according to iteg user querying for restaurant search wit provides the the name of the restaurant you query data base using the name and prepares the response then the prepared response is sent back to the witai from webhook then wit delivers your message to the respective user and message provider so you no need to train any rnn for responding the userbut if your business logic requires the rnn training you have to do it in the webhook its your web server you can refer to this link for more info
49358277,what are the best methods to classify the user gender based on names,python pythonx nlp deeplearning kaggle,you could use characterlevel embeddings ie your input classes are the different characters so a is class b is class etc onehot encoding the classes and then passing them through an embedding layer will yield unique representations for each character a string can then be treated as a charactersequence or equally a vectorsequence which can be used as an input for either a recurrent or convolutional network if you feel like reading this paper by kim et al will provide you all the necessary theoretical backbone
49252156,nlp what is the appropriate way to use engineered features in a sklearn pipeline,python scikitlearn nlp,incorporating features into a pipeline can be done using sklearns featureunion as suggested by vivek kumar with details found here on the scikitlearn website when using the pipeline it should be split into a number of sections sections with important ones the extraction of data then the featureunion and then a classifier within the featureunion there will likely be multiple pipelines corresponding to different features such as a bag of words model tfidf adhoc features etc as can be seen in detail in the link provided above the pseudostructure is like so
49239941,what is unk in the pretrained glove vector files eg glovebdtxt,neuralnetwork deeplearning nlp wordembedding glove,the unk token in the pretrained glove files is not an unknown token see this google groups thread where jeffrey pennington glove author writes the pretrained vectors do not have an unknown token and currently the code just ignores outofvocabulary words when producing the cooccurrence counts its an embedding learned like any other on occurrences of unk in the corpus which appears to happen occasionally instead pennington suggests in the same post ive found that just taking an average of all or a subset of the word vectors produces a good unknown vector you can do that with the following code should work with any pretrained glove file import numpy as np glovefile glovebdtxt get number of vectors and hidden dim with openglovefile r as f for i line in enumeratef pass nvec i hiddendim lenlinesplit vecs npzerosnvec hiddendim dtypenpfloat with openglovefile r as f for i line in enumeratef vecsi nparrayfloatn for n in linesplit dtypenpfloat averagevec npmeanvecs axis printaveragevec for glovebdtxt this gives and because it is fairly compute intensive to do this with the larger glove files i went ahead and computed the vector for glovebdtxt for you
48997688,how to use conceptual dependencies predicate calculuslogic conceptual graph in nlp,search nlp artificialintelligence,this seems like a homework assignment if it is id love to know more about the class it seems to be one i would like to know the professor etc because it amuses me ill try one of these all dogs bark this seems to be an english form of the predicate calculus forall x dog bark x assuming that dog is defined as a proper category and bark is an appropriate predicate i cant help with the conceptual dependency representation unless you share what set of primitives you have to work with do you use ptrans and mtrans is the air moving from a bark considered to be a physical object moved we need more definition to understand what you are trying to do why did you not include drs it seems to be a very common representation in many nlp applications currently which syntax for conceptual graphs are you using the original john sowa set from what grammar do you need to use cgif common logic best wishes david
48847221,what is the difference between the different glove models,nlp deeplearning stanfordnlp,unfortunately i dont think anyone can give you a better answer for this than try several options and see which one works the best ive seen work that uses the wikipedia gigaword d vectors that produced sota results for reading comprehension without experimentation its difficult to say conclusively which corpus is closer to your music review set or what the impact of larger dimensional word embeddings will be this is just random advice but i guess i would suggest trying in this order d from wikipediagigaword d from wikipediagigaword d from common crawl you might as well start with the smaller dimensional embeddings while prototyping and then you could experiment with larger embeddings to see if you get a performance enhancement and in the spirit of promoting other groups work i would definitely say you should look at these elmo vectors from allennlp they look very promising
48356421,what is the difference between syntactic analogy and semantic analogy,nlp wordembedding fasttext,syntactic means syntax as in tasks that have to do with the structure of the sentence these include tree parsing pos tagging usually they need less context and a shallower understanding of world knowledge semantic tasks mean meaning related a higher level of the language tree these also typically involve a higher level understanding of the text and might involve tasks sa question answering sentiment analysis etc as for analogies he is referring to the mathematical operator like properties exhibited by word embedding in this context a syntactic analogy would be related to plurals tense or gender those sort of things and semantic analogy would be word meaning relationships sa man queen king etc see for instance this article and many others
48143769,spacy nlp library what is maximum reasonable document size,python nlp spacy,spacy has a maxlength limit of characters i was able to parse a document with words just fine the limit can be raised i would split the text into n chunks depending upon total size the vx parser and ner models require roughly gb of temporary memory per characters in the input this means long texts may cause memory allocation errors if youre not using the parser or ner its probably safe to increase the nlpmaxlength limit the limit is in number of characters so you can check whether your inputs are too long by checking lentext
47706661,given a word get the meaning using wordnet api,nlp wordnet,here is how to get definition output
47388497,what is the difference between dialogflow bot framework vs rasa nlu bot framework,nlp opensource chatbot dialogflowes rasanlu,i think i can answer this without any bias granted that overtime the answer will grow outdated as the two services evolve cliffnotes version dialogflow is a complete closed source product with a fully functional api and graphical web interface rasa nlu core are open source python libraries that require slightly lower level development both try to abstract some of the difficulty of working with machine learning to build a chatbot as of writing this however here is my comparison dialogflow is a mostly complete tool for the creation of a chatbot mostly complete meaning that it does almost everything you need for most chatbots specifically it can handle classification of intents and entities it uses what it calls context to handle dialogue it allows web hooks for fulfillment one thing it does not have that is often desirable for chatbots is some form of end user management it has a robust api which allows you to define entitiesintentsetc either via the api or with their web based interface formerly known as apiai before being acquired by google data is hosted in the cloud and any interaction with apiai require cloud related communications cannot be operated on premise rasa nlu core to get close to the same level of fucntionality as dialogflow you have to use both rasa nlu and rasa core rasa nlu handles projectsintentsentities whereas rasa core handles dialogue and fulfillment rasa doesnt provide a complete open source gui leaving most of your interactions with nlu in json or markdown and rasa core requires direct python development to customize your bot also does not directly offer any sort of user info management the rasa team does not provide hosting at least outside of their enterprise offerings and you will be responsible for hosting and thus ownership of the data can be operated on premise as far as other open source frameworks i would say that it is very likely that most chatbot frameworks right now are built on a variety of open source tools with some proprietary addons so you can always start from the lower level open source tools like mitie or spacy update the smart platform group of which i am a member recently released a product in between rasa nlucore and dialogflow called articulate articulate is a fullfeatured bot framework based on rasa nlu that lets you build natural language agents effortlessly uses rasa nlu for understanding and custom context based code for dialog this makes it work closer to how dialogflow does than rasa core http api for creating intents entities and interacting with agents gui similar to dialogflow that is fully open source data and interface can be hosted in the cloud or on premise
47302947,understanding input and labels in wordvec tensorflow,arrays machinelearning tensorflow nlp wordvec,there are supposed to be labels for each input right window size on each side but the batchlabel variable is the same length the key setting is numskips this value defines the number of input label tuples each word generates see the examples with different numskips below my data sequence seems to be different from yours sorry about that example numskips batch labels generatebatchbatchsize numskips skipwindow it generates labels for each word ie uses the whole context since batchsize only words are processed in this batch and the rest will go into the next batch data batch labels example numskips batch labels generatebatchbatchsize numskips skipwindow here you would expect each word appear twice in the batch sequence the labels are randomly sampled from possible words data batch labels example numskips batch labels generatebatchbatchsize numskips skipwindow finally this setting same as yours produces exactly one label per each word each label is drawn randomly from the word context data batch labels how should i interpret the batchlabels each label is the center word to be predicted from the context but the generated data may take not all context center tuples depending on the settings of the generator also note that the trainlabels tensor is dimensional skipgram trains the model to predict any context word from the given center word not all context words at once this explains why all training pairs and are valid
47040505,what are the best preprocessing techniques for sentiment analysis,machinelearning nlp sentimentanalysis lightgbm,there are a few things to consider first of all your training set is not balanced the class distribution is you need to consider this fact in training what types of features are you using using the right set of features could improve your performance
46640820,best way to understand the input text before applying ngram,pythonx pandas nlp nltk nltkbook,to solve your problem you have to clean the stop words using regex see this example i hope this helps
46582351,understanding the flow of finite state transducer,nlp statemachine,for input you start as always in state the transition labeled takes you to state reads the first from the input and outputs now there is one of your input left so you take to state the first step outputs the second one so the total output is xy means that the transition reads x and outputs y
46377054,spacy what is normpart of tokenizerexceptions,python nlp tokenize spacy,to answer the question more generally in spacy vx the norm is mostly used to supply a normalised form of a token for example the full inflected form if the token text is incomplete like in the gonna example or an alternate spelling the main purpose of the norm in vx is making it accessible as the norm attribute for future reference however in vx currently in alpha the norm attribute becomes more relevant as its also used as a feature in the model this lets you normalise words with different spellings to one common spelling and ensures that those words receive similar representations even if one of them is less frequent in your training data examples of this are american vs british spelling in english or the currency symbols which are all normalised to to make this easier v introduces a new language data component the norm exceptions if youre working on your own language models id definitely recommend checking out v alpha which is pretty close to a first release candidate now
46356227,what is the initial value of embedding layer,machinelearning nlp deeplearning wordvec wordembedding,initializations define the way to set the initial random weights of layers you can use any value to do it but initial values affect word embedding there are many approach for pretrained word embedding that they try to choose better initial values like this
46326173,understanding lda topic modelling too much topic overlap,python nlp gensim lda topicmodeling,lda is extremely dependent on the words used in a corpus and how frequently they show up the words you are seeing are all stopwords meaningless words that are the most frequent words in a language eg the i a if for said etc and since these words are the most frequent it will negatively impact the model i would use the nltk stopword corpus to filter out these words then make sure your text does not contain any of the words in the stopwords list by whatever pre processing method you are using an example is below you may also want to remove punctuation and other characters etc then use regular expressions finally you may also want to filter on most frequent or least frequent words in your corpus which you can do using nltk that should get rid of the stopwords and extra characters but still leaves the vast problem of topic modelling which i wont try to explain here but will leave some tips and links assuming you know a little bit about topic modelling lets start lda is a bag of words model meaning word order doesnt matter the model assigns a topic distribution of a predetermined number of topics k to each document and a word distribution to each topic a very insightful high level video explains this here if you want to see more of the mathematics but still at an accessible level check out this video the more documents the better and usually longer documents with more words also fair better using lda this paper shows that lda doesnt perform well with short texts less than words k is up to you to choose and really depends on your corpus of documents how large it is what different topics it covers etc usually a good value of k is between but again this really depends on your corpus lda has two hyperparamters alpha and beta alpha and eta in gemsim a higher alpha means each text will be represented by more topics so naturally a lower alpha means each text will be represented by less topics a high eta means each topic is represented by more words and a low eta means each topic is represented by less words so with a low eta you would get less overlap between topics theres many insights you could gain using lda what are the topics in a corpus naming topics may not matter to your application but if it does this can be done by inspecting the words in a topic as you have done above what words contribute most to a topic what documents in the corpus are most similar using a similarity metric hope this has helped i was new to lda a few months ago but ive quickly gotten up to speed using stackoverflow and youtube
46299420,how wordvec or woddoc understand user sentiments,nlp wordvec docvec,by representing a document or set of words with feature vectors you can process text in other machine learning tasks for example if you have a dataset which labeled each document x with its sentiment y you can use the pretraind embedding as feature vectorisation to represent x as input to your machine learning method and test if these features help your task
46084574,what is the difference between mtevalvapl and nltk bleu,machinelearning nlp nltk machinetranslation bleu,tldr use when evaluating machine translation systems in short no the bleu in nltk isnt the exactly the same as the mtevalaperl but it can get really close see nltktranslatecorpusbleu corresponds to mtevalapl up to the th order of ngram with some floating point discrepancies the details of the comparison and the dataset used can be downloaded from or the major differences in long there are several difference between mtevalapl and nltktranslatecorpusbleu the first difference is the fact that mtevalapl comes with its own nist tokenizer while the nltk version of bleu is the implementation of the metric and assumes that input is pretokenized btw this ongoing pr will bridge the gap between nltk and nist tokenizers the other major difference is that mtevalapl expects the input to be in sgm format while nltk bleu takes in python list of lists of strings see the readmetxt in the zipball here for more information of how to convert textfile to sgm mtevalapl expects an ngram order of at least if the minimum ngram order for the sentencecorpus is less than it will return a probability which is a mathlogfloatinf to emulate this behavior nltk has a put an emulatemultibleu flag see mtevalapl is able to generate nist scores while nltk doesnt have nist score implementation at least not yet nist score in nltk is upcoming in this pr other than the differences nltk bleu scores packed in more features to handle fringe cases that the original bleu papineni overlooked see also to handle fringe cases where the largest order of ngram is see while nist has a smoothing method for geometric sequence smoothing nltk has an equivalent object with the same smoothing method and even more smoothing methods to handle sentence level bleu from chen and collin lastly to validate the features added in nltks version of bleu a regression test is added to accounts for them see
46055753,how to convert line of text into meaningful words,python regex nlp nltk,you can use recursion to solve this problem first you will want to download a dictionary txt file which you can get here output
45959618,what is the minimum dataset size needed for good performance with docvec,nlp docvec,a bunch of things have been called docvec but it seems to mostoften refer to the paragraph vector technique from le and mikolov the original paragraph vector paper describes evaluating it on three datasets stanford sentiment treebank sentences of moviereviews which were further broken into fragmentphrases of a few words each imdb dataset moviereviews often of a few hundred words each searchresult snippet paragraphs paragraphs collected from the top google search results for each of the top mostcommon queries the st two are publicly available so you can also review their total sizes in words typical document sizes and vocabularies note though that no one has been able to fullyreproduce that papers sentimentclassification results on either of those first two datasets implying some missing info or error in their reporting its possible to get close on the imdb dataset a followup paper applied the algorithm to discovering topicalrelationships in the datasets wikipedia article bodytexts arxiv academicpaper texts extracted from pdfs so the corpuses used in those two early papers ranged from tensofthousands to millions of documents and document sizes from a few word phrases to thousandsofword articles but those works did not necessarily mix wildlydifferentlysized documents in general wordvecparagraphvector techniques benefit from a lot of data and variety of wordcontexts i wouldnt expect good results without at least tensofthousands of documents documents longer than a few words each work much better results may be harder to interpret if wildlydifferentinsize or kind documents are mixed in the same training such as mixing tweets and books but you really have to evaluate it with your corpus and goals because what works with some data for some purposes may not be generalizable to verydifferent projects
45646938,crf anybody understand what does the float number mean in crf model file,nlp crf crf,after reading parts of the crf source code i know how to understand the crflearn output i will use some examples to explain the output basic lets assume we have the following training data and our template is very simple only has one line ux so the number of feature in this case is there are now let keep the training data unchanged add another feature in template ux uxxx now we have two features in template so the total number of feature changes to there are this feature template with two rules will apply to each single word now lets add a duplicated word in training data as following for the word it appears twice but only be regarded as one feature so the number of feature still advance now lets see how to understand the content in modeltxt a space line is used to delimit different block first block the maxid depends on numbers of features and numbers of tags using the first training data as example different words and two tags b and i the id should start from maxid is here why the step is because we have two types of tag actually each word corresponds to two different tags like second block list all the tags in the training data third block list all the template used ux b fourth block the feature id the template and the correspond word the fifth block for each feature the possibility for each tag there are two possibility correspond to each word possibility shuai hua
45502464,what is the difference between wmd word mover distance and wmd based similarity,nlp nltk gensim wordvec wordembedding,i think with the update youe moreorless answered your own question that one is a distance and the other a similarity is the only difference between the two calculations as the notebook you link notes in the relevant section wmd is a measure of distance the similarities in wmdsimilarity are simply the negative distance be careful not to confuse distances and similarities two similar documents will have a high similarity score and a small distance two very different documents will have low similarity score and a large distance as the code youve excerpted shows the similarity measure being used there is not exactly the negative distance but scaled so all similarity values are from exclusive to inclusive that is a zero distance becomes a similarity but everlarger distances become evercloser to
44600257,understanding stanford corenlp tokensregex syntax for arbitrary phrase matching,nlp stanfordnlp,it turns out i didnt need tokensregex directly for my problem the key thing i was trying to solve was picking out numbers in a phrase and convert them but i realized that i could use corenlps nerclassifiercombiner to pick them ouyreplace them and use plain regular expressions to match the updated input phrase example of what i did is below for phrases like show me all cars within fifteen kilometers this converts it to show me all cars within kilometers took some more digging into the library to find the ner toolkit but its working like a charm now hope this helps someone else thats trying to find numbers or other entities in their phrases
44238154,what is the difference between luong attention and bahdanau attention,tensorflow deeplearning nlp attentionmodel,i went through this effective approaches to attentionbased neural machine translation in the section they have mentioned the difference between two attentions as follows luong attention used top hidden layer states in both of encoder and decoder but bahdanau attention take concatenation of forward and backward source hidden state top hidden layer in luong attention they get the decoder hidden state at time t then calculate attention scores and from that get the context vector which will be concatenated with hidden state of the decoder and then predict but in the bahdanau at time t we consider about t hidden state of the decoder then we calculate alignment context vectors as above but then we concatenate this context with hidden state of the decoder at t so before the softmax this concatenated vector goes inside a gru luong has diffferent types of alignments bahdanau has only concat score alignment model
43608448,how to create meaningful column value pair lists from a string,python string nlp semantics,check the following approach build the regex to remove irrelevant words from the results based on the english nltk stopword list build the regex to split the text with using the dictcolumns keys after splitting zip the resulting list into a tuple list remove the irrelevant words from the values and strip the whitespace here is the code i have come so far
43479120,what are the details of sequencetosequence model for text summarization,nlp dataset sequencetosequence,youre right that there are very few large datasets that were created specifically to be used for training text summarization models people tend to use other existing data and find ways to turn it into a summarization problem you can read other text summarization papers to see what they do
43463792,what is the difference between bigram and unigram text features extraction,machinelearning nlp,we are trying to teach machine how to do natural language processing we human can understand language easily but machines cannot so we trying to teach them specific pattern of language as specific word has meaning but when we combine the wordsie group of words than it will be more helpful to understand the meaning ngram is basically set of occurring words within given window so when n it is unigram n it is bigram n it is trigram and so on now suppose machine try to understand the meaning of sentence i have a lovely dog then it will split sentences into a specific chunk it will consider word one by one which is unigram so each word will be a gram i have a lovely dog it will consider two words at a time so it will be bigram so each two adjacent words will be bigram i have have a a lovely lovely dog so like this machine will split sentences into small group of words to understand its meaning
43192690,watson natural language understanding javasdk,nlp watson,i was strugglling with the same issue luckily ibm has updated the sdk to version a few hours ago and a bit of information on usage is available at the moment use the link to sdk
43166762,what is relation between tsne and wordvec,nlp gensim wordvec,internally they both use gradientdescent to reach their final optimized states and both can be considered dimensionalityreduction operations but wordvec does not internally use tsne or viceversa tsne tdistributed stochastic neighbor embedding typically reduces manydimensional data to or dimensions for the purposes of plotting a visualization it involves learning a mapping from the original dimensionality to the fewer dimensions which still keeps similar points near each other wordvec takes many text examples and learns a shallow neuralnetwork thats good at predicting words from nearby words a particular layer of that neuralnetworks weights which represent individual words then becomes the learned ndimensional wordvectors with the value of n often to theres an alternative way to create wordvectors called glove that works a little more like tsne in that it trains directly from the highdimensional cooccurrence matrix of words rather than from the many incontext cooccurrence examples but its still not tsne itself you could potentially run tsne with a target dimensionality of but since that endresult wouldnt yet yield nice plots the maintenance of nearness thats central to tsne wont have delivered its usual intended benefit you could potentially learn wordvec or glove vectors of just or dimensions but most of the useful similaritiesarrangements that people seek from wordvectors would be lost in the crowding and in a plot youd probably not see as strong visual clumping of relatedword categories because tsnes specific hightolow dimensionality nearnesspreservation goal wasnt applied
42981868,watson natural language understanding java example,java nlp watson,until the api reference is published have you tried looking at the tests on github see here for naturallanguageunderstandingit ive gotten it working with a text string and looking at the above test it wont be too much to get it working with a url or html changing the analyzeoptions builder call from text to html for example code example make sure you populate your nlu service with default headers setdefaultheaders i pulled these from watsonservicetest id post the link but my rep is too low just use the findfile option on wdc github
42817834,understanding maximum likelihood in nlp,nlp mle,mle is indeed a maximization problem in the slides they skipped over the calculations and just indicated the result of the mle if you want to see the full derivation you can look at page here for example this link explains how to find maximum likelihood estimator of parameters of multinomial distribution and the same type of calculation also leads to the resuls you saw in the slides the n in the link corresponds to cwwi from your slides as this is the total number of cases and xi in link corresponds to cwwi from your slides as this is the total number of the specific cases you want to count among all the cases
42698919,classify words with the same meaning,pythonx machinelearning nlp nltk textprocessing,the easiest way to accomplish this would be to compare the similarity of the respective word embeddings the most common implementation of this is wordvec wordvec is a way of representing the semantic meaning of a token in a vector space which enables the meanings of words to be compared without requiring a large dictionarythesaurus like wordnet one problem with regular implementations of wordvec is that it does differentiate between different senses of the same word for example the word bank would have the same wordvec representation in all of these sentences the river bank was dry the bank loaned money to me the plane may bank to the left bank has the same vector in each of these cases but you may want them to be sorted into different groups one way to solve this is to use a sensevec implementation sensevec models take into account the context and part of speech and potentially other features of the token allowing you to differentiate between the meanings of different senses of the word a great library for this in python is spacy it is like nltk but much faster as it is written in cython x faster for tokenization and x faster for tagging it also has sensevec embeddings inbuilt so you can accomplish your similarity task without needing other libraries its as simple as its free and has a liberal license
42382446,what is the difference between viterbi cyk and probabilistic cyk algorithm is there any differences,parsing nlp stanfordnlp viterbi cyk,yes you are correct you can consider weight cky is equivalent to viterbi for parsing you can see the lecture on viterbi and statistical parsing with pcfg from here however viterbi algorithm can be used to find the most likely sequence of hidden states and probabilistic cyk algorithm is specifically designed for taggingparsing
42216995,what exactly are wordnet lexicographer files understanding how wordnet works,nlp artificialintelligence ontology wordnet,yes the wordnet documentation is rather hard to read youre looking for this page during wordnet development synsets are organized into fortyfive lexicographer files based on syntactic category and logical groupings these groupings are some sort of parallel clusters flat grouppings to the hyperhyponym hierarchical ontology in short from the docs file format of the lexicographer files in wordnetdict each line in lexnames contains tab separated fields and is terminated with a newline character the first field is the two digit decimal integer file number the first file in the list is numbered the second field is the name of the lexicographer file that is represented by that number and the third field is an integer that indicates the syntactic category of the synsets contained in the file this is simply a shortcut for programs and scripts since the syntactic category is also part of the lexicographer files name in laymans explanation me its just a standard of how you should assign the values for the nd column in the files eg datanouns dataverbs etc traditionally wordnet creatorsmaintainers should name their files accordingly but sometimes its easier to just put all nouns together and use the index of denote the synsets category the guidelines for the categories are as follows so for example in wordnetdictdatanoun we see lines look at the nd column for phenomenon the value is which points to nountops for thing it has the value which refers to nounact imho depending on the usage these assignments may not be useful they are mostly use when creating the wordnet and how we can easily flatten ontological hierarchies into simple flat clusters
42038337,what is the connection or difference between lemma and synset in wordnet,python nlp nltk wordnet,the terms are based on the general sense of the words lemma and synonym a lemma is wordnets version of an entry in a dictionary a word in canonical form with a single meaning eg if you wanted to look up banks in the dictionary the canonical form would be bank and there would be separate lemmas for the nouns meaning financial institution and side of the river a separate one for the verb to bank on etc the term synset stands for set of synonyms a set of synonyms is a set of words with similar meaning eg ship skiff canoe kayak might all be synonyms for boat in the nltk a synset is in fact a set of lemmas with related meaning taking your example the results of wnsynsetscake and wnlemmascake we can also write these are the lemmas making up the first synset given for cake wordnet provides a lot of methods that allow you to explore relationships like hypernymshyponyms usage domains and more for more information you should look directly in the wordnet documentation the nltk just provides an interface for it here is the wordnet glossary
41871139,what are the segmentation patterns for sentiment analysis,nlp sentimentanalysis,you have two specific approaches to do sentiment analysis corpusbased approach in this approach machine learning is used on text with any features that is valid on text such as ngrams tfidf term frequency term occurrence you can combine feature results with weights as well lexiconbased approach in this approach a sentiment lexicon such as sentiwordnet or senticnet is employed with basic rules to find the sentiment polarity of sentence pos tagging is mostly used in this approach
41709318,what is gensims docvecs,python nlp gensim docvec,the docvecs property of the docvec model holds all trained vectors for the document tags seen during training these are also referred to as doctags in the source code in the most simple case analogous to the paragraph vectors paper each text example paragraph just has a serial number integer id as its tag starting at this would be an index into the docvecs object and the modeldocvecsdoctagsyn numpy array is essentially the same thing as the capital d in your excerpt from the paragraph vectors paper gensim also supports using string tokens as document tags and multiple tags per document and repeating tags across many of the training documents for string tags if any theyre mapped to indexes near the end of the docvecs by the dict modeldocvecsdoctags
41666937,perceptron with unigram features how does it learn and what are the next steps,haskell nlp neuralnetwork perceptron,what part of this code learns learning is achieved by adjusting the weights to make the perceptrons output on the training data become closer to the desired output whats the next stage of nlp algorithms i dont know anything about nlp algorithms but perceptrons are the building blocks of neural networks i think the next thing youll want to look at is feedforward back propagation neural networks they consist of layers of connected perceptrons brush up on your linear algebra and multivariable calculus because adjusting the weights is a bit more involved
41665109,trying to understand cnns for nlp tutorial using tensorflow,tensorflow nlp convneuralnetwork,answer to ques so am i correct if i assume that tfnnembeddinglookup ignores the value the s in the input vector is the index to th symbol in the vocabulary which is the pad symbol i dont think it gets ignored when the lookup is performed th row of the embedding matrix will be returned answer to ques but how can tfnnembeddinglookup know about those indices given by selfinputx size of the embedding matrix is v e where is the size of vocabulary and e is dimension of embedding vector th row of matrix is embedding vector for th element of vocabulary st row of matrix is embedding vector for st element of vocabulary from the input vector x we get the indices of words in vocabulary which are used for indexing the embedding matrix answer to ques does this mean that we are actually learning the word embeddings here yes we are actually learning the embedding matrix in the embedding layer in line w tfvariable tfrandomuniformvocabsize embeddingsize namew w is the embedding matrix and by default in tensorflow trainabletrue for variable so w will also be a learned parameter to use pre trained model set trainable false for detailed explanation of the code you can follow blog
41403862,what are trained models in nlp,java nlp stanfordnlp opennlp,a model as downloadable for opennlp is a set of data representing a set of probability distributions used for predicting the structure you want eg partofspeech tags from the input you supply in the case of opennlp typically text files given that natural language is contextsensitive this model is used in lieu of a rulebased system because it generally works better than the latter for a number of reasons which i wont expound here for the sake of brevity for example as you already mentioned the token perfect could be either a verb vb or an adjective jj and this can only be disambiguated in context this answer is perfect for this example the following sequences of pos tags are possible in addition to many more dt nn vbz jj dt nn vbz vb however according to a model which accurately represents correct english the probability of example is greater than of example pdt nn vbz jj this answer is perfect pdt nn vbz vb this answer is perfect in reality this is quite contentious but i stress here that im talking about natural language as a whole including semanticspragmaticsetc and not just about naturallanguage syntax which in the case of english at least is considered by some to be contextfree when analyzing language in a datadriven manner in fact any combination of pos tags is possible but given a sample of correct contemporary english with little noise tag assignments which native speakers would judge to be wrong should have an extremely low probability of occurrence in practice this means a model trained on a large diverse corpus of contemporary english or some other target domain you want to analyze with appropriate tuning parameters if i want to be even more precise this footnote could easily be multiple paragraphs long
41210384,what is twolevel morphology,nlp stanfordnlp,there are lexical and surface levels in this framework hence the name twolevel morphology the surface level is the actual realization of words as they appear in the final form the lexical aka dictionary level corresponds to the combination of roots and affixes that are chained together with boundary markers for instance for the present tense third person singular form of the verb try in this framework these two levels are connected through a series of finite state transducers and form a single combined automaton for more information consult this document update also have a look at the documentation for twol a python package developed within this linguistic framework for a detailed theoretical treatment you can have a look at koskenniemis original work here
40836328,how to process natural language query into solr understandable query,solr lucene nlp,you are nowhere near solr yet you have to go back and look for the actual nlp natural language processing system if it uses solr or opennlp that integrates with solr great if not you have to invent this bridge it does not just come with solr as this is still a cutting edge of research
40793193,how to determine the least important word to the meaning of a sentence,python algorithm nlp nltk,this is a very vague question from what i understand you want to do something like keyword extraction pos tagging is a good start it lets you tag sentences to their parts of speech nouns verbs adjectives etc pos tag nltk you can then write your own rules to extract just the parts of speech that interest you stopword removal is another option keyword extraction does a bunch of stuff you can read with examples chunking chinking named entity recognition building cfgs and parse trees relation extraction i think reading this chapter will give the perspective and the code snippets to get you started
40555512,what is fp and tn in word sense diasiambiguation in calculating precision and recall,pythonx nlp,i think youre too caught up in the words positive and negative lets consider your sentence classification is binary its either a statement or a question so here we are considering statement positive question negative true positive your classifier predicted statement and it is a statement false positive your classifier falsely predicted statement positive when in fact the sentence is a question false negative your classifier falsely predicted question negative when in fact the sentence is a statement true negative your classifier predicted the sentence to be a question and it is a question i know tp is the number of documents that the tag of the test sentences equals to the tag of the classifier no that is tp tn number of statements correctly predicted number of questions correctly predicted fn is the number of documents that the tag of test sentences is not equal to the tags that the classifier found that is fp fn number of statements you tagged as questions number of questions you tagged as statements again positive and negative are just classes
39707654,what are derivationally related forms in wordnet,nlp wordnet,from the wordnet glossary derivationally related forms terms in different syntactic categories that have the same root form and are semantically related the verb to butter has the same root form as the noun butter they are different syntactic categories verb vs noun and theyre clearly semantically related on the other hand television and telescope do not have the same root form but eg to televise would have the same root as television and telescopic has the same root as telescope moreover they are not semantically related and they are both nouns
39462199,differentiate between sentences that have the same meaning but use different word combinations,machinelearning nlp deeplearning,one of deep learning based solution would be to use word embeddings which ideally should represent a word by a fixed dimensional vector such that similar words lie close in that embedding space and even vector operations like germany berlin italy rome may hold two famous word embeddings techniques are wordvec and glove another option is to represent a sentence by a fixed dimensional vector such that similar sentence lie close in that embedding space check skipthought vectors until now we have only tried to represent text wordssentences in a more semantic numerical way next step is to capture the meaning of the current context paragraphs documents a very naive approach would be to just average wordsentence embeddings you have to try this to see if it works or not better way would be to use some kind of sequence model like rnn actually lstm or gru to capture whatever has been said before the problem in using sequence models is that it will need supervision you should have a labelled data but if you dont have it which i guess is the case then just use sequence models in a language modelling setting and get the hidden representation of rnngrulstm at last time step ie after reading the last word or the aggregated word embeddings if you are using the naive approach once you have the hidden representation you may apply any clustering technique to cluster different paragraphs you have to find the appropriate distance metric or you can manually apply some distance metric and define or learn a threshold for similar paragraphs to be categorized as one
39255081,need references to understandanalyze a sentence for chatbot without using existing libraries,nlp artificialintelligence textanalysis,without using nlp libraries youll have to write some of their functionality yourself although this can be educational you should know it can also be very time consuming some academic resources christopher d mannings introduction to information retrieval manningjurafskys speech and language processing programmingpractical resources how to create your own customised chatbot for beginners chatbots be your own botmaster nltk book although this is a library the book and code base can be very educational chatbot tutorial
38986863,what is the difference between a trait freetext and keyword and which should i use in witai,nlp witai,trait when the entity value is not inferred from a keyword or specific phrase in the sentence there is no obvious association between certain words in the sentence and the value of the entity but rather you need the sentence as a whole to determine the value ex intent sentiment politeness free text when you need to extract a sub string of the message and this sub string does not belong to a predefined list of possible values ex message body contact name etc keywords when the entity value belongs to a predefined list and you just need sub string matching to look it up in the sentence ex country car make colours cuisines etc
37889914,what is a projection layer in the context of neural networks,machinelearning nlp neuralnetwork wordvec,i find the previous answers here a bit overcomplicated a projection layer is just a simple matrix multiplication or in the context of nn a regulardenselinear layer without the nonlinear activation in the end sigmoidtanhreluetc the idea is to project the eg kdimensions discrete vector into a dimensions continuous vector i chose the numbers here randomly your mileage may vary the exact matrix parameters are learned through the training process what happens beforeafter already depends on the model and context and is not what op asks in practice you wouldnt even bother with the matrix multiplication as you are multiplying a hot vector which has for the word index and s everywhere else and would treat the trained matrix as a lookout table ie the th word in the corpus the th rowcolumn depends how you define it in the projection matrix
37524799,what is the best way to do natural language processing in rails app,rubyonrails nlp nltk,i had the same problem a few months ago after a bit of research and testing this is the solution i implemented run several python processes as many as one machine can hold and use as many machines as you need use zeromq to communicate between the web servers and the machines running python processes do not use http to communicate because the overhead is significant and it will be very slow compared to zeromq you will also not need an as complex handler with zeromq as you would with http take care to expose zeromq sockets to internal networks only or you would need to set up authentication on each python server another option is to just use one of the many available nlp apis if dont need any corpus based algorithms such as pos tagging sentiment analysis etc
36997147,understanding anothers textmining function that removes similar strings,python r dictionary nlp tm,note the indentation in your code the else is lined up with the second for not the if this is a forelse construct not an ifelse in that case the else is being used to initialize the inner loop because it will be executed when sofar is empty the first time through and each time the inner loop runs out of items to iterate through i am not sure that this is the most efficient way to achieve these comparisons but conceptually you can get a sense of the flow with this snippet output i would think that in r there is a much better way to do this than nested loops
36856145,what are the spell correct apis available,api nlp spellchecking autocorrect,first of all you can write your own spell corrector with this tutorial in addition there are some python packages that may help you with that such as textblob which i highly recommend another option is gingerit which ive never tried but looks promising another diy spell correct tutorial might interest you as well
36034454,what meaning does the length of a wordvec vector have,python nlp gensim wordvec,i think the answer you are looking for is described in the paper measuring word significance using distributed representations of words by adriaan schakel and benjamin wilson the key points when a word appears in different contexts its vector gets moved in different directions during updates the final vector then represents some sort of weighted average over the various contexts averaging over vectors that point in different directions typically results in a vector that gets shorter with increasing number of different contexts in which the word appears for words to be used in many different contexts they must carry little meaning prime examples of such insignificant words are highfrequency stop words which are indeed represented by short vectors despite their high term frequencies for given term frequency the vector length is seen to take values only in a narrow interval that interval initially shifts upwards with increasing frequency around a frequency of about that trend reverses and the interval shifts downwards both forces determining the length of a word vector are seen at work here smallfrequency words tend to be used consistently so that the more frequently such words appear the longer their vectors this tendency is reflected by the upwards trend in fig at low frequencies highfrequency words on the other hand tend to be used in many different contexts the more so the more frequently they occur the averaging over an increasing number of different contexts shortens the vectors representing such words this tendency is clearly reflected by the downwards trend in fig at high frequencies culminating in punctuation marks and stop words with short vectors at the very end figure word vector length v versus term frequency tf of all words in the hepth vocabulary note the logarithmic scale used on the frequency axis the dark symbols denote bin means with the kth bin containing the frequencies in the interval k k with k these means are included as a guide to the eye the horizontal line indicates the length v of the mean vector discussion most applications of distributed representations of words obtained through wordvec so far centered around semantics a host of experiments have demonstrated the extent to which the direction of word vectors captures semantics in this brief report it was pointed out that not only the direction but also the length of word vectors carries important information specifically it was shown that word vector length furnishes in combination with term frequency a useful measure of word significance
35168281,what are the methods to estimate probabilities of production rules,nlp stanfordnlp contextfreegrammar,as i understand your question you are asking how to estimate the parameters of a pcfg model from data in short its easy to make empirical productionrule probability estimates when you have groundtruth parses in your training data if you want to estimate the probability that s np vp this is something like counts np vp counts where is any possible subtree you can find a much more formal statement in lots of places on the web search for pcfg estimation or pcfg learning heres a nice one from michael collins lecture notes
34607284,what are the languages available for graphlab stopwords,python nlp stopwords nonenglish graphlab,for now graphlab version theres only english stopwords available silly me after trying out
34363250,understanding wordvecs skipgram structure and output,vector machinelearning nlp wordvec,your understanding in both parts seem to be correct according to this paper the paper explains wordvec in detail and at the same time keeps it very simple its worth a read for a thorough understanding of the neural net architecture used in wordvec the structure of skip gram does use a single neural net with input as onehot encoded targetword and expectedoutput as onehot encoded context words after the neuralnet is trained on the textcorpus the input weight matrix w is used as the inputvector representations of words in the corpus and the output weight matrix w which is shared across all the c outputs outputvectors in the terminology of the question but avoiding that to prevent confusion with outputvector representations used next becomes the outputvector representations of words usually the outputvector representations are ignored and the inputvector representations w are used as the word embeddings to get into the dimensionality of the matrices if we assume a vocabulary size of v size of hidden layer as n we will have w as vn matrix with each row representing the input vector of the indexed word in the vocabulary w will be a nv matrix with each column representing the output vector of the indexed word in this way we get ndimensional vectors for words as you mentioned each of the outputsavoiding using the term output vector is of size v and are the result of a softmax function with each node in the output giving the probability of the word occurring as a context word for the given target word resulting in the outputs not being onehot encodedbut the expected outputs are indeed onehot encoded ie in training phase the error is computed by subtracting the onehot encoded vector of the actual word occurring at that context position from the neuralnet output and then the weights are updated using gradient descent referring to the example you mentioned with c and with a vocabulary of quick fox jumped lazy dog if the output from the skipgram is where the correct target word is fox then error is calculated as and the weight matrices are updated to minimize this error
34361634,what is the difference between semantic in nlp and semantic in ontology,nlp semanticweb ontology,as you can find from a quick search semantics is the branch of linguistics and logic concerned with meaning the two main areas are logical semantics concerned with matters such as sense and reference and presupposition and implication and lexical semantics concerned with the analysis of word meanings and relations between them this is the correct definition for nlp semantics for semantic web semantics is specifically the semantics of logical languages defined for the semantic web ie rdf rdfs owl and the main difference between the semantics of these languages and that of other languages logical and not is the restrictions that are applied to rdfs and owl dl to make them machine understandable this means that in these languages all implications can be made explicit in finite time you can find a lot of material on rdfs and owl on the wc pages
33677687,what is a regular expression for parsing out persian individual sentences,c regex nlp textprocessing,how about this demo which matches everything that doesnt include those characters then a punctuation
33543446,what is the formula of sentiment calculation,nlp sentimentanalysis mining,there are several methods for computing an index from scored sentiment components of sentences each is based on comparing positive and negative words and each has advantages and disadvantages for your scale a measure of the central tendency of the words would be a fair measure where the denominator is the number of scored words this is a form of the relative proportional difference measure employed below you would probably not want to divide the total sentiment words scores by all words since this makes each sentences measure strongly affected by nonsentiment terms if you do not believe that the point rating you describe is accurate you could just classify it as positive or negative depending on its sign then you could apply the following methods where you have transformed where each p and n refer to the counts of the positive and negative coded sentiment words and o is the count of all other words so that the total number of words p n o absolute proportional difference bounds sentiment p n p n o disadvantage a sentences score is affected by nonsentimentrelated content relative proportional difference bounds sentiment p n p n disadvantage a sentences score may tend to cluster very strongly near the scale endpoints because they may contain content primarily or exclusively of either positive or negative logit scale bounds infinity infinity sentiment logp logn this tends to have the smoothest properties and is symmetric around zero the is a smoother to prevent log for details please see william lowe kenneth benoit slava mikhaylov and michael laver scaling policy preferences from coded political texts legislative studies quarterly feb where we compare their properties for measuring rightleft ideology but everything we discuss also applies to positivenegative sentiment
32812342,what is the data dictionary in nlp,java machinelearning nlp stanfordnlp opennlp,first of all learning like in any subject takes time so dont rush it or you will confuse yourself the output syntax you see is a tree which take on the form of a series of lists and embedded lists it may remind you of the syntax of a popular lisp such as scheme or clojure the tags to the left of the words lists are what is known as pos partofspeech tags that represent the grammatical category the word falls into essentially a wordcategory disambiguation pos tagging is still one of the very difficult research areas of natural language processing as a subject with fscores in their high s your tree snippet built out with the list below looks as follows pos tagging is a great linguistic feature for tasks such as semantic parsing or named entity recognition some good resources to learn from include nltk natural language toolkit book chapter foundations of statistical natural language processing part of speech tagging and partial parsing list of partofspeech tags penn treebank corpus cc coordinating conjunction cd cardinal number dt determiner ex existential there fw foreign word in preposition or subordinating conjunction jj adjective jjr adjective comparative jjs adjective superlative ls list item marker md modal nn noun singular or mass nns noun plural nnp proper noun singular nnps proper noun plural pdt predeterminer pos possessive ending prp personal pronoun prp possessive pronoun rb adverb rbr adverb comparative rbs adverb superlative rp particle sym symbol to to uh interjection vb verb base form vbd verb past tense vbg verb gerund or present participle vbn verb past participle vbp verb nonrd person singular present vbz verb rd person singular present wdt whdeterminer wp whpronoun wp possessive whpronoun wrb whadverb
32390030,what are the methods except bag of words tfidf for converting textual features into numerical features,machinelearning nlp randomforest tfidf,the question is really how do i enumerate the possible inputs this is one of those rare situations where really the only real limit is your imagination but a simple approach is to just catalog the possible permutations and assign a number to each with a riduculously small lexicon you could assign a number to each possible permutation of the words in the lexicon if your vocabulary is bag of words you could assign the numbers and perhaps a few more to cater for an empty slot but for a large dictionary clearly this isnt feasible perhaps if you instead assign a number identifier to each word then you can do something like to obtain the number for the permutation bag of words or if you want to emphasize the context maybe assign binary features and apply a multiplier to the central word would obtain for the head word of surrounded by the leading context bag and the trailing context words what makes sense depends on your application its easy to come up with niche applications where it might make sense to count the number of occurrences of the letter b or whatever and simply directly use the metric you are interested in as the identifier
31844602,algorithms for natural language understanding,patternmatching nlp semantics stanfordnlp lexicalanalysis,one way stanford corenlp could help you is its tokensregex functionality with this tool you can write explicit patterns and then tag them in your input text then your code can react based on the presence of certain patterns here are some links with more info i would recommend identifying common expressions that you want to handle that deserve a clear response and build up so you get decent coverage of what users input for instance obviously you could combine these rules and make them increasingly complicated but i think a straight forward approach would be to think of the various ways one might express they want to begin and then capture that with rules
31789934,what is the difference between comparable corpus and parallel corpus,nlp corpus,a comparable corpus is a pair of corpora in two different languages which come from the same domain as defined in the statistical machine translation survey wiki a parallel corpus is a specific type of comparable corpus where the text is paired with its translation into a second language there are many machine translation papers that assume this definition for example the main paper from the europarl project
31767931,what is the annotation class used to get result data from matched token in stanford corenlp tokensregex,c net nlp stanfordnlp,im not sure what you would like to get each token in matchedtokens has the same annotations as other tokens in the sentence if you want to get the first capture group the ner person part then you should use matchergroup or matchergroupnodes see for other functions on the matched result
31526644,what is the difference between corpus and lexicon in nltk python,machinelearning nlp nltk corpus lexical,corpora is the plural for corpus corpus basically means a body and in the context of natural language processing nlp it means a body of text source lexicon is a vocabulary a list of words a dictionary source in nltk any lexicon is considered a corpus since a list of words is also a body of text eg a list of stopwords can be found in nltk corpus api the movie review dataset in nltk canonically known as movie reviews corpus is a text dataset of k movie reviews with sentiment polarity classification source and it is often used for tutorial purposes for introduction to nlp and sentiment analysis see and nltk naivebayesclassifier training for sentiment analysis wordnet is lexical database for the english language its like a lexicondictionary with wordtoword relations source in nltk it incorporates the open multilingual wordnet that allows you to query the words in other languages since it is also a list of words in this case with many other things included relations lemmas pos etc its also invoked using nltkcorpus in nltk the canonical idiom to use the wordnet in nltk is as such the easiest way to understandlearn the nlp jargons and the basics is to go through these tutorial in the nltk book
31268796,concept based text summarization abstraction,machinelearning nlp summarization,i dont know any open source project which fits your requirements about abstraction and a meaning as i assume but i have an ideas how to build such engine and how to train it in a few words i think we all keep in mind some bayesiannetwork like structure in our minds with helps us not only to classify some data but also to form an abstract meaning about text or message since it is impossible to extract all that abstract categories structure from our mind i think its better to build mechanism which allow as to reconstruct it stepbystep abstract the key idea of the proposed solution is in the extraction of meaning of a conversation using approaches which easier in operation with it from an automated computer system this will allow creating the good level of illusion of real conversation with another person proposed model supports two levels of abstraction first of them less complex level consists in the recognition of groups of words or a single word as a group which related to the category instance or to the instance attribute instance means instantiation from the general category of the real or abstract subject object action attribute or other kind of instances as an example concrete relation between two or more subjects concrete relations between employer and employee concrete city and country where its situated and so on this basic meaning recognition approach allows us to create bot with ability sustain a conversation this ability based on recognition of basic elements of meaning categories instances and instances attributes second the most complicated method based on scenario recognition and storing them into the conversation context with instancescategories as well as using them for completion some of recognized scenarios related scenarios will be used to complete the next message of the conversation as well as some of scenarios can be used to generate the next message or for recognizing meaning element by using of conditions and by using meaning elements from the context something like that basic classification should be entered manually and with future correctionaddition of the teachers words from sentence in conversation and scenarios from sentence can be filled from context conversation scenarioscategories can be fulfilled by previously recognized instances or with instances described in future conversation selflearning pic word detectioncategorization basically flow vision pic general system vision big picture view pic meaning element classification pic basically categories structure could be like that
31178216,what is the nltk equivalent of the uima cas common annotation structure,nlp nltk uima,in short there is no equivalent concept to the cas common analysis system in nltk the latter uses much simpler means of representing texts than does uima in nltk texts are simply lists of words whereas in uima you have very complex and heavyweight data structures defined as part of the cas for the purpose of describing the input data and its flow through a uima system that being said i view the two of them to serve quite different purposes anyway if i was to name a java equivalent for nltk i would choose the opennlp toolkit rather than uima the former offers a number of algorithms for nlp based on machine learning as does nltk among other things while the latter is a componentbased framework not only for nlp but unstructured data in general that is it defines a general model for building applications working with unstructured data
31108036,how extracting meaning of sentences for sentiment analysis using nlp,nlp sentimentanalysis,to categorize entities of a sentence or a sentence as a whole you first need to have defined set of classescategoriesgroups for eg to categorize journey to travellingdriving you should train your systemalgorithm to identify specific pattern of sentences which will fall under the category of drivingjourney this training involves concepts of machine learning text categorization is what you should be searching for here is a reference to just give you an idea and you can find many more over the web good luck note below are some links from coursera which offers a course on nlp link link
30858844,what is the default behavior of stanford nlps wordstosentencesannotator when splitting a text into sentences,nlp stanfordnlp,it does split on these characters however only when they appear as their own token and not at the end of an abbreviation such as in etc so the issue here is not the sentence splitter but the tokenizer which thinks that n is an abbreviation and therefore does not split n into two separate tokens if you know in advance that your text doesnt contain any abbreviations the easiest thing to do is to split all tokens that contain a period at the end before you process them with corenlp your input would then be d r e l i n okay in case your input also contains abbreviations things are a bit more complicated as youll have to edit the rules of the tokenizer see stanford corenlp splitting sentences abbreviation exceptions for a highlevel description on how to edit the rules of the tokenizer
29915993,what is the most efficient way of storing language models in nlp applications,nlp ngram languagemodel,the most common data structures in language models are tries and hash tables you can take a look at kenneth heafields paper on his own language model toolkit kenlm for more detailed information about the data structures used by his own software and related packages
29575784,what is distant supervision,nlp stanfordnlp supervisedlearning unsupervisedlearning,re yes this is exactly right in the end what we want is a classifier that takes as input text and a pair of entity mentions in the text and tells us what relation holds between those entities in that sentence distant supervision is a way of mocking this training data using distant supervision from a known knowledge base but the end goal is the same as most machine learning tasks generalize to new sentences re certainly distant supervision only applies to how the training data is generated once youve assumed distant supervision what youre left with is a corpus of sentence relationforsentence pairs and then you extract all of the usual nlp features on the sentence to a first approximation there are distantly supervised models like multir and mimlre which dont directly generate fake training data but incorporate the supervision indirectly into the training procedure itself but even in these there is a factor in the latentvariable model that amounts to a persentence classification and its just that the output variable is latent rather than naively observed as in vanilla distant supervision
29367964,given html file extract just meaningful text,java algorithm nlp jsoup,you can use boilerpipes article extractor if your input is a news site and some other extractor types also available in boilerpipe in jsoup you can use selector concept
29078792,what is the most efficient way to convert spoken language dates to a normalized form,nlp spokenlanguage,i have searched through the internet and found that i can do it with writing rules and patterns the olympus system is a complete dialog system that provides good ways of doing this through its datetime binding filters
27975767,what are and nltk,python nlp nltk semantics firstorderlogic,see nltksemlogicexpression is this is the base abstract object for all logical expressions there are many types of logical expressions implemented in nltk see line the applicationexpression is this class is used to represent two related types of logical expressions the first is a predicate expression such as pxy a predicate expression is comprised of a functionvariableexpression or constantexpression as the predicate and a list of expressions as the arguments the second is a an application of one expression to another such as xdogxfido the reason predicate expressions are treated as application expressions is that the variable expression predicate of the expression may be replaced with another expression such as a lambdaexpression which would mean that the predicate should be thought of as being applied to the arguments the logical expression reader will always curry arguments in a application expression so x yseexyjohnmary will be represented internally as x yseexyjohnmary this simplifies the internals since there will always be exactly one argument in an application the str method will usually print the curried forms of application expressions the one exception is when the the application expression is really a predicate expression ie underlying function is an abstractvariableexpression this means that the example from above will be returned as x yseexyjohnmary im not exactly an expert in formal logics but your code above is trying to declare a logical function variable x for a crash course see and a nltk crash course to lambda expressions see
27860652,what is the concept of negativesampling in wordvec,machinelearning nlp wordvec,the idea of wordvec is to maximise the similarity dot product between the vectors for words which appear close together in the context of each other in text and minimise the similarity of words that do not in equation of the paper you link to ignore the exponentiation for a moment you have the numerator is basically the similarity between words c the context and w the target word the denominator computes the similarity of all other contexts ci and the target word w maximising this ratio ensures words that appear closer together in text have more similar vectors than words that do not however computing this can be very slow because there are many contexts ci negative sampling is one of the ways of addressing this problem just select a couple of contexts ci at random the end result is that if cat appears in the context of food then the vector of food is more similar to the vector of cat as measures by their dot product than the vectors of several other randomly chosen words eg democracy greed freddy instead of all other words in language this makes wordvec much much faster to train
27830026,finding probable number of meaningful english words for given number of blank spaces,java javascript nlp,if youre on a mac theres a list of all english words at usrsharedictwords theres word per line so you can read in that file split it by newline characters n store them in some object if youre always going to be looking for words based on length you may also want to read the length of each word while your parsing for new lines and put it in an appropriate array for example have some dictionary object with arrays for words of length character characters characters etc
27697766,understanding mindf and maxdf in scikit countvectorizer,python machinelearning scikitlearn nlp,maxdf is used for removing terms that appear too frequently also known as corpusspecific stop words for example maxdf means ignore terms that appear in more than of the documents maxdf means ignore terms that appear in more than documents the default maxdf is which means ignore terms that appear in more than of the documents thus the default setting does not ignore any terms mindf is used for removing terms that appear too infrequently for example mindf means ignore terms that appear in less than of the documents mindf means ignore terms that appear in less than documents the default mindf is which means ignore terms that appear in less than document thus the default setting does not ignore any terms
27558629,understanding accuracyscore with scikitlearn with my own corpus,python machinelearning nlp scikitlearn,there is a small error in your example the line is wrong there should be a tag for each example sentencedocument in your corpus so tags should be not but the length of your trainset the same applies for the test set you should have a variable testtags that is the same length as testset these tags are normally a column inside the file testtxt but you might get it from somewhere else this would be your ytrue when you predict on the test set you will get a vector of the same length as testset ie a tag prediction for each example in your test set this is your ypred i omitted some details related to the multiclass vs single class case material for another question but this should answer your question
27416164,what is conll data format,nlp textparsing textmining informationextraction,there are many different conll formats since conll is a different shared task each year the format for conll is described here each line represents a single word with a series of tabseparated fields s indicate empty values mateparsers manual says that it uses the first columns of conll the definition of some of these columns come from earlier shared tasks the conllx format used in and id index in sentence starting at form word form itself lemma words lemma or stem pos part of speech feat list of morphological features separated by head index of syntactic parent for root deprel syntactic relationship between head and this word there are variants of those columns eg ppos but not pos that start with p indicate that the value was automatically predicted rather a gold standard value update there is now a conllu data format as well which extends the conllx format
27347555,what is the standard way in scikitlearn to arrange textual data for text classification,python machinelearning nlp scikitlearn,your question is very vague there are books and courses on the subject you can access have a look at this blog for a start and these course and
26988686,online documentation explaining tags output by stanford nlp parser,parsing nlp stanfordnlp,for grammatical dependencies nsubj poss you can read the official manual tags like nn vbz are partofspeech tags you can find info about them here or by googling partofspeech tags penn treebank
26947373,extracting the meaning of a sentence,java machinelearning nlp,use gate a nlp machine learning tool you can use annie for splitting sentences and pos tagging you have to prepare training dataset with sentiments already annotated manually and then use batch learning plugin to predict sentiment for training documents stepbystep tutorial for this and the example talked about in the pdf
26879761,what is pos of or in wordnet via nltk,nlp nltk wordnet,see
26716622,how to automatically detect acronym meaning extension,nlp informationextraction acronym,reading your question and the comments i understand that you want to create a mapping from an acronym to its extension assuming you have a collection of textual documents where both the acronym and its expansion occur you can apply an algorithm to extract acronymextension pairs a simple algorithm for identifying abbreviation definitions in biomedical text by as schwartz and ma hearst does exactly this by looking at patterns the java implementation is available here i applied this algorithm to the english wikipedia you can see the results here i also applied it to a collection of portuguese new articles results are here
26455860,concepts extraction from stanford parsing tree nlp,nlp stanfordnlp,your definition of concepts is not perfectly clear to me but take illinois shallow parser might be useful for this see a demo here
25902119,scikitlearn tfidfvectorizer meaning,machinelearning nlp scikitlearn featureextraction documentclassification,tfidfvectorizer transforms text to feature vectors that can be used as input to estimator vocabulary is a dictionary that converts each token word to feature index in the matrix each unique token gets a feature index what iseg ume it tells you that the token me is represented as feature number in the output matrix is this a matrix or just a vector each sentence is a vector the sentences youve entered are matrix with vectors in each vector the numbers weights represent features tfidf score for example julie tells you that the in each sentence julie appears you will have nonzero tfidf weight as you can see in the nd vector the th element scored the tfidf score for julie for more info about tfidf scoring read here
25108053,what is the accuracy of nltk postagger,python nlp nltk postagger,nltk default pos tagger postag is a maxent tagger see line from out
24384758,machine understand natural language nlp,machinelearning nlp,check these out in that order natural language tool kit nltk main pageit is in pythonbuilding a machine learning class around nltk and making an actual application out of it this should give you a great foundation for building nlp applicationsprovided your nlp fundamentals are strong
24317095,what is one way to find related names using the web,python nlp,you can use freebase for example the univerisity of california berkeley page has a field commontopicalias in which it lists different common names for this university although some of them might be noisy
23341858,what is the meaning of this nlp notation,machinelearning nlp,that means that f is a function which takes an input and an output and produces a vector in this context the input is usually a word sequence and the output a candidate labeling of that word sequence eg a sequence of partofspeech tags or a parse tree there are some examples on slide of ryan mcdonalds slide deck linked in the question mcdonald makes this point too but ill repeat it here in some cases we can produce a feature vector purely from the input sequence without reference to an output eg if were tagging word of the sentence f is a function and our feature mapping included only the current word and the previous word wed incorporate f as the previous word and is as the current word but in some cases notably structured prediction well want to include features depending on a candidate labeling as well perhaps a label sequence over the entire input note that that will usually result in a huge feature space one other note mcdonalds mapping is to a realvalued vector rn but in nlp we often find that indicator features are sufficient so many systems us a bit vector instead still in a very high dimensional space the formalism doesnt change only the mapping function f but the simplifying assumption will often allow efficiencies in the weight vector storage and dotproduct implementation
23117979,the distance between the meaning of two sentences,nlp semantics linguistics semanticanalysis,as rob pointed out this is a very hard problem it requires the program to not only understand linguistic semantics but also have encyclopedic knowledge for example when we say the beautiful cherry blossoms in japan are we talking about a cherry that is beautiful and happens to blossom in japan or are we talking about a single collective entity cherry blossoms which are beautiful and happen to be in japan this requires a combination of encyclopedic and linguistic knowledge from a purely encyclopedic perspective consider the sentences the beautiful cherry blossoms in japan the beautiful sakura in japan the beautiful flowers in japan the first two are identical while the third is closely related but not identical establishing sentence distance based on this kind of knowledge is beyond the scope of just a grammatical analysis and require the use of external ontologies eg sakura cherry blossom and that cherry blossom isa flower having said that there is a little bit that can be done based on parse trees of sentences for example if you look at the constituency parse trees of the two sentences you provided you will be able to break them down into phrases np vp etc for many examples it will suffice to define the distance between two sentences as the max of the distance between its constituent phrases where the distance between phrases can in turn be based on lexical databases such as wordnet or ontologies such as yago for wordnet a readily available package to measure semantic distances is the javabased package wsj they have an online demo as well these semantic distances are based on the pathdistance between two terms in the ontology graph except lesk which simply calculates the overlap of terms in dictionary glosses this is far far away from a complete solution to the problem of measuring semantic distance but i hope it will give you a starting point
22848846,extracting only meaningful text from webpages,python webscraping nlp nltk,i think what you are looking for is the stopwordswords from nltkcorpus edit searching for stopword give possible duplicates stopword removal with nltk how to remove stop words using nltk or python see the answers of these question and consider effects of stemming on the term frequency too
22452713,search similar meaning phrases with nltk,python search nlp nltk,the way i would do it is the following use nltk to find nouns followed by one or two verbs in order to match your exact specifications i would use wordnet the only nouns nn nnp prp nns that should be found are the ones that are in a semantic relation with physical or material and the only verbs vb vbz vbd etc that should be found are the ones that are in a semantic relation with fall i mentioned one or two verbs because a verb can be preceded by an auxiliary what you could also do is create a dependency tree to spot subjectverb relations but it does not seem to be necessary in this case you might also want to make sure you exclude location names and keep person names because you would accept john has fallen but not berlin has fallen this can also be done with wordnet locations have the tag nounlocation i am not sure in which context you would have to convert the tags so i cannot provide a proper answer to that in seems to me that you might not need that in this case you use the pos tags to identify nouns and verbs and then you check if each noun and verb belong to a synset hope this helps
21444074,what are the applications of length normalization,nlp normalization,the link you provide in the question already mentions one reason for using lengthnormalization to avoid having high termfrequency counts in document vectors this affects document ranking considerably a direct application of this is of course querybased document retrieval there are other algorithmspecific applications as well for example if you want to cluster documents using cosine similarity between the vectors simple clustering algorithms such as kmeans may not converge unless the vectors are all on a sphere ie all vectors have the same length
21318791,how to get all the meanings of a word using python nltk,python nlp nltk wordnet,to know which word have the samesimilar pos tag you can use the idiomatic then to get the possible synsets for a word simply do most probably the solution youre looking for is
20988969,the meaningimplication of the matrices generated by singular value decomposition svd for latent semantic analysis lsa,machinelearning nlp datamining textmining lda,i warmly recommend reading the information retrieval chapter in the snlp bible by manning and schutze in pages it explains everything you want to know about lsi and svd you will find paragraphs like this
20930155,how to extract meaningful words from messy strings,python regex nlp,in short the examples you provide cannot be assessed in the way you want them to be unless you skew your decision tree or classifier to your particular data consider for example numbers and prod is a word in any english dictionary but info wont necessarily show up in most english dictionaries if you train your classifier or decision tree on these specific data only then will you get the result you want but generally speaking you might try tokenizing your text to begin with as user has suggested then you might be able to find further possibile words with regular expressions such as this this regular expression will find all sequences that begin with an uppercase letter and that are then followed by or more lowercase letters regarding your comment no this regex will not work for unicode unfortunately regular expressions in python do not presently have the capability to distinguish between upper and lowercase in the same fashion in this case you might need something like this which i have thrown together fairly quickly without taking the time to make it pretty then as acarlon has suggested you will start needing to check substrings against a dictionary such as pyenchant but even then you will find meaning where no one may have meant to impart it and further you will discover words that do not interest you such as prod
20814189,what are some simple nlp projects that a cs undergrad can try implementing,nlp artificialintelligence computerscience,there are plenty of them here is a list of different nlp problems spam detection text genre categorization news fiction science paper finding similar texts for example search for similar articles find something about author genre nativespeakernonnativespeaker create automatic grader for students work check text for plagiarism create an application that looks for grammatical errors pretty much any conference paper can give an idea about an nlp project for example you can think about text summarization lemmatisation tokenization correct splitting text in sentences etc
20335572,what is part of speech pos tag in natural language processing,nlp datamining stanfordnlp,the stanford nlp documentation refers to the penn treebank documentation for the precise definitions however if prp personal pronoun and vbp presenttense verb were hard to guess perhaps you should start with some nlp fundamentals before attempting this a partofspeech tagger as such does not perform any sort of sentiment analysis
20168457,how to control what is displayed on a jtextarea,java swing nlp,dont use a keylistener for this if you need to process the input before it is displayed this would be considered filtering the input and in this situation you will want to set your jtextareas documents documentfilter via setdocumentfilter for example please have a look at my answer and code to this question
19262597,why no programming in english what is the difference between natural languages and programming languages,languageagnostic programminglanguages nlp,this is an extremely interesting question and in short yes there are some very good reasons why we dont use english to write programs its been said before that the greatest gift that computer science has given us is not the ability to talk to computers but now that formal languages exist for describing algorithms we now have even better tools for communicating these ideas to other people even if a computer is not involved indeed the best software engineers see their jobs primarily as writing software that is readable to other people so as to make maintenance and addition of new features as easy as possible this is not possible in a language as big and as free form as any natural spoken language ambiguity one reason is that of ambiguity have you ever looked a menu in a restaurant and seen that with your burger you can get coleslaw and fries or salad what does this mean can i get both coleslaw and fries or the other option is a salad alone or do i always get coleslaw and i have to chose between the fries or a salad english is full of these things i used to teach a class on this and an example i liked to use to explain ambiguity was as follows i asked the students to write a one paragraph story ending with the sentence tom asked chris if he could help him about half the time the stories written indicated that the student interpreted the sentence as tom asking for assistance from chris the other half of the time people thought tom was offering to lend chris a hand if you think about it there are a lot of people who do write programs in english theyre called product managers and the compiler they use is software engineers the problem here is that a software engineer has to inject a lot of his own understanding of the problem to understand what the description really means and trust me there is a lot of back and forth even on very simple business requirements i must clarify ambiguities context i would not agree that lawyers have ways to solve the context problem we continually have ongoing arguments in courts among in some cases some of the most educated people in the country about the meanings of various laws sometimes this involves arguing about the context in which the laws were written long ago sometimes in involves applying it to a new previously nonexistent context like the internet the fact that we have thousands of lawyers working on disambiguating these issues is proof that it cannot be handled by a simple computer program like a compiler its just too hard of a problem conciseness another issue is just the ability to be concise mathematics long ago invented notations for many different concepts in the maths because its just easier to read if theres a special syntax that is concise and has a well defined meaning a mathematician knows what it means when i say fx x it means the same thing as there is a function called f and it has one argument the value of applying f to a number is the number that is one more than three times the number given but the former is a lot easier to read once youve learned the syntax the same is true for programming languages programming languages are specialized to describe computations implementation creators of programming languages deliberately create very small languages these are in fact subsets of english also with some extra syntax the idea of understanding all of english in all of its free form ways and worse yet increasing vocabulary is a job for natural language processing npl a very hard job if you want to be able to assign unambiguous meaning to a program and have the programs behavior never change you need a well defined syntax and semantics the takeaway point here is that english is a very big very flexible language with no formal specification programming languages need to have a welldefined syntax and semantics in order for algorithms to have unambiguous and unchanging meaning someone could in fact write a formal syntax for a subset of english and give it unambiguous meaning but this would be a huge huge job its been done check out babelbuster the idea here was to take c and convert it to and from a very small subset of very rigorous english such that one could write a program in c and then convert it to english during the decss dvd decryption arguments the mpaa was trying to get programs that could decrypt their dvds declared illegal babelbuster fought back with a very interesting idea create a way to convert english which is protected under the freedom of speech into working code in c and thus make the point that c code is also just a language which should be protected as such therefor one should be able to publish code that cracks decss its an interesting piece of work relevant to your question regardless of which side youre on the problem with babelbuster is that you need to write your program in a very very limited subset of english but it is possible to do this conclusion english like all natural languages allows us to describe a computation or algorithm but the language is verbose offers many ways to say the same thing is dependent on the context of the speaker and not formally specified if your goal is to describe computations you should take english chose a minimal workable subset in which you can say everything you need formally specify what each word in this subset will mean then create a few special notations to make it concise to say the things you say just like mathematics did if you do this you do this youll end up with a typical programming language or something like it
19080284,how to tell if a word is meaningless in text,java rss hashmap nlp searchengine,in solr i believe these are called stopwords i believe they just use a text file to define all the words that they will not search on
18754589,what is the difference between evaluation metrics and features in relation to binary classification,machinelearning nlp,it seems that you are completely missing the meaning of basic concepts here evaluation metric is a function which given some modelalgorithm answers and some golden standard true answers provided by an expert measures how good is your modelalgorithm it has nothing ok not nothing as it is often used during crossvalidation and tuning models parameters to do with the actual classification process it is not used to make any decisions it is a method of quantifing how good are your results features are just data representation so there are related in the sense that they are part of the problem and obiously correct choice of features also called feature engineering has a big impact on the quality of your model but a possible feature of the data which then could be used to classify inputs into having this feature or not is rather meaningless feature is a value of some function often called feature detector lets call it f which applied to your input object x returns some value for example number or a there is notthere is representation of some phenomen for example such feature could be for text documents does given text contain substring in the past and so fi like trainsfalse and fi liked trains in the past true you do not train classifier to detect features you extract them using some simple efficient algorithm to represent your data which is then used to classify them to some classes once you have f there would be no point in classify inputs into having this feature because f does exactly this of course it is possible to actually train classifiers for filling in missing features when they are not avaliable for some data points but this is a more advanced topic and it does not seem to be the part of your question i would recommend you to watch some great introduction videos into machine learning by andrew ng avaliable on the coursera platform
18705778,what is the use of brown corpus in measuring semantic similarity based on wordnet,nlp similarity wordnet corpus semanticanalysis,take a look at the explanation at the nltk howto for wordnet specifically the ic notation is information content synsetressimilaritysynset ic resnik similarity return a score denoting how similar two word senses are based on the information content ic of the least common subsumer most specific ancestor node note that for any similarity measure that uses information content the result is dependent on the corpus used to generate the information content and the specifics of how the information content was created a bit more info on information content from here the conventional way of measuring the ic of word senses is to combine knowledge of their hierarchical structure from an ontology like wordnet with statistics on their actual usage in text as derived from a large corpus
18473958,what is zone hashing in natural language processing,nlp informationretrieval,as far as i know zone hashing is not a well established concept in the nlp as a discipline it is just a simple concept used in some algorithms related to nlp the only one i know which uses it is a sphinx search server and here zone hashing is simply hashing of objects called zones where zone is described as follows zones can be formally defined as follows everything between an opening and a matching closing tag is called a span and the aggregate of all spans corresponding sharing the same tag name is called a zone for instance everything between the occurrences of and in the document field belongs to h zone zone indexing enabled by indexzones directive is an optional extension of the html stripper so it will also require that the stripper is enabled with htmlstrip the value of the indexzones should be a commaseparated list of those tag names and wildcards ending with a star that should be indexed as zones zones can nest and overlap arbitrarily the only requirement is that every opening tag has a matching tag you can also have an arbitrary number of both zones as in unique zone names such as h and spans all the occurrences of those h tags in a document once indexed zones can then be used for matching with the zone operator see section extended query syntax and hashing of these structures is used in the traditional sense to speed up search and lookup i am not aware of any deeper meaning perhaps it refers to locality sensitive hashing locality sensitive hashing is a probabilistic method for multi dimensional data i do not see any deeper connections to the zone hashing then fact that both use hash functions
18369515,natural language understanding api,php nlp artificialintelligence freebase nlpquestionanswering,this is a great question natural language understanding is a difficult problem and there arent a lot of dropin solutions out there the problem that youve described eg how tall is mount everest is actually better known as question answering here is some research into question answering that used freebase data including ibms watson computer here are some templates in freebase that map freebase properties to english sentences here is a simple open source app that i built which does some basic question answering using the freebase apis the quepy project uses python to do question answering using either dbpedia or freebase data please let us know what else you discover theres certainly a lot more that we could be doing in this area
17724164,stanford ner prop file meaning of distsim,nlp stanfordnlp namedentityrecognition,distsim refers to using features based on word classesclusters built using distributional similarity clustering methods eg brown clustering exchange clustering word classes group words which are similar semantically andor syntactically and allow an ner system to generalize better including handling words not in the training data of the ner system better many of our distributed models use a distributional similarity clustering features as well as word identity features and gain significantly from doing so in stanford ner there are a whole bunch of flagsproperties that affect how distributional similarity is interpretedused usedistsim distsimlexicon distsimfileformat distsimmaxbits caseddistsim numberequivalencedistsim unknownworddistsimclass and you need to look at the code in nerfeaturefactoryjava to decode the details but in the simple case you just need the first two and they need to be used while training the model as well as at test time the default format of the lexicon is just a text file with a series of lines with two tab separated columns of word clustername the cluster names are arbitrary
17247874,what is the difference between information extraction and text mining,nlp informationretrieval textmining informationextraction,information extraction ie is the task of automatically extracting structured information from unstructured andor semistructured machinereadable documents in most of the cases this activity concerns processing human language texts by means of natural language processing nlp recent activities in multimedia document processing like automatic annotation and content extraction out of imagesaudiovideo could be seen as information extraction text mining is the activity of obtaining information resources relevant to an information need from a collection of information resources searches can be based on metadata or on fulltext indexing text mining is vast area as compared to information retrieval typical text mining tasks include document classification document clustering building ontology sentiment analysis document summarization information extraction etc where as information retrieval typically deals with crawling parsing and indexing document retrieving documents source
14765632,what is a relatively simple way to determine the probability that a sentence is in english,python string nlp bayesian,a bayesian classifier would be a good choice for this task
13016469,detecting meaningless andor grammatically incorrect sentence with languagetool,java nlp grammar textprocessing languagetool,languagetool is rule based obviously the sentence eat i rice every day and go school to good as a boy is not catched by any of the rules yet has the info on how to add userdefined rules to languagetool here is an example of such a rule thathadswillmustcouldcanshouldwoulddoesdidmaymighttlet feelhearseewatchpreventhelpstopbe plower the proper name in singular must be used with a thirdperson verb grammatical problem ann walk to the building bill walks to the building guinness walked to the building roosevelt and hoover speak each others lines boys are at higher risk for autism than girls in reply he said he was too old for this i can see bill looking through the window richard j hughes made his morris county debut in his bid for the democratic gubernatorial elections last night got its sevenconcert beethoven cycle at carnegie hall off to a good start and through knowing him better to become happier and more effective people there is an online rule editor available at a simple solution to the problem would be eat i instead of it should be wrong order of verb and nown eat i rice i eat rice but of course this would only cover the verb eat but i hope you get the picture how it works
12918606,what is the default nltk part of speech tagset,python nlp nltk,ntlk uses penntreebank tagset have a look at this link
12821201,what are ngram counts and how to implement using nltk,python nlp nltk,i found my old code maybe its useful
12475733,how to extract meaningful keywords from a query,nlp informationretrieval,well what you are looking into a text analytics solution i have only used r for this purpose but one way to look at it is you need a list of words that you consider not meaningful keywords this is often called stop words you can find online lists of stop words for almost any popular language after doing this you might want to get a couple hundred inputs and calculate the frequency of every keyword there having already removed stop words as well as punctuation and having all text in lowercase and try to identify other keywords that you think are irrelevant and add them to your list of words to remove after this there are a ton of options you can explore an example would be stemming which is getting the core term of each word so that pages and page are considered the same keyword as you go deeper you will find a ton of stuff online to finetune your approach hope this helps
11798389,what nlp tools to use to match phrases having similar meaning or semantics,python nlp nltk latentsemanticindexing,if you have a big corpus where these words occur available you can train a model to represent each word as vector for instance you can use deep learning via wordvecs skipgram and cbow models they are implemented in the gensim software package in the wordvec model each word is represented by a vector you can then measure the semantic similarity between two words by measuring the cosine of the vectors representing th words semantic similar words should have a high cosine similarity for instance the value is made up just for illustration also from my experiments summing a relatively small number of words ie up to or words preserves the semantics for instance again just for illustration you can use this semantic similarity measure between words as a measure to generate your clusters
11697734,understanding brown tags,syntax nlp partofspeech,i can help you out on the whdeterminer its just a whword specifically what or which in the place of an ordinary determiner it replaces the the and in so doing shows that the speaker is unclear about which or what noun is verbing for example i milked the cow yesterday which cow did you milk yesterday see how the which replaces the the its even clearer in the form of an echo question you milked which cow yesterday similarly the possessive whpronoun takes the place of his her their our etc in a question whose cow did you milk yesterday i milked his cow yesterday the objective and nominative whpronouns meanwhile are true pronouns in that they help replace a noun phrase in its entirety whom did you milk who milked the cow hope this helps
11595754,what area of machine learning should i look into to automatically extract certain info from messages,nlp,in order to detect and label amounts dates person names and similar information you can use a technique called named entity recognition the stanford named entity recognizer comes with pretrained ready to use models you also use whatever labeled data you have generated so far to learn a custom model for your application the standard techniques used for this purpose are conditional random fields or sequence perceptron there are many toolkits implementing these models including wapiti a simple and fast discriminative sequence labelling toolkit sequor sequence labeler based on collinss perceptron
11479935,what area deals with the extraction of words with similar characteristics,python machinelearning nlp nltk,take a look at chapter of the nltk book from what you have described it sounds like a supervised classification technique based on feature characteristic extraction might be a good choice from the book a classifier is called supervised if it is built based on training corpora containing the correct label for each input you can use some of the data that you have manually encoded to train your classifier it might look like this next you can train your classifier on some of the data you have already tagged you should probably train on half of the data you already tagged that way you can test the accuracy of the classifier with the other half keep working on the features until the accuracy of the classifier is as you desire you can check individual classifications as follows if you are not familiar with nltk then you can read the previous chapters as well
10979434,given a huge set of street names what is the most efficient way to test whether a text contains one of the street names from the set,algorithm nlp,a simple solution would be to create a dictionarymultimap with firstwordofstreetnamefullstreetnames when you iterate each word in your sentence youll look up potential street names and check if you have a match by looking at the next words this algorithm should be fairly easy to implement and should perform pretty good too
10725256,how to evaluate and explain the trained model in this machine learning,statistics nlp machinelearning artificialintelligence datamining,yes fold cross validation this testing method has the common flaw of testing on the training set that is why the accuracy is inflated it is unrealistic because in real life your test instances are novel and previously unseen by the system nfold cross validation is a valid evaluation method used in many works
10625152,could lojban be used to perform better at natural language understanding than english,nlp artificialintelligence,i asked a similar question at the linguistics stack exchange the response i received was quite informative from user prash a few corrections lojban though a human language is not a natural language it is a conlang afaik there are no native speakers of lojban that would require teaching lojban as one of the primary languages to a very young child lojban is syntactically unambiguous and only mostly unambiguous semantically if there were a lojban programming language this should not matter because one would avoid writing semantically ambiguous forms like metaphors this question has come up on various forums for lojban prolog haskell etc the consensus on those forums seems to be that it is possible but no one has done it yet some people eg eg have attempted to implement such a thing but afaik for very limited domains
10565544,how to understand and add syllable break in this example,nlp machinelearning,the method described in the article is based on a statistical law allowing to compute the correct value observing a noisy value in other words nonsyllabified word is noisy or incorrect like picnic and the goal is finding a probably correct value which is picnic here is an excellent video lesson on very this topic scroll to but the whole set of lectures worth watching this method is specifically useful for word delimiting but some use it for syllabification as well chinese language has space delimiters only for logical constructs but most words follow each other with no delimiters however each character is a syllable no exception there are other languages that have more complicated grammar for instance thai has no spaces between the words but each syllable may be constructed from several symbols eg rulebased syllabification may be hard but possible as per english i would not bother with markov chains and ngrams and instead just use several simple rules that give pretty good match ratio not perfect however two consonants between two vowels vccv split between them vccv as in coffee picnic except the cluster consonant that represents a single sound method rochester hangout three or more consonants between the vowels vcccv split keeping the blends together as in monster or children this seems the most difficult as you cannot avoid a dictionary one consonant between two vowels vcv split after the first vowel vcv as in bacon arid the rule above also has an exception based on blends courage playtime two vowels together vv split between except they represent a cluster vowel poem but glacier earlier i would start with the main rules first and then cover them with guard rules preventing cluster vowels and consonants to be split also there would be an obvious guard rule to prevent a single consonant to become a syllable when done i would have added another guard rule based on a dictionary
10554052,what are the major differences and benefits of porter and lancaster stemming algorithms,java machinelearning nlp,at the very basics of it the major difference between the porter and lancaster stemming algorithms is that the lancaster stemmer is significantly more aggressive than the porter stemmer the three major stemming algorithms in use today are porter snowballporter and lancaster paicehusk with the aggressiveness continuum basically following along those same lines porter is the least aggressive algorithm with the specifics of each algorithm actually being fairly lengthy and technical here is a break down for you though porter most commonly used stemmer without a doubt also one of the most gentle stemmers one of the few stemmers that actually has java support which is a plus though it is also the most computationally intensive of the algorithmsgranted not by a very significant margin it is also the oldest stemming algorithm by a large margin porter nearly universally regarded as an improvement over porter and for good reason porter himself in fact admits that it is better than his original algorithm slightly faster computation time than porter with a fairly large community around it lancaster very aggressive stemming algorithm sometimes to a fault with porter and snowball the stemmed representations are usually fairly intuitive to a reader not so with lancaster as many shorter words will become totally obfuscated the fastest algorithm here and will reduce your working set of words hugely but if you want more distinction not the tool you would want honestly i feel that snowball is usually the way to go there are certain circumstances in which lancaster will hugely trim down your working set which can be very useful however the marginal speed increase over snowball in my opinion is not worth the lack of precision porter has the most implementations though and so is usually the default goto algorithm but if you can use snowball snowball additional info snowball is a small string processing language designed for creating stemming algorithms for use in information retrieval the snowball compiler translates a snowball script into another language currently iso c c go java javascript object pascal python and rust are supported history of the name since it effectively provides a suffix stripper grammar i had toyed with the idea of calling it strippergram but good sense has prevailed and so it is snowball named as a tribute to snobol the excellent string handling language of messrs farber griswold poage and polonsky from the s martin porter stemmers implemented in the snowball language are sometimes simply referred to as snowball stemmers for example see the natural language toolkit nltkstemsnowball
10542937,what is oracle experiment,nlp machinelearning,an oracle is an imaginary entity that always gives the right answer an oracle experiment is used to compare your actual system to how your system would behave if some component of it always did the right thing for example in the nlp domain lets assume you built a parser that takes partofspeech pos tagged sentences as input in the real world you would have to run real sentences through an actual pos tagger this tagger would probably produce results with accuracy above but less than since the accuracy of your parser depends on the accuracy of the incoming tags your parsers performance will be negatively affected by this loss in order to see how well your parser would perform if the pos tagger was perfect you could run an experiment with an oracle tagger in this experiment you would replace the real pos tagger with a program that knows the actual pos tags for the sentences thus always returning tag results with accuracy so if your parser gets accuracy in an experiment with a real tagger and in an experiment with an oracle tagger then you know that of your performance loss is directly due to the mistakes of the tagger
10389414,trouble conceptualizing how to have ldaruby read multiple txt files,ruby nlp lda,basically you just need to initialize the corpus before going through the directory and then add each file to the corpus in the block the same way you were previously adding your csv file i know this is a rather old question but i found this question while looking for a solution to a similar problem your code helped me so i thought my answer might be helpful to you or others
10180032,how to neglect the output of ocr engine that has no meaning,algorithm nlp ocr tesseract,divide the output text into words divide the words into triples count the triple frequencies and compare to triple frequencies from text of a knowngood text corpus eg all the articles from some mailing list discussing what you intend to ocr minus the header lines when i say triples i mean whe hen i say tri rip ipl ple les i mea ean so i has a frequency of in this short example while the others are all frequency if you do a frequency count of each of these triples for a large document in your intended language it should become possible to be reasonably accurate in guessing whether a string is in the same language granted its heuristic ive used a similar approach for detecting english passwords in a password changing program it worked pretty well though theres no such thing as a perfect obvious password rejecter
9564979,what is the meaning of isolated symbol probabilities of english,nlp entropy,it would be helpful to know where the note came from and what the context is but even without that i am quite sure this simply means that they use the frequency of individual symbols eg characters as the basis for entropy rather than for example the joint probability of character sequences or the conditional probability of one particular character to follow another so if you have an alphabet xabcz and a probability pa pb for each character to appear in text eg based on the frequency found in a data example youd compute the entropy by computing px logpx for each character x individually and then taking the sum of all then obviously youd have used the probability of each character in isolation rather than the probability of each character in context note however that the term symbol in the note you found does not necessarily refer to characters it might refer to words or other units of text nevertheless the point they are making is that they apply the classical formula for entropy to probabilities of individual events characters words whatever not probabilities of complex or conditional events
8998979,what is the difference between pos tagging and shallow parsing,nlp postagger,pos tagging would give a pos tag to each and every word in the input sentence parsing the sentence using the stanford pcfg for example would convert the sentence into a tree whose leaves will hold pos tags which correspond to words in the sentence but the rest of the tree would tell you how exactly these these words are joining together to make the overall sentence for example an adjective and a noun might combine to be a noun phrase which might combine with another adjective to form another noun phrase eg quick brown fox the exact way the pieces combine depends on the parser in question you can see how parser output looks like at a shallow parser or chunker comes somewhere in between these two a plain pos tagger is really fast but does not give you enough information and a full blown parser is slow and gives you too much a pos tagger can be thought of as a parser which only returns the bottommost tier of the parse tree to you a chunker might be thought of as a parser that returns some other tier of the parse tree to you instead sometimes you just need to know that a bunch of words together form a noun phrase but dont care about the substructure of the tree within those words ie which words are adjectives determiners nouns etc and how do they combine in such cases you can use a chunker to get exactly the information you need instead of wasting time generating the full parse tree for the sentence
8974090,finding meaningful subsentences from a sentence,parsing artificialintelligence nlp machinelearning grammar,you can use dependency parser provided by stanford corenlp collapsed output of your sentence will look like below the last of your sentence output are optional you can remove one or more parts that are not essential to your sentence most of this optional parts are belong to prepositional and modifier eg prepin prepdo advmod tmod etc see stanford dependency manual for example if you remove all modifier from the output you will get i am going to do a seminar on nlp at sxsw in austin
8683588,understanding nltk collocation scoring for bigrams and trigrams,python nlp nltk,the nltk collocations document seems pretty good to me you need to give the scorer some actual sizable corpus to work with here is a working example using the brown corpus built into nltk it takes about seconds to run the output seems reasonable works well for baseball less so for doctor and happy
8203025,api to find nouns in sentence and nearest adjective in meaning in ruby,ruby linguistics nlp,i dont know about ruby but to determine the part of speech of a word like whether its a noun you need whats called a part of speech tagger for the second part it sounds like wordnet will help you wordnet is a database of english words you didnt say what language youre interested in with relationships like similar in meaning more specific like cat is more specific than animal opposite in meaning etc
8017572,what are the basic algorithms for text mining,nlp informationretrieval textmining,text mining is a rather broad term it roughly means machine learning applied to text common techniques include kmeans clustering naive bayes and linear svm classification tfidf vectorization svd called lsa when applied to text latent dirichlet allocation so performing some text mining might mean just about anything just like doing some information retrieval see bing lius book web data mining for a good intro to the field
7429198,what is a simple visualization tool to show word counts,r graphics nlp datavisualization,the type of plot you referred to in the op bubble plot is also referred to as a balloon plot the title of your question is directed to the more general problem of intuitively displaying word frequency in a given text given this perhaps its worth mentioning that the infographics gurus are critical of bubble plots because the plot is based on mapping data values to circle areas unfortunately the same gurus havent agreed on a plausible set of alternatives as far as i know the best alternative to a bubble plot to show term frequency that i can think of is usually referred to as a tag cloud on his blog statistics r graphics and fun yihui xie has written an excellent tutorial for creating tag clouds using r his tutorial is excellent for two reasonsits nicely written with stepbystep code and the result is beautiful see also this post on r bloggers for a tutorial on creating a better tag cloud but if a bubble aka balloon plot is what you want here you go they are simple to create in r there is meticulously detailed stepbystep tutorial for creating and polishing bubble charts on the excellent flow data site in addition the r package gplots available on cran includes a function balloonplot for plotting these directly from the flowing data site
7315463,what is the stateofart in extracting noun phrases from a textual content,nlp machinelearning,if youre working on english data check out the illinois chunker ive yet to try it out but its pretty new and the folks at illinois tend to write good nlp software update the project is available on github now
7290197,paraphrasing for math word problems changing sentence structure without changing meaning,nlp,when creating the word problem use some sort of syntax to denote various equivalent phrases as is done in article spinning sometimes then when displaying the word problem pick randomly between them example syntax example word problems that the syntax above could create for even more combinations you could make it recursive heres an article explaining a similar syntax to what i showed above
7059954,latent semantic analysis concepts,algorithm nlp datamining textmining latentsemanticindexing,there is no linguistic interpretation there is no syntax involved no handling of equivalence classes synonyms homonyms stemming etc neither are any semantics involved it is just wordsoccuringtogether consider a document as a shopping cart it contains a combination of words purchases and words tend to occur together with related words for instance the word drug can occur together with either of love doctor medicine sports crime each will point you in a different direction but combined with many other words in the document your query will probably find documents from a similar field
6615833,clustering conceptually similar documents together,python numpy nlp machinelearning datamining,for your first part of your question no you do not need to perform any clustering anymore such clustering is already available from your singular value decomposition if this is still unclear please study more on detailed manner your link latent semantic analysis for your second part please just figure out the first part of your question and then restate this part of your question based on that
6572207,stanford core nlp understanding coreference resolution,java nlp stanfordnlp,ive been working with the coreference dependency graph and i started by using the other answer to this question after a while though i realized that this algorithm above is not exactly correct the output it produced is not even close to the modified version i have for anyone else who uses this article here is the algorithm i ended up with which also filters out self references because every representativemention also mentions itself and a lot of mentions only reference themselves and the final output for your example sentence is the following usually the atom ends up being the representative mention but in the case it doesnt surprisingly another example with a slightly more accurate output is for the following sentence the revolutionary war occurred during the s and it was the first war in the united states produces the following output
5910820,what is the effective method to handle word contractions using java,java solr nlp,if you are worried about queries containing for eg whos finding documents containing for eg who is then you should look at using a stemmer which is designed exactly for this purpose you can easily add a stemmer buy configuring it as a filter in your solr config see edit a snowballporterfilterfactory will probably do the job for you
5846574,find sentences with similar relative meaning from a list of sentences against an example one,nlp googlenaturallanguage,first off what youre trying to solve is a very hard problem depending on whats in your dataset it may be aicomplete youll need your program to know or learn that add plus and sum refer to the same concept while multiplies is a different concept you may be able to do this by measuring distance between the words synsets in wordnetframenet though your distance calculation will have to be quite refined if you dont want to find multiplies otherwise you may want to manually establish some wordconcept mappings such as add addition plus addition sum addition times multiplication if you want full sentence semantics you will in addition have to parse the sentences and derive the meaning from the parse treesdependency graphs the stanford parser is a popular choice for parsing you can also find inspiration for this problem in question answering research there a common approach is to parse sentences then store fragments of the parse tree in an index and search for them by common search engines techniques eg tfidf as implemented in lucene that will also give you a score for each sentence
5578791,what is the mecab output and the tagset,nlp translation nltk postagger mecab,the output format in your example appears to be chasen which is defined in the dicrc file that would be for a normal node format that would be where items through are hyphendelimited for further details you should see the documentation for mecab edit updated link to the mecab output formatting explanation page
5479333,what are the available tools to summarize or simplify text,python nlp textprocessing,maybe you can try sumy its a quite small library that i wrote in python there are implemented luhns and edmundsons approaches lsa method sumbasic klsum lexrank and textrank algorithms its apache licensed and supports czech slovak english french japanese chinese portuguese spanish and german languages feel free to open an issue or send a pull request if there is something you are missing
5375980,can someone explain how this mgiza script works,python nlp corpus machinetranslation,based on my not equivalent experience with giza and the page you link to id say evcb and fvcb are the english and foreign vocab files youve generated already and that etxt and ftxt are the english and foreign text inputs it seems then that esnt and fsnt are the english and foreign sentence output files probably the sentences with the words replaced by their unique identifiers from the vcb files finally evcbx and fvcbx seem to be output locations for extending the original vocab files by concatenation i hope this helps and i hope someone else whos used mgiza can jump in and correct me if i am wrong
5235537,what is the easiest way to compare two web pages using python,python comparison nlp,first you want to retrieve both webpages you can use wget urlretrieve etc wget vs urlretrieve of python second you want to compare the pages you can use a diff tool as chinmay noted you can also do a keyword analysis of the two pages parse all keywords from page eg how do i extract keywords used in text optionally take the stem of the words with something like use some math to compare the two pages keywords eg term frequencyinverse document frequency with some of the python tools out there like these
5061746,processing and understanding sentences,algorithm artificialintelligence nlp analysis dataanalysis,you are discussing the field of natural language processing nlp it is a very complex issue and an area of active research it is safe to say there will never be a simple way of parsing a general english sentence let alone establishing meaning the school of informatics at the univeristy of sussex has a set of nlp lectures online that may help you to understand some of the issues which make this such a hard problem
4806176,what are the most challenging issues in sentiment analysisopinion mining,nlp sentimentanalysis,the key challenges for sentiment analysis are named entity recognition what is the person actually talking about eg is spartans a group of greeks or a movie anaphora resolution the problem of resolving what a pronoun or a noun phrase refers to we watched the movie and went to dinner it was awful what does it refer to parsing what is the subject and object of the sentence which one does the verb andor adjective actually refer to sarcasm if you dont know the author you have no idea whether bad means bad or good twitter abbreviations lack of capitals poor spelling poor punctuation poor grammar
4764715,what are some software and techniques for extracting proper names from a text,parsing nlp informationretrieval,are you looking for named entity recognition take a look at the wikipedia article the stanford nlp group has a decent readytouse package here with both gpl and commerical licenses available
4757947,what is a chunker in natural language processing,nlp chunking,according to these slides chunking is an alternative to parsing that provides a partial syntactic structure of a sentence with a limited tree depth as opposed to full on parsing it is more limited than full parsing but is sufficient when it comes to extracting or ignoring information and is thus many times used as its faster and more robust than parsing much more information is available in the slides further links more slides notes from lectures at nyu
4633794,understanding relevance score of opencalais,nlp informationextraction namedentityrecognition opencalais,their documentation states the relevance capability detects the importance of each unique entity and assigns a relevance score in the range being the most relevant and important while they do not explain what relevance means exactly one would expect it to quantify the centrality of the entity to the discourse of the document its likely influenced by factors such as the entities mention frequency in this document as compared to its expected frequency in a random document cf tfidf but could also involve more sophisticated discourse analysis
4583689,understanding semcor corpus structure h,linguistics corpus nlp,the format is described in the doccxtfiletxt file in the semcor archive for some reason documentation is not included in later versions
4456181,what are some examples of machine translation applicationslibraries currently being developed,opensource nlp machinetranslation,machine translation packages besides moses and apertium other good open source tools for machine translation that are being actively developedsupported are cdec c joshua java jane c phrasal java soon to be released
4003840,how to build a conceptual search engine,python search lucene nlp lsa,im not sure how to integrate that into a search engine could i use lucene to do this how step stop step get something to work step by then youll understand more about python and lucene and other tools and ways you might integrate them dont start by trying to solve integration problems software can always be integrated thats what an operating system does it integrates software sometimes you want tighter integration but thats never the first problem to solve the first problem to solve is to get your search or concept thing or whatever it is to work as a dumbold commandline application or pair of applications knit together by passing files around or knit together with os pipes or something later you can try and figure out how to make the user experience seamless but dont start with integration and dont stall because of integration questions set integration aside and get something to work
3917134,what are some good natural language parsing tools for perl,perl nlp,there is a natural language processing page on the perl wiki
3837157,what are features generators in natural language processing,nlp,if im reading this correctly i believe feature generation in this quote is referring to the process of extracting features from your text without going into too much detail this is basically getting the dimensions of your data you think would be useful for your predictionclassification task and putting it into a vector representation for example suppose we were trying to create a classifier to determine if an email was spam we might extract features such as containswordnigeria or isfrompersonincontactlist or if we were to follow the quote above we might make specialized features using the html tags such as percentofwordsinhreftag as you might imagine you can go overboard when feature engineering and the real challenge lies is in optimizing your feature set to give you good results on unseen data
3591474,changing the words keeping its meaning intact,python net nlp,just for laughs running yields hi we have a commitment in which we have to change the words or phrases in a sentence while preserving its meaning hello we have a requirement where we need to change words or phrases in the sentence while keeping its meaning intact hi we have a requirement we need the words or phrases within the meaning while changing its meaning intact hey we have a requirement we need to change the word or phrase in the sentence meaning while maintaining its integrity hi we maintain that we need to change the word or phrase in the sentence requirements have meant that literally hello we have a requirement that we must change the words or phrases in the sentence keeping intact its meaning hi we have an obligation that we need to change words or phrases in the sentence keeping intact its meaning hello we have a requirement where we need to change the words or phrases in the sentence while keeping intact the concept
2339377,programmatic parsing and understanding of language english,nlp lexicalanalysis,check out wordnet
2061881,natural language parsing tools what is out there and what is not,api nlp,i suggest you take a look at the following the ususal nlp libraries like open nlp lingpipe nltk gate uima all of these provide parsers and word stemmers ie they dont give you back the root of a word but its stem some also provide lemmatizers websites which collect nlp tools these are but a few of them the wiki of the association of computational linguistics language technology world the website of the compling dep at heidelberg university im not aware of a tool which returns the root of a word but as i said there are stemmers and lemmatizers for lemmatization try tree tagger or morpha morphophonemic analysis is a term not specific enough to get you what you want once you know more specifically what you need you could search the archives of the corpora list or post a question there
2006763,what are the prerequisites to learning natural language processing,nlp,there are two main approaches to nlp right now one is the languagebased approach detailed by jurafsky and martin speech and language processing and the other is a probability and statisticsbased approach foundations of statistical natural language processing most people that ive talked to tend to prefer the latter as far as ease of ramping up and useful results so i would recommend going over probability theory first and then tackling an nlp book like the second one i linked to which i am actually using on a project right now with pretty good results while i agree with laura that formal language theory is highly useful i actually think that currently if you just want to get into the actual nl parts of nlp you can leave formal languages for later as there are enough tools that will do your lexical analysis parsing tokenizing text transformations that you can use those rather than roll your own here is a book describing three such tools i own it and recommend it as a good introduction to all three building search applications lucene lingpipe and gate edit in response to your question i would say that the first step would be to get a thorough grounding in the basics of probability the first chapters of any undergrad probstats book should be fine and then from there look up new topics as they come up in the nlp book for instance yesterday i had to learn about tvalues or something im bad with names because they happened to be relevant to determining incidence of collocation
1787110,what is the difference between lemmatization vs stemming,nlp nltk lemmatization,short and dense the goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form however the two words differ in their flavor stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time and often includes the removal of derivational affixes lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words normally aiming to remove inflectional endings only and to return the base or dictionary form of a word which is known as the lemma from the nltk docs lemmatization and stemming are special cases of normalization they identify a canonical representative for a set of related word forms
1687510,what is the default chunker for nltk toolkit in python,python nlp nltk chunking,you can get out of the box named entity chunking with the nltknechunk method it takes a list of pos tagged tuples nltknechunkbarack nnp obama nnp lives nns in in washington nnp results in trees treeperson barack nnp treeorganization obama nnp lives nns in in treegpe washington nnp it identifies barack as a person but obama as an organization so not perfect
1598940,in natural language processing what is the purpose of chunking,computerscience nlp,chunking is also called shallow parsing and its basically the identification of parts of speech and short phrases like noun phrases part of speech tagging tells you whether words are nouns verbs adjectives etc but it doesnt give you any clue about the structure of the sentence or phrases in the sentence sometimes its useful to have more information than just the parts of speech of words but you dont need the full parse tree that you would get from parsing an example of when chunking might be preferable is named entity recognition in ner your goal is to find named entities which tend to be noun phrases though arent always so you would want to know that president barack obama is in the following sentence president barack obama criticized insurance companies and banks as he urged supporters to pressure congress to back his moves to revamp the healthcare system and overhaul financial regulations source but you wouldnt necessarily care that he is the subject of the sentence chunking has also been fairly commonly used as a preprocessing step for other tasks like examplebased machine translation natural language understanding speech generation and others
1453552,what is a fast and unsupervised way of checking quality of pdfextracted text,java pdf text nlp,of course no method will be perfect there are usually two classes of text extraction poblems nothing gets extracted this can be because youve got a scanned document or something is invalid in the pdf usually easy to detect you should not need complicaed code to check those you get garbage most of the times because the pdf file is weirdly encoded this can be because of homemade encoding not properly declared or maybe the pdf author needed characters not recognized by pdf for example the turkish s with cedilla was missing for some time in the adobe glyph list you could not create a correctly encoded file with it inside so you had to cheat to get it visually on the page i use a ngram based method to detect languages of pdf files based on the extracted text with different technologies but the idea is the same files where the language was not recognized are usually good suspects of a problem about spellchecking i suppose it will give you tons of false positives especially if you have multiple languages
1140908,parsing meaning from text,python parsing nlp lexicalanalysis,you need to look at the natural language toolkit which is for exactly this sort of thing this section of the manual looks very relevant categorizing and tagging words heres an extract here we see that and is cc a coordinating conjunction now and completely are rb or adverbs for is in a preposition something is nn a noun and different is jj an adjective
501675,algorithm for separating nonsense text from meaningful text,algorithm filter cpuword nlp spam,how about just using some existing implementation of a bayesian spam filter instead of implementing your own i have had good results with dspam
212219,what are good starting points for someone interested in natural language processing,nlp dcg,tough call nlp is a much wider field than most people think it is basically language can be split up into several categories which will require you to learn totally different things before i start let me tell you that i doubt youll have any notable success as a professional at least without having a degree in some closely related field there is a lot of theory involved most of it is dry stuff and hard to learn youll need a lot of endurance and most of all time if youre interested in the meaning of text well thats the next big thing semantic search engines are predicted as initiating web but were far from there yet extracting logic from a text is dependant on several steps tokenization chunking disambiguation on a lexical level time flies like an arrow but fruit flies like a banana syntactic parsing morphological analysis tense aspect case number whatnot a small list off the top of my head theres more and many more details to each point for example when i say parsing what is this there are many different parsing algorithms and there are just as many parsing formalisms among the most powerful are treeadjoining grammar and headdriven phrase structure grammar but both of them are hardly used in the field for now usually youll be dealing with some halfbaked generative approach and will have to conduct morphological analysis yourself going from there to semantics is a big step a syntaxsemantics interface is dependant both on the syntactic and semantic framework employed and there is no single working solution yet on the semantic side theres classic generative semantics then there is discourse representation theory dynamic semantics and many more even the logical formalism everything is based on is still not welldefined some say one should use firstorder logic but that hardly seems sufficient then there is intensional logic as used by montague but that seems overly complex and computationally unfeasible there also is dynamic logic groenendijk and stokhof have pioneered this stuff great stuff and very recently this summer actually jeroen groenendijk presented a new formalism inquisitive semantics also very interesting if you want to get started on a very simple level read blackburn and bos its great stuff and the defacto introduction to computational semantics i recently extended their system to cover the partitiontheory of questions question answering is a beast as proposed by groenendijk and stokhof but unfortunately the theory has a complexity of on over the domain of individuals while doing so i found bbs implementation to be a bit erhm hackish at places still it is going to really really help you dive into computational semantics and it is still a very impressive showcase of what can be done also they deserve extra coolpoints for implementing a grammar that is settled in pulp fiction the movie and while im at it pick up prolog a lot of research in computational semantics is based on prolog learn prolog now is a good intro i can also recommend the art of prolog and covingtons prolog programming in depth and natural language processing for prolog programmers the former of which is available for free online
77757228,what are the differences between fairseq and fairseq,deeplearning frameworks opensource languagemodel fairseq,quoting from the can balioglus comment research engineer at fair which is part of a discussion in the fairseq repository issue we wanted to let you know that fair will soon kick off the fairseq v project in order to modernize our code base and to address fairseqs long standing structural and technical issues our highlevel goals are for fairseq to have a clean maintainable welltested code base that leverages the latest features of pytorch and its ecosystem preserve the performance optimizations of the original fairseq that have accumulated throughout the years enforce user code to be separate from library code via welldefined apis so that it can be used both as a framework and as a library offer a familiar interface for researchers used to the original fairseq come with new faulttolerant features and tools for largescale training and inference note that although our aim is to keep them at a minimum in order to realize some of our goals we will be making backwardsincompatible changes mostly in our trainer and data loading apis along with these changes we also plan to offer a large set of extensibility apis that will mitigate the need to forkbranch fairseq in majority of use cases note that releases of fairseq are available via the fairseq releases page changelogs are provided for some releases indicating possibly breaking changes especially for earlier versions
52226905,in the context of recurrent neural networks what is the meaning of conditioned on something,deeplearning recurrentneuralnetwork languagemodel,conditioning in the context of sequence to sequence learning in rnns is the process of computing the probability of obtaining the output sequence conditioned on the input sequence or pyx the network is used to model this conditional probability mapping a technique to expedite training in sequence to sequence learning is known as teacher forcing where the hidden states of neurons in adjacent timesteps are decoupledsee image the ground truth label yt in conjunction with input sequence element xt are used as input to the neuron in the subsequent timestep teacher forcing eliminates the need for backpropagation through time and parallelizes training using fewer computational resources unfortunately some empirical results indicate that rnns that employ teacher forcing are less robust to generalization error when compared with vanilla rnns edit the includes the conditional probability distribution that teacher forcing in sequence to sequence rnns approximates
49828024,how to build deep learning model that picks words from serval distinct bags and forms a meaningful sentence,deeplearning keras nltk languagemodel googlenaturallanguage,first we need a way that the computer can recognise a word otherwise it cannot pick the correct one that means at this stage we need to decide what we are teaching the computer to begin with ie what is a verb noun grammar but i will assume we will dump a dictionary into it and give no information except the words themselves so that the computer can compute what sentences are we need to convert them to numbers one way would be to work alphabetically starting at using them as keys for a dictionary digital this time and the word as the value now we can apply the same linear algebra techniques to this problem as any other problem so we need to make generations of matrices of weights to multiply into the keys of the dictionary then remove all the weights beyond the range of dictionary keys the rest can be used to get the value in the dictionary and make a sentence optionally you can also use a threshold value to take off of all the outputs of the matrix multiplication now for the hard part learning once you have a few say matrices we need to breed the best ones this is where human intervention is needed and you need to pick the most meaningful sentences might be hard at first and use them to base your next of easiest way would be to weight the matrices randomly for a weighted mean times and the boring bit keep running the generations over and over until you get to a point where your sentences are meaningful most of the time of course there is no guarantee that it will always be meaningful but thats the nature of anns if you find it doesnt work you can use more layers more matrices andor i recently heard of a different technique that dynamically changed the network but i cant really help with that
46889727,wordvec what is best add concatenate or average word vectors,python wordvec gensim wordembedding languagemodel,i have found an answer in the stanford lecture deep learning for natural language processing lecture march its available here in minute richard socher states that the common way is to average the two word vectors
44586333,understanding character level embedding in keras lstm,python keras lstm embedding languagemodel,in my knowledge the structure is basic and may work to some degree i have some suggestions in the timedistributed layer you should add an activation function softmax which is wide employed in multiclassification and now in your structure the output is nonlimited and its not intuitive as your target is just onehot with softmax function you could change the loss to crossentropy which increase the probability of correct class and decrease the others its more appropriate you can take a try for more useful model you could try following structure which is given in pytorch tutorial thanks
39039793,what is the softmaxw and softmaxb in this document,tensorflow languagemodel softmax,all that code is doing is adding an extra linear transformation before computing the softmax softmaxw should be a tfvariable containing a matrix of weights softmaxb should be a tfvariable containing a bias vector take a look at the softmax example in this tutorial for more details
34502351,what is the next procedure after creating a cmusphinx language model with my own dictionary,java dictionary cmusphinx languagemodel,procedure for training acoustic model is described in tutorial for acoustic model training you need to create fileids and transcription files manually in a text editor or with a script if you want to convert existing transcription in any custom form to required format fileids must list the file names transcription file must list transcription for each of the files in a special format for example of acoustic model training database you can check inside an database
75061462,having trouble understanding the predictions array in classification model evaluation,deeplearning bertlanguagemodel textclassification,there are two values because you have two classes no yes these values are logits which when fed into a softmax function gives the probability of each class if you want to know whether the sample is classified as sarcasm or not just take the class with the highest logit
63377198,what is the difference between pooled output and sequence output in bert layer,pythonx tensorflow neuralnetwork textclassification bertlanguagemodel,sequence output is the sequence of hiddenstates embeddings at the output of the last layer of the bert model it includes the embedding of the cls token hence for the sentence you are on stackoverflow it gives embeddings one embedding for each of the four words assuming the word stackoverflow was tokenized into a single token along with the embedding of the cls token pooled output is the embedding of the cls token from sequence output further processed by a linear layer and a tanh activation function the linear layer weights are trained from the next sentence prediction classification objective during pretraining for further details please refer to the bert original paper
62828346,what is the difference between args wordngrams minn and maxn in fassttext supervised learning,textclassification supervisedlearning fasttext,raju you are almost right but the averaging happens at the very end first how a sentence is tokenized the whole sentence is tokenized with spaces so i love you will produce words i love you and a special word eos end of sentence so far we have tokens then for each word depending of what you set for minn and maxn fasttext will compute the subwords and consider them as tokens as well so in your case with minn maxn it will be i e u we add beginning and end of word characters and as well so the overall tokens will be i love you eos i e u now with wordngrams we also add tokens corresponding to pair of words i love love you you eos once we have the tokens in order to compute the hidden layer the embedding of the sentence will be the average of the embeddings of individual tokens above this is done by summing the corresponding column vectors of dimension in the input matrix and we divide by the number of tokens to have the average with this line of code
61702235,what is the difference between text classification and feature selection,machinelearning textclassification featureselection,text classification is classifying the text based on its features for example you might classify a sentence as having a positive i am so happy or negative i am so sad sentiment text feature selection is effectively deciding how you want to encode the text so you can run it through the classifier there are many ways of doing this for example you could use a bag of words representation where each column represents a word in your vocabulary and each cell represents how many times the word appears in the document if you had two sentences i am so happy so very happy and i am so sad your encoding for the sentences might be i am so happy very sad
56637851,keras movie review sentiment classifier what is the role of globalaveragepoolingd layer,keras textclassification,to answer specifically why its there and not how it works modelsummary will reveal that it is providing dimensional reduction
56118110,what is the most efficient way to extract tweets that has certain dialect,python twitter dataset textclassification,note that this is a platform to get advice with particular code not to discuss methodologies that said you could manually collect data from this particular dialect and collect other tweets as well and then build a classifier that predicts to what group a tweet belongs
53136542,what is the numpy way to conditionally merge arrays,python numpy textclassification,youre looking for numpywhere
46942526,tensorflow understanding filter and stride shapes for cnn text classification,python tensorflow convneuralnetwork textclassification,filters have i interpreted this correctly yes exactly strides does this shapes dimensions correspond to the dimensions of the filtershape yes it corresponds to the strides in which you convolve the filter on the input embedding it would seem that the nature of word vector representations means that the stride length should be embeddingsize meaning i want to move the window one full word atatime over one channel for each filter pay attention to the padding strategy the padding in convd is set to be valid this means there will be no padding since the filter size in the embedding dimension covers the input entirely it can fit only once without any consideration of the stride along this dimension put differently you can convolve along the embedding dimension only once independently of the stride
46601522,what is the difference between countvectorizer and charngramanalyzer in scikitlearn,python machinelearning scikitlearn textclassification,first check your sklearn version i feel that you are using an old version of sklearn the explanation that you gave for countvectorizer is not right it does not count the number of different words in the corpus at least not the current version as per the docs of countvectorizer you need to pass analyzerword to make the word count in the latest version of sklearn charngramanalyzer is deprecated and now merged with countvectorizer just do analyzerchar to replicate charngramanalyzer to verify this check has no entry for charngramanalyzer
45775028,reducing the output of wordnet to one meaning,python pythonx wordnet textclassification,you need to find the synonyms for a specific lemma canonical dictionary entry a word with a single definition ill simply include the link i posted in the comments and wish you good luck
45211095,how to explain to customer why classifier make such decision,machinelearning textclassification,first and foremost if your customer is not from technical background then never use technical terms in front him by using technical terms you are making situation even more worse because he is into new thing and he is confused with your jargon so never make someone freak out give him simple examples like recommending music on gaanacom saavncom or recommending movie on netflix tell himher how a machine will understand what is your like and dislike or even how you will get to know my music liking and disliking can you by finding my favorite right how you get to know this my favorite either by asking me or looking into my most top rated or more liked or you heard i always listen some common songs exactly this above process you followed is called finding pattern in machine learning and using this method machine able to recommend new songs movies etc ill also suggest dont explain above thing because your customer is not that much dumb who is dealing with your workproduct give him real time use cases like recommendation process or in social media recommending friends and many more
41182372,what is the difference between gensim labeledsentence and taggeddocument,gensim textclassification wordvec docvec,labeledsentence is an older deprecated name for the same simple objecttype to encapsulate a textexample that is now called taggeddocument any objects that have words and tags properties each a list will do words is always a list of strings tags can be a mix of integers and strings but in the common and mostefficient case is just a list with a single id integer starting at modell and modelt will serve the same purposes having trained on the same data with the same parameters using just different names for the objects but the vectors theyll return for individual wordtokens modelsomeword or documenttags modeldocvecssomefilenamenn will likely be different theres randomness in wordvecdocvec initialization and trainingsampling and introduced by orderingjitter from multithreaded training
26456904,how to classify urls what are urls features how to select and extract features from url,url machinelearning classification featureextraction textclassification,i assume you do not have access to the content of the url thus you can only extract features from the url string itself otherwise it makes more sense to use the content of the url here are some features i will try see this paper for more ideas all url components for example this page has the below url all tokens that occurs in different parts of urls should have variable value to the classification in this case the last part after tokenization contributes great features for this page eg classify urls select extract features the length of a url ngrams grams as examples below stackoverflowcom comquestions questions how howto
24896644,machinelearning concept recommendations,machinelearning classification textclassification,you have a very minimal text data set you could use any library it wouldnt really matter more advanced options would require more data than you have to be meaningful so its not an issue worth considering the simple way text classifications problems are handled is to use a bag of words model and a linear classifier both weka and mallet support this personally i find weka to be a pain and mallet to be poorly documented out of date when it is so i use jsat there is an example on doing spam classification here bias warning im the author of jsat
21087349,what is the impact of number of training documents on classification time,performance machinelearning textclassification,only lazy classifiers have such a characteristics one of which is knn svm classification time depends on the number of support vectors which may but not have to be dependent on the number of training documents they are the upper bound of the number of svs naive bayes there is no impact unless these new documents carry many new words as the nb classification time is o number of features so if you do not enlarge the vocablurary in case of bow model you are safe to use many training data decision tree the same as for nb it depends only on the number of features and the complexity of the problem which do not change with number of instances neural network here classification time only depends on the number of neurons
16266842,maxent classifier nltk output understand,python machinelearning nltk textclassification,it seems that you have two labels relevant and irrelevant when there are two labels one is normally named or positive and the other or negative during the training process the classifier analysed the features of the training instances and weighted them according to their ability to distinguish well between the two labels the details of the weighting process depend on the algorithm you chose poitive precision of the testing instances that were classified as label during the testing really have the label positive recall of the label instances in the testing set were found ie classified as label negative precision negative recall is the same but for label accuracy of the testing instances were labeled correctly the features are sorted according to their absolute value which corresponds to their relevance for the classification the most helpful feature in this case was need and if it is true this is a very good hint that the label of the instance should be relevant
76299956,what is the best way to save fasttext word vectors in a dataframe as numeric values,python dataframe vector wordembedding fasttext,for further calculations usually the best approach is to not move the vectors into a dataframe at all which brings up these sorts of typesize issues and adds more indirection datastructure overhead from the dataframes tablecells model rather leave them as the numpyndarray objects they are either the individual dimension arrays or in some cases the giant numberofwords vectorsize matrix used by the fasttext model itself to store all the words using numpy functions directly on those will generally lead to the most concise efficient code with the least memory overhead for example if wordlist is a python list of the words whose vectors you want to average
72918624,what is the meaning of sizeembeddingmodel,gensim wordvec wordembedding,yes lenmodel in this case gives you the count of words inside it modelvectorsize will give you the number of dimensions not bytes per vector the actual size of the vector in bytes will be times the count of dimensions as each floatsized value takes bytes i generally recommend against ever using the gensim apidownloader functionality if you instead find manually download from the original source of the files youll better understand their contents formats limitations and where the file has landed in your local filesystem and by then using a specific classmethod to load the file youll better understand what kinds of classesobjects youre using rather than whatever mysteryobject downloaderload might have given you
70843845,understanding results of wordvec gensim for finding substitutes,python gensim wordvec wordembedding recommendationengine,you may not get a very good intuitive understanding of usual wordvec behavior using these sorts of productbaskets as training data the algorithm was originally developed for naturallanguage texts where texts are runs of tokens whose frequencies cooccurrences follow certain indicative patterns people certainly do use wordvec on runsoftokens that arent natural language like product baskets or logsofactions etc but to the extent such tokens have verydifferent patterns its possible extra preprocessing or tuning will be necessary or useful results will be harder to get as just a few ways customerpurchases might be different from real language depending on what your pseudotexts actually represent the ordering within a text might be an artifact of how you created the datadump rather than anything meaningful the nearestneighbors to each token within the window may or may not be significant compared to more distant tokens customer ordering patterns might in general not be as reflective of shadesofrelationships as wordsinnaturallanguage text so its not automatic that wordvec will give interesting results here for recommendatinos thats especially the case with small datasets or tiny dummy datasets wordvec requires lots of varied data to pack elements into interesting relative positions in a highdimensional space even small demos usually have a vocabulary count of unique tokens of tensofthousands with training texts that provide varied usage examples of every token dozens of times without that the model never learns anything interesinggeneralizable thats especially the case if trying to create a manydimensions model say the default vectorsize with a tiny vocabulary just dozens of unique tokens with few usage examples per example and it only gets worse if tokens appear fewer than the default mincount times when theyre ignored entirely so dont expect anything interesting to come from your dummy data at all if you want to develop an intuition id try some tutorials other goals with real natural language text st with a variety of datasets parameters to get a sense of what has what kind of effects on result usefulness only after that try to adapt wordvec to other data negativesampling is the default works well with typical datasets especially as they grow large where negativesampling suffes less of a performance hit than hierarchicalsoftmax with large vocabularies but a toggle between those two modes is unlike to cause giant changes in quality unless there are other problems sufficient data of the right kind is the key then tweaking parameters may nudge endresult usefulness in a better direction or shift it to be better for certain purposes but more specific parameter tips are only possible with clearer goals once some baseline is working
64717185,conceptnet numberbatch multilingual oov words,python wordembedding conceptnet,are you taking into account conceptnet numberbatchs format as shown in the projects github it looks like this cenabsolutevalue cenabsolutezero this format means that fille will not be found but cfrfille will
57165579,understanding fasttext multilingual,python textalignment wordembedding fasttext,a backslash at the end of a line tells python to extend the current logical line over across to the next physical line in your case you can read the two lines as a single line in python a variable is created the moment you first assign a value to it so wordid idword and embed are not keywords they are created when a value is assigned to them
56575043,understanding number of params in keras rnn and output shape dimension in keras embedding when rnn and embedding are chained together,keras recurrentneuralnetwork wordembedding,for calculating the number of params of simplernn number of parameters for keras simplernn for your second question the output shape of embedding layer is batchsize inputlength outputdim since you didnt specifiy the inputlength argument length of input sequences of embedding layer it would take the default value which is none variable also since rnn blocks run in each timestep you can add it to a variable timestep layer however if you want to add flatten followed by dense layers which take the whole previous layer as input you have to specifiy the inputlength in embedding layer
54836522,keras understanding word embedding layer,python tensorflow keras wordembedding,yes word unicity is not guaranteed see the docs from onehot this is a wrapper to the hashingtrick function from hashingtrick two or more words may be assigned to the same index due to possible collisions by the hashing function the probability of a collision is in relation to the dimension of the hashing space and the number of distinct objects it would be better to use a tokenizer for this see question its very important to remember that you should involve all words at once when creating indices you cannot use a function to create a dictionary with words then again with words then again this will create very wrong dictionaries embeddings have the size x because that was defined in the embedding layer vocabsize this means there are words in the dictionary embeddingsize this is the true size of the embedding each word is represented by a vector of numbers you dont know they use the same embedding the system will use the same embedding the one for index this is not healthy for your model at all you should use another method for creating indices in question you can create a word dictionary manually or use the tokenizer class manually make sure you remove punctuation make all words lower case just create a dictionary for each word you have tokenizer see the output of encodeddocs see the maximum index so your vocabsize should be otherwise youd have lots of useless and harmless embedding rows notice that was not used as an index it will appear in padding do not fit the tokenizer again only use textstosequences or other methods here that are not related to fitting hint it might be useful to include endofsentence words in your text sometimes hint it is a good idea to save your tokenizer to be used later since it has a specific dictoinary for your data created with fitontexts params for embedding are correct dense params for dense are always based on the preceding layer the flatten in this case the formula is previousoutput units units this results in from the flatten dense units dense biasunits flatten it gets all the previous dimensions multiplied the embedding outputs lenght and embeddingsize the embedding layer is not dependent of your data and how you preprocess it the embedding layer has simply the size x because you told so see question there are of course better ways of preprocessing the data see question this will lead you to select better the vocabsize which is dictionary size seeing the embedding of a word get the embeddings matrix choose any word index thats all if youre using a tokenizer get the word index with
53587960,what is the meaning of size of wordvec vectors gensim library,python gensim wordvec wordembedding,it is not the case that wordvec aims to represent each word in the dictionary by a vector where each element represents the similarity of that word with the remaining words in the dictionary rather given a certain target dimensionality like say the wordvec algorithm gradually trains wordvectors of dimensions to be better and better at its training task which is predicting nearby words this iterative process tends to force words that are related to be near each other in rough proportion to their similarity and even further the various directions in this dimensional space often tend to match with humanperceivable semantic categories so the famous wvking wvman wvwoman wvqueen example often works because malenessfemaleness and royalty are vaguely consistent regionsdirections in the space the individual dimensions alone dont mean anything the training process includes randomness and over time just does whatever works the meaningful directions are not perfectly aligned with dimension axes but angled through all the dimensions that is youre not going to find that a v is a genderlike dimension rather if you took dozens of alternate malelike and femalelike word pairs and averaged all their differences you might find some dimensional vectordimension that is suggestive of the gender direction you can pick any size you want but are common values when you have enough training data
52615380,what is the most efficient way to store a set of points embeddings such that queries for closest points are computed quickly,informationretrieval embedding wordembedding dataretrieval,there are standard approximate nearest neighbors library such as faiss flann javalsh etc which are either lsh or product quantization based which you may use the quickest solution which i found useful is to transform a vector of say dimensions to a long variable bits by using the johnsonlindenstrauss transform you can then use hamming similarity ie minus the number of bits set in a xor b to compute the similarity between bit vectors a and b you could use the popcount machine instruction to this effect which is very fast in effect if you use popcount in c even if you do a complete iteration over the whole set of binary transformed vectors long variables of bits it still will be very fast
52364632,what is the operation behind the word analogy in wordvec,python gensim wordvec wordembedding,you should be clear about exactly which wordvector set youre using different sets will have a different ability to perform well on analogy tasks those trained on the tiny text dataset might be pretty weak the big googlenews set google released would probably do well at least under certain conditions like discarding lowfrequnecy words youre doing the wrong arithmetic for the analogy youre trying to solve for an analogy a is to b as c is to often written as you begin with b subtract a then add c so the example gives the formula in your excerpted text and to solve instead you would try then see whats closest to targetcoordinates note the difference in operationordering to your attempt you can think of it as start at a countryvector france subtract the countrycapitalvector paris this leaves you with an interim vector thats sortof zero countryness and negative capitalness add another countrycapitalvector berlin this leaves you with a result vector thats again sortof one countryness and zero capitalness note also that gensims mostsimilar takes multiple positive and negative wordexamples to do the arithmetic for you so you can just do
45631962,extract more meaningful words from publicly available word embedding,machinelearning wordvec wordembedding,the googlenews vector set does not contain frequency information but does seem to be sorted from mostfrequent to leastfrequent so if you change the code that loads it to only load the first n words you should get the n mostfrequent words the python gensim library for training or working with wordvectors includes this as a limit option on the loadwordvecformat function glove may follow the same convention a look over the orderofwords in the file should give a good idea
45495885,what is the effect of adding new word vector embeddings onto an existing embedding space for neural networks,neuralnetwork wordvec wordembedding,the initial training used info about known words to plot them in a useful ndimensional space it is of course theoretically possible to then use new information about new words to also give them coordinates in the same space you would want lots of varied examples of the new words being used together with the old words whether you want to freeze the positions of old words or let them also drift into new positions based on the new examples could be an important choice to make if youve already trained a preexisting classifier like a sentiment classifier using the older words and didnt want to retrain that classifier youd probably want to lock the old words in place and force the new words into compatible positioning even if the newer combined text examples would otherwise change the relative positions of older words since after an effective trainup of the new words they should generally be near similarmeaning older words it would be reasonable to expect classifiers that worked on the old words to still do something useful on the new words but how well thatd work would depend on lots of things including how well the original wordset covered all the generalizable neighborhoods of meaning if the new words bring in shades of meaning of which there were no examples in the old words that area of the coordinatespace may be impoverished and the classifier may have never had a good set of distinguishing examples so performance could lag
77324154,what is the optimal value of limitphrases for the summary method in pytextrank,python spacy summary pytextrank,the optimal values for limitphrases will depend strongly on your content do you have any kind of benchmark against which you could run test essentially doing a grid search to find a reasonable setting for this parameter fwiw im one of the authors of pytextrank and this is really good question theres no analytic way to determining how to set this parameter as far as our team knows
73722706,meaning of ner training values using spacy,pythonx spacy namedentityrecognition spacy,refers to iterations or batches and e refers to epochs the score is calculated as a weighted average of other metrics as designated in your config file this is documented here
70070719,what is the difference between strings for spacy ner,python spacy namedentityrecognition transliteration,you forgot to define the o letter mapping here is the fix mapping abvgdeziyklmnoprstufhabvgdeziyklmnoprstufh note i added both upper and lowercase o letter mappings
69757652,what is the most accurate way to detect dates in text,python spacy namedentityrecognition dateparser datefinder,what does your corpus include does it include full sentences first of all you can try spacy ner with context ner algorithms work on full sentences if you look for a more tokenshape oriented solution i suggest context free parsing a context free grammar is great for describing dates basically you define some grammar rules such as regex is not a good idea here because it has no context ie parsed characters are not aware of what have been parsed before there is no memory context free grammars offer a structured way to parse strings and offer parse trees as well this is how i did it with lark dates are in german
69422116,what is the best way to get accurate text similarity in python for comparing single words or bigrams,python nltk spacy similarity sentencesimilarity,i found some methods that might be helpfuli am new to programming so dont really know how to implement your data set still wanted to share it this code says similarity between two strings is i tried the same code for black and white it says similarity between two strings is note i think sklearn modules affinity propagation and levenstein distance might be helpfulbut dont know how to implement them to your questions
66751457,meaningless spacy nouns,python text spacy wordnet,it seems you can use pyenchant library enchant is used to check the spelling of words and suggest corrections for words that are missspelled it can use many popular spellchecking packages to perform this task including ispell aspell and myspell it is quite flexible at handling multiple dictionaries and multiple languages more information is available on the enchant website sample python code import spacy re import enchant pip install pyenchant d enchantdictenus nlp spacyloadencorewebsm sentence for example it filters nouns like motorbike whoosh trolley metal suitcase zip etc cleanstring resubw sentencelower merging w and into one regex doc nlpcleanstring for token in doc if tokenposnoun and dchecktokentext print tokentext example nouns motorbike whoosh trolley metal suitcase zip
66446435,what is the model architecture used in spacys token vectors english,python spacy,the english vectors are glove common crawl vectors most other languages have custom fasttext vectors from oscar common crawl wikipedia these sources should be included in the model metadata but it looks like the vector information has been accidentally left out in the model releases
64724483,what is the underlying architecture of spacys blank model spacyblanken,python spacy,blank model does not have pretrained tagger parser and ner spacyblank function is here github link it just calls utilgetlangclassname which essentially loads a languagespecific module from here github link to spacylang heres the link to the code for the blank english model github link to spacy english model the detailed documentation is here adding new languages if the only thing you are changing is ner i would start with the pretrained model i assume english and just disable ner pipe using this model instance nlp you would train your ner if it is mlbased or add entityruler pipe if your ner is rulebased this way you will still have postagger and dependency parser available to you after you finished with training just save the model using todisk if you use entityruler rulebased ner you will need to write a few lines of code to register the new pipe welldocumented on their webste
60533029,what is a good way to speed up test runs utilizing larger spacy models,python testing spacy,the v md models have a minor bug that make them particularly slow to load see you can reformat one file in the model package to improve the load time in the vocab directory for the model package eg libpythonsitepackagesencorewebmdencorewebmdvocab in my tests this nearly halves the loading time s to s the remaining time is mostly loading strings and lexemes for the model which is harder to optimize further at this point so this improves things a bit but the overall load time is still relatively burdensome for short tests
57963657,what is the best way to benchmark custom components in a spacy pipeline,python spacy,this is a good question and the extension attribute idea is actually very clever the only downside is that youd have to add debugging code to all of your existing components which also works less well if theyre thirdparty code but if you know that the offending code is part of your codebase this shouldnt be a problem another option would be to wrap each pipeline component in a function that logs the timestamp and whatever else you need and returns pipedoc you can then overwrite nlppipeline with those wrapped components def wrappipename pipe def wrappeddoc printfstarted name datetimedatetimenow return pipedoc return wrapped def debugwrappipelinenlp nlppipeline name wrappipename pipe for name pipe in nlppipeline return nlp debugnlp debugwrappipelinenlp however the downside here is that youd also need to wrap each components pipe method if available so you can run and debug nlppipe under the same conditions if youre benchmarking you often want to do this at a larger scale and process a stream of texts with nlppipe to avoid this a slightly more verbose option could be to add a debug component before each existing component in the pipeline basically something like this def makedebugcomponentname def debugcomponentdoc printfbefore name datetimedatetimenow return doc return debugcomponent def debugwrappipelinenlp pipeline listnlppipeline we dont want to modify this while were looping over it for name pipe in pipeline debugcomponent makedebugcomponentname nlpaddpipedebugcomponent beforename namefdebugname return nlp disclaimer i only just hacked those ideas together and havent tested them extensively yet but they did seem to work if you end up exploring this id be very curious to hear what worked best it might also be a feature that spacy could ship with outofthebox and itd pair well with the proposed static analysis for pipeline components also just to add for completeness when debugging text processing pipelines like this always benchmark things on a larger scale with a single corpus that you process once rather than looping over a single example times or something like that there are caching effects both within spacy but also the cpu differences in memory allocation and so on that can all have an impact and make the smallscale tests less reliable of course in a scenario like this where youre experiencing drastic differences even processing a single text can probably give you enough clues and everything you need to debug your code further
57747872,what is the good metric to evaluate ner model trained in spacy,machinelearning spacy namedentityrecognition,it depends on your application whats worse missing an entity or wrongly flagging something as an entity if failing to label an entity false negative is bad then you care about recall if wrongly flagging a nonentity as an entity false positive is bad you care about precision if you care about both precision and recall the same use f if you care about precision false positives twice as much as recall false negatives use f you can do fb for any b to express what you care about the formula is shown and explained on the wikipedia page for f score edit answering the direct question from the original post the system does badly at location and the date entities the others look good if it were me i would try to use ner to extract all dates as one entity then try to build a separate system rule based or a classifier for distinguishing between the different kinds of dates for location you could use a system that focuses on just geoparsing such as mordecai
55306056,what is the best way to overcome wrong entity recognision with spacy,pythonx spacy entities,one potential difficulty in your example is that its not very close to natural language the pretrained english models were trained on m words of general web and news text so theyre not always going to perform perfect outofthebox on text with a very different structure while you could update the model with more examples of quantity in your specific texts i think that a rulebased approach might actually be a better and more efficient solution here the example in this blog post is actually very close to what youre trying to do import spacy from spacypipeline import entityruler nlp spacyloadencorewebsm weightspattern likenum true lower in g kg grams kilograms lb lbs pounds patterns label quantity pattern weightspattern ruler entityrulernlp patternspatterns nlpaddpiperuler beforener doc nlpus average was lbs printenttext entlabel for ent in docents us gpe lbs quantity the statistical named entity recognizer respects predefined entities and wil predict around them so if youre adding the entityruler before it in the pipeline your custom quantity entities will be assigned first and will be taken into account when the entity recognizer predicts labels for the remaining tokens note that this example is using the latest version of spacy vx you might also want to add more patterns to cover different constructions for more details and inspiration check out the documentation on the entityruler combining models and rules and the token match pattern syntax
50792574,what are the supported date and time formats in spacy,spacy,the english models were trained on the ontonotes corpus which supports the more extensive label scheme including date and time the xxentwikism model was trained on a wikipedia corpus with a more limited label scheme and only recognises per loc org and misc out of the box model details here when using the models to extract mentions of date and time its important to keep in mind that its a statistical process so the results you see will depend on the context and the data the models were trained on depending on the texts youre working with you likely want to update and finetune the pretrained models with more examples specific to your application or try a rulebased approach instead also see this thread for more details on date and time parsing
50644777,understanding spacys scorer output,python spacy namedentityrecognition,uas unlabelled attachment score and las labelled attachment score are standard metrics to evaluate dependency parsing uas is the proportion of tokens whose head has been correctly assigned las is the proportion of tokens whose head has been correctly assigned with the right dependency label subject object etc entsp entsr entsf are the precision recall and fscore for the ner task tagsacc is the pos tagging accuracy tokenacc seems to be the precision for token segmentation
50487495,what is difference between encorewebsm encorewebmd and encoreweblg model of spacy,python spacy,smmdlg refer to the sizes of the models small medium large respectively as it says on the models page you linked to model differences are mostly statistical in general we do expect larger models to be better and more accurate overall ultimately it depends on your use case and requirements we recommend starting with the default models marked with a star below fwiw the sm model is the default as alluded to above
70242454,how to check if a given english sentence contains all nonmeaning words using python,python pythonx dictionary nltk,you can use setdifference method note that since words in nltkcorpuswords are mostly in lower case have to use strlower method as well eg hello is in but hello isnt just fyi but your function does not do what your explanation says
63402609,how to split up column name and find dictionary meaning with wordnet,python nltk,output
62594180,attributeerror list object has no attribute allhypernyms what is this error,python nltk wordnet lcs sentencesimilarity,so i am not sure of what you are trying to acheive with this code but i see why the code is breaking what is happening is that in the line that is breaking you are comparing two lists of synsets this is problematic because the function cannot handle list of synsets so if you want to compare all the synsets that are created you will need to use an additional for loop to extract all the synset in the list however if you want to compare the first synset of the first word with the first synset of the secon word you can simply do this also you need to be careful in the if statement of the wordcheck rangeis becasue you are comparing a list with a value while you should check the similaryty outcome itself
58039580,what is missing parameter in the below mentioned program,python machinelearning nltk porterstemmer,you need to instantiate the porterstemmer class not use it directly this psporterstemmer needs to become this ps porterstemmer more on the matter here future word of advice it is imperative that you try to research as much as possible before posting on stackoverflow you could have found the answer to this question as it is a simple question if you took the error exactly as it is and just pasted it on google you would have found this answer and also this answer and this one and many more and you would have gained a lot more than simply getting the answer
55492666,what is better to use keraspreprocessingtokenizer or nltktokenize,python keras nltk tokenize,by default they both use some regular expression based tokenisation the difference lies in their complexity keras tokenizer just replaces certain punctuation characters and splits on the remaining space character nltk tokenizer uses the treebank tokenizer uses regular expressions to tokenize text as in penn treebank this implementation is a port of the tokenizer sed script written by robert mcintyre and available at they are both very fast since they just run regular expressions if you have very basic text with not too much punctuation or out of order characters then keras might be the simplest choice if you actually want a neural network based one that can parse numbers dates etc correctly and potentially perform partofspeech tagging entity recognition you can use stanford corenlp that gives a full pipeline for processing text finding dependencies recognising entitites etc spacy is also a full python nlp pipeline that gives you similar results as well a loading corresponding word vectors such as glove the above two are slower than any regular expression based methods but it depends on the source text you want to process
55094368,what is the way to specify download directory while using download missing resources in command line,python anaconda nltk,you could add this installed directory that is within your home directory to pythonpath variable for it to work
54745482,what is the difference between tfidf vectorizer and tfidf transformer,python scikitlearn nltk tfidf tfidfvectorizer,tfidfvectorizer is used on raw documents while tfidftransformer is used on an existing count matrix such as one returned by countvectorizer
54432045,using python what is the best way to replace x with just in text strings,python regex nltk,this matches x with a look behind assertion that the prior character is a digit and replaces the x with nothing
50431155,whats the tags meaning of stanford dependency parser,nltk stanfordnlp,for the last few versions the stanford parser has been generating universal dependencies rather than stanford dependencies the new relation set can be found here and are listed below for version version seems to be a workinprogress still although no longer maintained you can get the old dependency format by setting the property depparselanguage to english see eg here
46352106,what is happening in lambda function in python,python numpy lambda scikitlearn nltk,this is basically specifying that the key used as a basis for sorting is idx now each element of wordcount contains a word followed by its frequency so when you write idx you are accessing the frequency which is being used as the basis to sort the array i think the reason he is multiplying it by is becaused sorted by default sorts in ascending order so if you multiply a list of ve numbers by and sort them in ascending order you get the original list in descending order which is exactly what you want list of words in descending order of their frequency you can read more about using lambda and key in sorted on this page
45210930,what are the entity types for nltk,nltk namedentityextraction,thats a very good question ive wondered the same myself it doesnt seem to be documented anywhere even in the nltk source and of course it is determined by the corpus that the chunker was trained on which it seems is or was the ace corpus which is not distributed with the nltk a little bit of digging around in the source turned up the answer note that some of the common types mentioned in the book including date and time are not actually detected by this chunker gpe stands for geopolitical entity gsp stands for geographicalsocialpolitical entity an older tag that was replaced by gpe in the ace project from their definition see links below they seem to be pretty much equivalent edit january prompted by daniels question i looked at the documentation of the ace project myself in search of a description of these entities sure enough this page links to documentation for each phase of the project the entity names listed above including the mysterious gsp but without the gpe entity were used through phase of the project starting with phase gpe replaced gsp on the list one has to wonder how the nltk chunker ended up being trained on both gpe and gsp or how it decides between the two my best guess is that it was trained on a combination of phase and phase materials
44299509,do not understand nltk regex parsing format,python regex nltk,dt is a determiner like athe verb participle defintion a participle glossing abbreviation ptcp is a form of a verb that is used in a sentence to modify a noun noun phrase verb or verb phrase and plays a role similar to an adjective or adverb it is one of the types of nonfinite verb forms you can find more about them here what does mean its the same thats used in regular expressions denotes any set of characters ofcourse the set of characters that constitute the should make sense upon combination lets go into some examples
43656078,word sense disambiguation with wordnet how to select the words related to the same meaning,python nltk wordnet wordsensedisambiguation,you could use wordnet hypernyms synsets with a more general meaning my first idea would be to go from the current synset upwards using synsethypernyms and keep checking whether i find the sound synset when i hit the root which has no hypernyms ie synsethypernyms returns an empty list i would stop now for your two examples this produces the following sequences of synsets so one of the synsets you might want to look for is soundn but there could be others i think you could play with other examples and try to come up with a list
40024874,what is regex for website domain to use in tokenizing while keeping punctuation apart from words,python regex nltk tokenize,you may use see the regex demo details b leading word boundary there must be a nonword char before a protocol ftpftps s nonwhitespace symbols w a word char letterdigit or w or more word chars or ws or more nonword chars excluding whitespaces
37050509,can someone explain what does the map function do,python pandas dataframe nltk,i looked at the other questions and they dont really seem to explain your question what does the map function do map takes an iterable and a function and applies the function to every element in the iterable in turn heres an example output note that were passing the name of the function without at the end to map a lambda is just a function with no name in your case you could actually just pass in mapstrstemmer since it just takes one argument walking through my example you can see that the first output comes from within the function squaring then it goes through the first iteration of the loop and displays squared item is that is because im using python and map is an iterator in python it outputs something different thats because it applies the function over the iterable first and produces a list
36038827,import nltk ununderstandable error,python centos nltk python dictionarycomprehension,since version nltk drops supports for python nltk released october add support for python drop support for python sentiment analysis package and several corpora improved pos tagger twitter package multiword expression tokenizer wrapper for stanford neural dependency parser improved translationalignment module including stack decoder skipgram and everygram methods multext east corpus and mtecorpusreader minor bugfixes and enhancements for details see since dictionary comprehension is a feature from python using nltk will lead to error when a dictionary comprehension occurs strongly encouraged to upgrade to python or using conda would simplify the problem too but if python is really necessary
35963350,what is the nltk fcfg grammar standardspecification,python nltk grammar contextfreegrammar,the question was asking for fcfg feature grammars not plain cfg i think you can just add square brackets to the nonterminals and have a feature name an equal sign and a value in the brackets the value can either be a variable starting with a question mark a terminal symbol for simple values or a new feature structure i found this example on the internet and it is working at my laptop it seems that it doesnt matter whether the feature terminal symbols are quoted or not
33339588,use lexical pcfg for generating meaningful phrase,python nltk stanfordnlp,a syntactic grammar will generate grammatical sentences but it makes no guarantees that the sentences make sense really theres no way to make sentences that make semantic sense this would require the computer to understand the meaning of what its saying on a deeper level than currently possible you can try to combine your cfg with an ngram language model which should create more locally coherent sentences but still not necessarily globally coherent
32549376,can someone explain the syntax of bigramassocmeasureschisq,python nltk chisquared,i found following sources for explanation text classification for sentiment analysis python code search nullege samples for chisq python code search nullege explanation of bigramassocmeasures the first source explains the subject and its application for sentiment analysis as well as python code the second source provides more code samples the third souces contains the explanation which you wanted the arguments constitute the marginals of a contingency table counting the occurrences of particular events in a corpus the letter i in the suffix refers to the appearance of the word w in question while x indicates the appearance of any word thus for example this may be shown with respect to a contingency table i hope this research helped
29445798,what is the regular expression,python regex nltk,the below regex would replace all the dots follwed by a nonspace character with n demo
27897591,python nltk naive bayes classifier what is the underlying computation that this classifier uses to classifiy input,python machinelearning nltk,from the source code
24647400,what is the best stemming method in python,python nltk stemming,the results you are getting are generally expected for a stemmer in english you say you tried all the nltk methods but when i try your examples that doesnt seem to be the case here are some examples using the porterstemmer the results are grow leav and fairli which even if they are what you wanted are stemmed versions of the original word if we switch to the snowball stemmer we have to provide the language as a parameter the results are as before for grows and leaves but fairly is stemmed to fair so in both cases and there are more than two stemmers available in nltk words that you say are not stemmed in fact are the lancasterstemmer will return easy when provided with easily or easy as input maybe you really wanted a lemmatizer that would return article and poodle unchanged
24093509,what is the total bigram count returned for nltk bigramcollocationfinder,python nltk ngram,first we dig out the scorengram from nltkcollocationsbigramcollocationfinder see then we take a look at the studentt from nltkmetricsassociation see and product and small is so going back to your example out in nltk it takes the number of tokens as the population count ie but i would say this is not usually how the studentt test scores are calculated i would have gone with ngrams rather than tokens see nlpstanfordedufsnlppromocollocpdf and but since the population is a constant and when tokenis is im not sure whether the effect size of the difference accounts for much since tokens ngrams for bigrams lets continue in digging into how nltk calculates the studentt so if we strip the studentt out and just put in the parameters we get the same output so we see that in nltk the studentt score for bigrams is calculated as such in formula
23938294,what is wrong with this code of nltk python,python nltk,your return statement is in the loop which means that the function immediately returns as soon as tokens in wordstomatch is true to correct this problem just move the return out of the loop like this for simplicity i removed the part of opening a file its just a test youll have to let your method read that file the result is it seems to work
23530098,what is the probability of begining given the,python nltk corpus taggedcorpus,there is sort of a difference between probability of beginning intersect the and probability of beginning given the try out
18107104,what is this dictionary assignment doing,python mapreduce nltk sentimentanalysis,the loop creates a nested dictionary and sets all values to presumably to then just use the keys as a way to weed out duplicate values you could use sets instead and avoid the value note that you dont even need to create the initial dictionaries you can create the whole set with one statement a set comprehension if other code does rely on dictionaries with the values being set to perhaps to update counts at a later stage itd be more performant to use the dictfromkeys class method instead looking at your source blog article however shows that the dictionaries are only used to do membership testing against the keys so using sets here is much better and transparent to the rest of the code to boot
15388831,what are all possible pos tags of nltk,python nltk,to save some folks some time here is a list i extracted from a small corpus i do not know if it is complete but it should have most if not all of the help definitions from upenntagset cc conjunction coordinating cd numeral cardinal dt determiner ex existential there in preposition or conjunction subordinating jj adjective or numeral ordinal jjr adjective comparative jjs adjective superlative ls list item marker md modal auxiliary nn noun common singular or mass nnp noun proper singular nns noun common plural pdt predeterminer pos genitive marker prp pronoun personal prp pronoun possessive rb adverb rbr adverb comparative rbs adverb superlative rp particle to to as preposition or infinitive marker uh interjection vb verb base form vbd verb past tense vbg verb present participle or gerund vbn verb past participle vbp verb present tense not rd person singular vbz verb present tense rd person singular wdt whdeterminer wp whpronoun wrb whadverb
14852184,comparing sentences according to their meaning,python datamining nltk,you will need a more advanced topic modeling algorithm and of course some corpora to train your model so that you can easily handle synonyms like giggle and laugh in python you can try this package i never used it but it includes classic semantic vector spaces methods like lsalsi random projection and even lda my personal favourite is random projection because it is faster and still very efficient im doing it in java with another library though
12702839,what is the error in following python code,python nltk stopwords,the problem with what you are doing is listremovex only removes the first occurrence of x not every x to remove every instance you could use filter but i would opt for something like this
2289046,what is the difference between running a script from the command line and from exec with php,php python apache exec nltk,you have to run nltkdownload and choose maxenttreebankpostagger you must make a python script and in it put then run it from command line it will install the data files for the pos tagges which you dont have installed yet after you do this it should work
1859554,what is entropy and information gain,math text computerscience nltk textmining,i assume entropy was mentioned in the context of building decision trees to illustrate imagine the task of learning to classify firstnames into malefemale groups that is given a list of names each labeled with either m or f we want to learn a model that fits the data and can be used to predict the gender of a new unseen firstname first step is deciding what features of the data are relevant to the target class we want to predict some example features include firstlast letter length number of vowels does it end with a vowel etc so after feature extraction our data looks like the goal is to build a decision tree an example of a tree would be basically each node represent a test performed on a single attribute and we go left or right depending on the result of the test we keep traversing the tree until we reach a leaf node which contains the class prediction m or f so if we run the name amro down this tree we start by testing is the length and the answer is yes so we go down that branch following the branch the next test is the number of vowels again evaluates to true this leads to a leaf node labeled m and thus the prediction is male which i happen to be so the tree predicted the outcome correctly the decision tree is built in a topdown fashion but the question is how do you choose which attribute to split at each node the answer is find the feature that best splits the target class into the purest possible children nodes ie nodes that dont contain a mix of both male and female rather pure nodes with only one class this measure of purity is called the information it represents the expected amount of information that would be needed to specify whether a new instance firstname should be classified male or female given the example that reached the node we calculate it based on the number of male and female classes at the node entropy on the other hand is a measure of impurity the opposite it is defined for a binary class with values ab as this binary entropy function is depicted in the figure below random variable can take one of two values it reaches its maximum when the probability is p meaning that pxa or similarlypxb having a chance of being either a or b uncertainty is at a maximum the entropy function is at zero minimum when probability is p or p with complete certainty pxa or pxa respectively latter implies pxb of course the definition of entropy can be generalized for a discrete random variable x with n outcomes not just two the log in the formula is usually taken as the logarithm to the base back to our task of name classification lets look at an example imagine at some point during the process of constructing the tree we were considering the following split as you can see before the split we had males and females ie pm and pf according to the definition of entropy next we compare it with the entropy computed after considering the split by looking at two child branches in the left branch of endsvowel we have and the right branch of endsvowel we have we combine the leftright entropies using the number of instances down each branch as weight factor instances went left and instances went right and get the final entropy after the split now by comparing the entropy before and after the split we obtain a measure of information gain or how much information we gained by doing the split using that particular feature you can interpret the above calculation as following by doing the split with the endvowels feature we were able to reduce uncertainty in the subtree prediction outcome by a small amount of measured in bits as units of information at each node of the tree this calculation is performed for every feature and the feature with the largest information gain is chosen for the split in a greedy manner thus favoring features that produce pure splits with low uncertaintyentropy this process is applied recursively from the rootnode down and stops when a leaf node contains instances all having the same class no need to split it further note that i skipped over some details which are beyond the scope of this post including how to handle numeric features missing values overfitting and pruning trees etc
77732511,what are differences between t and bart,seqseq encoderdecoder,similarity both models are encoderdecoder models both models are suitable for most seqseq tasks such as summarization translation qa tasks comprehension tasks etc both of them issued in t by google bart by facebook ai differences pretraining objective t pretraining objective randomly samples and then drops out of tokens in the input sequence all consecutive spans of droppedout tokens are replaced by a single sentinel token each sentinel token is assigned a token id that is unique to the sequence the sentinel ids are special tokens that are added to our vocabulary and do not correspond to any word piece the target then corresponds to all of the droppedout spans of tokens delimited by the same sentinel tokens used in the input sequence plus a final sentinel token to mark the end of the target sequence read section unsupervised objective in t paper bart is trained by corrupting documents and then optimizing a reconstruction loss the crossentropy between the decoders output and the original document bart allows to application of any type of document corruption in the extreme case where all information about the source is lost in detail the pretraining process is explained in section pretraining bart in the bart paper linked below activation functions t initially used relu later there were other activation functions such as gelu take a look into the implementation for precise understanding bart following gpt authors modified relu activation functions to gelus parameter initialization bart initializes parameters from n t n sqrtdmodel pretraining corpus t used c bart pretrained directly on data sets of squad an extractive question answering task on wikipedia paragraph mnlia bitext classification task to predict whether one sentence entails another elia longform abstractive question answering dataset xsumsummarization convaidialogue response generation task conditioned on context and a persona cnndmsummarization tasks positional encoding t uses relative position embeddings bart uses absolute position embeddings as usual both models use different tokenizers in short bart is more of a pretraining approach that learns to map corrupted documents to the original as the main difference of the t model because both of them are encoderdecoder transformers also you can find more information by reading the linked resources if you want more finegrade technical differences look into the models implementation too on hugging face resources exploring the limits of transfer learning with a unified texttotext transformer paper t from hugging face bart denoising sequencetosequence pretraining for natural language generation translation and comprehension paper bart from hugging face
73448366,understanding states of a bidirectional lstm in a seqseq model tf keras,tensorflow keras lstm bidirectional seqseq,this model is not valid it is set up as a translation model which during inference would predict one word at a time starting with the start of sequence token to predict y then looping and feeding in the start of sequence token y to get y etc a bidirectional lstm cannot be used for real time predictions in a many to many prediction unless the entire decoder input is available in this case the decoder input is only available after predicting one step at a time so the first prediction of y is invalid without the rest of the sequence yyt the decoder should therefore not be a bidirectional lstm as for the states the encoder bidirectional lstm does indeed output h and c states going forward orange arrow and h and c states going backward pink arrow by concatenating these states and feeding them to the decoder we can give the decoder more information this is possible as we do have the entire encoder input at time of inference also to be noted is that the bidirectional encoder with lstmunits eg effectively has lstm units half going forward half going backward to feed these into the decoder the decoder must have units too
58266407,specifying a seqseq autoencoder what does repeatvector do and what is the effect of batch learning on predicting output,python keraslayer autoencoder seqseq,this might prove useful to you as a toy problem i created a seqseq model for predicting the continuation of different sine waves this was the model
53933854,what is the list of possible tags with a description of conll ner task,tags namedentityrecognition conll,for ner task there are some common types of entities used as tags persons per organizations org monetary values money geopolitical entity ie countries cities states gpe and many others furthermore to distinguish adjacent entities with the same tag many applications use bio tagging scheme here b denotes the beginning of an entity i stands for inside and is used for all words comprising the entity except the first one and o means the absence of entity so on the example above bperson means that the person name begins with the token bob the next tag iperson says that ross relates to the entity as the previous tag then goes o which means that lived doesnt belong to any entity the same is with in whereas florida is the begginging of geopolitical entity gpe please let me know if this was helpful enough
31386459,whats meaning of bos and eos in crfsuite feature list and what is the role of them,python namedentityrecognition crf,these stand for beginning of sentence and end of sentence they are used in place of the previous word and next word features for words that do not have previousnext words
20211380,what is the best way to match substring from a big string to a huge list of keywords,c regex lookup stringmatching namedentityrecognition,assumptions most keywords are single words but there are som multi word keywords my suggestion hash the keywords based on the first word so presidentpresident obama and president clinton will all hash to the same value then search wordbyword by computing the hashes on hash matches implement logic to check if you have a match on a multi word keyword calculating the hashes will be the most expensive operation of this solution and should be linear in the length of the input string
65426684,what is keras tokenizer fitonsequences used for,python tensorflow keras tokenize textprocessing,sequencestomatrix does work after calling fitonsequences you just need to specify the argument numwords in the tokenizer instantiation the zero at the beginning is there because there is no in your sequence and the zeroes at the end are because i specified numwords but the highest value in your test sequence in the purpose it serves is just skipping the step of mapping an integer to a string it only uses the integer
65172390,awk equivalents for tidyverse concepts melt and spread,awk textprocessing,i think the following should output what you want tested on repl
53452313,what is fasterbetter practice between a for loop for greping a file greping a file with a file query,bash shell loops grep textprocessing,expanding on my comment you can download the source for grep via git with you can see at line of srcgrepc a comment which is about all the clue we need to see that the patterns being searched whether they come in through e or through f with a file are dumped into an array that array is then the source of the search moving through that array in c is going to be faster than your shell looping through a file so this alone will win the speed race also as i mentioned in my comment the grep f listtxt salestxt is easier to read easier to maintain and only a single program grep has to be invoked
49564990,what is the meaning of perl switch octal or hexadecimal parameter,perl textprocessing textparsing,ok for perl le ooo is the null byte from man ascii so le set output separator to null byte useful to pipe by example to xargs to go further on a bunch of other tricks perldoc perlrun octalhexadecimal specifies the input record separator as an octal or hexadecimal number if there are no digits the null character is the separator other switches may precede or follow the digits for example if you have a version of find which can print filenames terminated by the null character you can say this the special value will cause perl to slurp files in paragraph mode any value or above will cause perl to slurp files whole but by convention the value is the one normally used for this purpose you can also specify the separator character using hexadecimal notation xhhh where the h are valid hexadecimal digits unlike the octal form this one may be used to specify any unicode character even those beyond xff so if you really want a record separator of specify it as xff this means that you cannot use the x option with a directory name that consists of hexadecimal digits or else perl will think you have specified a hex number to test on all combinations i know are interesting
48102393,what is the fastest way to remove a number from the beginning of so many files,regex bash performance shell textprocessing,this is much faster on a file with million rows it took less than one second to use this on several files in a directory use tmppathtotmpfile for file in dir do cut f d file tmp mv tmp file done a thing worth mentioning is that it often takes much longer time to do stuff in place rather than using a separate file i tried your sed command but switched from in place to a temporary file total time went down from s to s
35778753,what is the fastest most errorfree method of extracting and cleaning the html body text in python,python html beautifulsoup lxml textprocessing,youve done a lot to make it fast the soup strainer and the lxml parser are usually the first things to try when optimizing the parsing with beautifulsoup here are some improvements to this particular code remove the body existence check and use find instead replace the if text is none or lentext with just if not text strip via gettextstriptrue the improved code these are just microimprovements and i dont think they are gonna change the overall performance picture what i would also look into running the script via pypy beautifulsoup is compatible but you would not be able to use lxml parser try it with htmlparser or htmllib you might win a lot without even modifying the code at all
16934983,what is a good way to encode diffs in absence of the source text,diff textprocessing,one of the output formats of diff is an ed script with diff e now diff produces ed scripts that make lineoriented edits like delete lines or insert lines but since youre not necessarily using diff you can make your tool output a finergrained ed script which performs insertions and substitutions within a line ed does not support numeric addressing of the characters within a line but it can be done with regular expression matchreplace to replace an ncharacter sequence starting at column m counting from with the text rep you can use this command here m and n are replaced by decimal numbers if m happens to be then just your program has be careful about escaping the characters of rep of course the edits are then applied to a file like this
7303166,what is the preferred way to implement yield in scala,python scala generator yield textprocessing,the premise of your question seems to be that you want exactly pythons yield and you dont want any other reasonable suggestions to do the same thing in a different way in scala if this is true and it is that important to you why not use python its quite a nice language unless your phd is in computer science and using scala is an important part of your dissertation if youre already familiar with python and really like some of its features and design choices why not use it instead anyway if you actually want to learn how to solve your problem in scala it turns out that for the code you have delimited continuations are overkill all you need are flatmapped iterators heres how you do it thats it all your cases can be reduced to one of these three in your case your example would look something like ps scala does have continue its done like so implemented by throwing stackless lightweight exceptions but that wont get you what you want because scala doesnt have the yield you want
49028540,what is the conceptual difference between topic extraction and text categorization,datamining textmining categoricaldata topicmodeling,topic model approaches topic extraction are unsupervised approaches so you dont need to know that each document belongs to what categories classes latent dirichlet allocation lda is a method for topic modeling lda divides the documents into topics and assigns a name to the topics topic model needs the number of output clusters as the same as clustering methods but they assign a topic name to each output cluster in contrast to topic model approaches document classification approaches categorization are supervised so they need the class labels
41945528,what are fpgrowth allowed input data type,c database sequence datamining textmining,depends on your implementation but its fairly standard to allow items such as milk and not only one letter items
38141711,text mining sparsenonsparse meaning,r textmining,by this code you have created a document term matrix of the corpus document term matrix dtm lists all occurrences of words in the corpus by document in the dtm the documents are represented by rows and the terms or words by columns if a word occurs in a particular document then the matrix entry for corresponding to that row and column is else it is multiple occurrences within a document are recorded that is if a word occurs twice in a document it is recorded as in the relevant matrix entry as an example consider corpus of having two documents doc bananas are good doc bananas are yellow dtm for the above corpus would look like the output the output signifies that dtm has entries which has over terms which have appeared at least once now you are removing those terms which dont appear too often in your data we will remove any element that doesnt appear in atleast of the entries or documents relating to the above created dtm we are basically removing those columns whose entries are in least number of documents now if you look at the output the number of entries documents are still the same ie but number of terms terms which have appeared at least once has changed to
37386595,what is the optimal topicmodelling workflow with mallet,python r textmining lda mallet,thank you for this thorough summary as an alternative to topicmodels try the package mallet in r it runs mallet in a jvm directly from r and allows you to pull out results as r tables i expect to release a new version soon and compatibility with tm constructs is something others have requested to clarify its a good idea for documents to be at most around tokens long not vocabulary any more and you start to lose useful information the assumption of the model is that the position of a token within a given document doesnt tell you anything about that tokens topic thats rarely true for longer documents so it helps to break them up another point i would add is that documents that are too short can also be a problem tweets for example dont seem to provide enough contextual information about word cooccurrence so the model often devolves into a onetopicperdoc clustering algorithm combining multiple related short documents can make a big difference vocabulary curation is in practice the most challenging part of a topic modeling workflow replacing selected multiword terms with single tokens for example by swapping spaces for underscores before tokenizing is a very good idea stemming is almost never useful at least for english automated methods can help vocabulary curation but this step has a profound impact on results much more than the number of topics and i am reluctant to encourage people to fully trust any system parameters i do not believe that there is a right number of topics i recommend using a number of topics that provides the granularity that suits your application likelihood can often detect when you have too few topics but after a threshold it doesnt provide much useful information using hyperparameter optimization makes models much less sensitive to this setting as well which might reduce the number of parameters that you need to search over topic drift this is not a well understood problem more examples of realworld corpus change would be useful looking for changes in vocabulary eg proportion of outofvocabulary words is a quick proxy for how well a model will fit
36299544,what is the structure of atis airline travel information system dataset,python dataset textmining recurrentneuralnetwork,each of the pickle can be divided into training validation testing and its dictionary when you see the dictionary elements they contain the wordsidx tablesidx labelsidx now test the following code for i in trainset print leni it will return same length file so the first element is the wordssecond is the tablesidx and third is final result of slot filling labelsidx use the dict to decry pt the ids you will get the meaning
30238014,what is the meaning of cutoff and iteration for trainings in opennlp,textmining opennlp,correct the term iteration refers to the general notion of iterative algorithms where one sets out to solve a problem by successively producing hopefully increasingly more accurate approximations of some ideal solution generally speaking the more iterations the more accurate better the result will be but of course the more computational steps have to be carried out the term cutoff aka cutoff frequency is used to designate a method of reducing the size of ngram language models as used by opennlp eg its partofspeech tagger consider the following example if you set the cutoff frequency to for this example the ngram model would be reduced to that is the cutoff method removes from the language model those ngrams that occur infrequently in the training data reducing the size of ngram language models is sometimes necessary as the number of even bigrams let alone trigrams grams etc explodes for larger corpora the remaning information ngram counts can then be used to statistically estimate the probability of a word or its pos tag given the n previous words or pos tags
28989810,what is gettext function in textmining where does it come from r,r twitter textmining tm,gettext is an accessor method for the status class as described here sorry for not clarifying in the text nathan danneman
27047450,meaning of stanford spanish pos tagger tags,python stanfordnlp textmining,this is a simplified version of the tagset used in the ancora treebank you can find their tagset documentation here the simplification consists of nulling out many of the final fields which dont strictly belong in a partofspeech tag for example our partofspeech tagger will always give you null values for the ner field of the original tagset see eagles noun documentation in short the fields in the pos tags produced by our tagger correspond exactly to ancora pos fields but a lot of those fields will be null for most practical purposes youll only need to look at the first characters of the tag the first character always indicates the broad pos category and the second character indicates some kind of subtype were in the process of writing some introductory documentation for using spanish with corenlp that means understanding these tags and much else right now for the moment you can find more information on the first page of our technical documentation
26035773,text mining what is the best way to mine descriptive excel sheet data,excel textmining dataanalysis vba,i am not a data expert but i have some data mining experience i would try following these steps for starters excel is not a good for such an analysis find some tool dedicated to data mining eg rstudio r has many useful outofthebox algorithms for data mining cleanse the data eg all texts to lower case remove stop words remove punctuation remove additional white spaces tokenize the data eg word tokens finance bachelor decide on how you will assert if a certain profile is in demand or not if by profile you mean that you need the information on the frequency of certain tokens appearing in the data more often then others eg finance bachelor etc then simply create a frequency matrix r allows you to create a visualisation of this word clouds this is to start you off i am sure there is much more to be suggested in this matter
25612631,better understanding of cosine similarity,datamining textmining cosinesimilarity,i do not understand question tfidf weighting is a weighting scheme that worked well for lots of people on real data think lucene search but the theoretical foundations of it are a bit weak in particular everybody seems to be using a slightly different version of it and yes it is weights cosine similarity in practise you may want to try eg okapi bm weighting instead though i do not undestand this question either angular similarity is beneficial because the length of the text has less influence than with other distances furthermore sparsity can be nicely exploitet as for the weights idf is a heuristic with only loose statistical arguments frequent words are more likely to occur at random and thus should have less weight maybe you can try to rephrase your questions so i can fully understand them also search for related questions such as these cosine similarity and tfidf and better text documents clustering than tfidf and cosine similarity
5322317,what is a good approach for extracting keywords from usersubmitted text,ruby metadata sinatra keyword textmining,maybe you can use textanalyzer
1635014,besides nltk what is the best information retrieval library for python,python informationretrieval textmining,alternatively r has many tools available for text mining and its easy to integrate with python using rpy have a look at the natural language processing view on cran in particular look at the tm package here are some relevant links paper about the package in the journal of statistical computing the paper includes a nice example of an analysis of the rdevel mailing list newsgroup postings from package homepage look at the introductory vignette in addition r provides many tools for parsing html or xml have a look at this question for an example using the rcurl and xml packages
853139,best clustering algorithm simply explained,algorithm text clusteranalysis datamining textmining,the most standard way i know of to do this on text data like you have is to use the bag of words technique first create a histogram of words for each article lets say between all your articles you only have unique words between them then this histogram is going to be a vectorarray list whatever of size where the data is the number of times each word appears in the article so if the first spot in the vector represented the word asked and that word appeared times in the article vector would be now to compare any two articles it is pretty straightforward we simply multiply the two vectors sorry for using python instead of php my php is rusty and the use of zip makes that bit easier this is the basic idea notice the threshold value is semiarbitrary youll probably want to find a good way to normalize the dot product of your histograms this will almost have to factor in the article length somewhere and decide what you consider related also you should not just put every word into your histogram youll in general want to include the ones that are used semifrequently not in every article nor in only one article this saves you a bit of overhead on your histogram and increases the value of your relations by the way this technique is described in more detail here
67977030,what are the cons and potenzial problems of using textblob to perform sentiment analysis how could they be solved,python sentimentanalysis textblob,most of the challenges in nlp sentiment analysis tasks are semantic ones like irony and sarcasm ambiguity in th textmultipolarity thay why textblob may not yield the best resulat depending on your text and if it contains multiples languges you can add new models or languages through extensions
60929241,what is the error in this code using dataframe and matplotlib,python pandas matplotlib sentimentanalysis,it is not a dataframe it is a numpy array the result of your predict method is a numpy array which cannot be indexed like you are trying to why not just use the dataframe that you append the prediction to dftweetpredspredictions tweetpreds then you can do all sorts of indexing
45904323,what is the proper way to deal with score dispersion in sentiment analysis on different topics in relation,sentimentanalysis,the short answer is both the algorithm and the input keywords as they are dependent on each other given the right input the dispersion would increse in any algorithm and given the wrong algorithm the same will happen for any input usually in this cases you should revise the algorithm as this is the case in most situations you can also read this in order to understand it better
42414917,what is the relationship between machine learning and sentiment analysis,machinelearning socialnetworking sentimentanalysis,there has been research working on the automatic detection of user latent variables including age and gender on social media data these studies have taken into account a variety of features and evaluated their effectiveness for instance the content of ones social media post can say a lot about their age and gender for example studies have shown that if someone uses the word buddy the user is more likely to be a young male so the answer to your question is yes you can use machine learning techniques to detect age and gender on social media however choosing an effective set of features depends on the context you want to study and the platform you want to focus on and it requires some experimentation use of sentiment as a feature might be useful in one context and might not be of help in another i refer you to the following articles that have studied this topic before this one analyzes a set of contentbased and stylistic feature including sentiment this paper looks at tokenbased and characterbased methods this one looks at ones social neighborhood to predict hisher characteristics
36237416,what is the meaning of sense number in sentiwordnet,sentimentanalysis sentiwordnet,if you lookup parturient in wordnet youll see two meanings are shown these are parturient and parturient respectively in that case the difference is rather subtle but for instance the word field has lots of senses and you might care which one is being referred to you would use them if you then start looking at the semantic relations of that word eg the hypernym of field is knowledge domain whereas the hypernym of of field is tract piece of land a classic example when considering sentiment is to compare suck and suck in the context of talking about a vacumn cleaner eg this cleaner really sucks as it hardly sucks at all
23863225,what is the meaning of the following lines of code exactly for knn algorithm,python sentimentanalysis knn,you take for training the first n positives and the first n negatives this means position to n you take for testing from position n until the end of the negatives and the positives since this is knn when you say train that basically means that you will build a table with the training data and use the distance and the label of the training data to evaluate the testing data there is really no training in knn itself
18513413,understanding this application of a naive bayes classifier,bayesian sentimentanalysis,first of all the formula isnt quite right you need to divide that by pw but you hint that this is taken care of later when it says that they do a few sums so we can move on to your main question traditionally when doing naive bayes on text classification you only look at the existence of words not their counts of course you need the counts to estimate pword class at train time but at test time pmusic terrorism typically means the probability that the word music is present at least once in a terrorism document it looks like what the implementation you are dealing with is doing is its trying to take into account poccurrences of kill terrorism which is different from pat least occurrence of kill terrorism so why do they end up raising probabilities to powers it looks like their reasoning is that pkill terrorism which they estimated at train time represents the probability of an arbitrary word in a terrorism document to be kill so by simplifying assumption the probability of a second arbitrary word in a terrorism document to be kill is also pkill terrorism this leaves a slight problem for the case that a word does not occur in a document with this scheme the corresponding probability is raised to the th power in other words it goes away in other words it is approximating that poccurrences of music terrorism it should be clear that in general this is strictly speaking false since it would imply that poccurrences of music terrorism but for real world examples where you have long documents and thousands or tens of thousands of words most words dont occur in most documents so instead of bothering with accurately calculating all those probabilities which would be computationally expensive they are basically swept under the rug because for the vast majority of cases it wouldnt change the classification outcome anyway also note that on top of it being computationally intensive it is numerically unstable because if you are multiplying thousands or tens of thousands of numbers less than together you will underflow and it will spit out if you do it in log space you are still adding tens of thousands of numbers together which would have to be handled delicately from a numerical stability point of view so the raising it to a power scheme inherently removes unnecessary fluff decreasing computational intensity increasing numerical stability and still yields nearly identical results i hope the nsa doesnt think im a terrorist for having used the word terrorism so much in this answer s
10692428,what are the existent sentiment analysis algorithm,sentimentanalysis,some of the papers on sentiment analysis may help you one of the earlier works by bo pang lillian lee a comprehensive survey of sentiment analysis techniques study by hang cui v mittal m datar using grams for quick implementation naive bayes is recommended you can find an example here we did a statistical comparision of various classifiers and found svm to be most accurate though for a dataset consisting of large contents none of the methods worked wellour study may not be accurate though also instead of treating sentiment analysis as a text classification problem you can look at extraction of meaning from text though i do not know how successful it might be
32997877,in the porter stemming algorithm what is the purpose of including an identity rule such as ss ss,algorithm informationretrieval stemming,imagine the rule ssss was not in the algorithm then words like caress would not be recognized at all and it would seem that algorithm cant do anything to reduce it to a stem however with the rule ssss the stemmer says i recognize the word caress and i reduce it to caress im done the alternative would be i cant do anything of course it is fictitious work but what matters since is that it increases the precision of the stemmer you can see that when the testing of the algorithm is being done if this rule was not in the stemmer the results would have been different worse look at the word list ridiculousness caress case rule ssss in the algorithm stemming case rule ssss not in the algorithm stemming from practical point of view this rule doesnt matter its just a formalism
30983495,how to split a text into two meaningful words in r,r split stemming textanalysis,given a list of english words you can do this pretty simply by looking up every possible split of the word in the list ill use the first google hit i found for my word list which contains about k lowercase words this sometimes works but also sometimes fails when the relevant words arent in the word list in this case sensor was missing
226485,what is the best turnkey stemming algorithm,comparison stemming,the porter stemmer is the one ive decided to go with it seemed the porter stemmer was the standard but when i found the page by the author he recommended the snowball porter stemmer there is a c port link on this page
78916043,what is the exact vocab size of the mistralnemoinstruct tokenizer model,huggingfacetransformers tokenize largelanguagemodel mistralai,each standard tokenizer has a property called vocabsize and len can also be used to get the size of the supported vocabulary the vocabulary is also available as a dictionary via vocab from transformers import autotokenizer secret hf t autotokenizerfrompretrainedmistralaimistralnemoinstruct tokensecret printtvocabsize printlent printlentvocab output
77910495,what are my options for running llms locally from pretrained weights,python huggingfacetransformers langchain largelanguagemodel,you dont really have to install ollama instead you can directly run the llm for example for mistral model locally llm gptall modelhomejeffcachehuggingfacehubgptallmistralbopenorcaqgguf devicegpu nthreads callbackscallbacks verbosetrue or for falcon from transformers import autotokenizer automodelforcausallm pipeline import torch modelid tiiuaefalconbinstruct tokenizer autotokenizerfrompretrainedmodelid pipeline pipeline textgeneration modelmodelid tokenizertokenizer torchdtypetorchbfloat trustremotecodetrue devicemapauto maxnewtokens maxlength from langchaincommunityllmshuggingfacepipeline import huggingfacepipeline llm huggingfacepipelinepipelinepipeline i have a g ram nvidia installed on my laptop which can support the above models running locally
76403814,what is the best approach to creating a question generation model using gpt and bert architectures,python opensource huggingfacetransformers huggingface gpt,when dealing with text generation it is more straightforward to work with transformer decoder models such as gpt models although bertlike models are also capable of text generation it is a quite convoluted process and not something that follows naturally from the tasks for which these models have been pretrained i assume you are comparing gpt and wizardlm b the performance of the model on this task is expected to improve as you scale up the number of parameters by using larger models i would recommend you to try llms such as alpacalora dolly or gptj see here how to run gptj on colab pro
76130589,what is the function of the parameter in huggingfaces,python huggingfacetransformers huggingface,sometimes it is necessary to look at the code if text is none and texttarget is none raise valueerroryou need to specify either or if text is not none the context manager will send the inputs as normal texts and not texttarget but we shouldnt change the input mode in this case if not selfintargetcontextmanager selfswitchtoinputmode encodings selfcallonetexttext textpairtextpair allkwargs if texttarget is not none selfswitchtotargetmode targetencodings selfcallonetexttexttarget textpairtextpairtarget allkwargs leave back tokenizer in input mode selfswitchtoinputmode if texttarget is none return encodings elif text is none return targetencodings else encodingslabels targetencodingsinputids return encodings as you can see in the above snippet both text and texttarget are passed to selfcallone to encode them note that texttarget is passed as the text parameter that means the encoding of the same string as text or texttarget will be identical as long as switchtotargetmode doesnt do anything special the conditions at the end of the function answer your question when you only provide text you will retrieve the encoding of it when you only provide texttarget you will retrieve the encoding of it when you provide text and texttarget you will retrieve the encoding of text and the token ids of texttarget as the value of the labels key to be honest i think the implementation is a bit unintuitive i would expect that passing the texttarget would return an object that only contains the labels key i assume that they wanted to keep their output objects and the respective documentation simple and therefore went for this implementation or there is a model where it actually makes sense that i am unaware of
75710776,huggingface gpt loss understanding,pytorch huggingfacetransformers gpt,the default loss function is negative loglikelihood the actual model output is not the token city but a categorical distribution over the entire k vocabulary depending on the generation strategy you either sample from these distributions or take the most probable token the token city apparently the most probable one gets some probability and the loss is then minus the logarithm of this probability loss close to zero would mean the token would get a probability close to one however the token distribution also considers many plausible but less likely followups loss corresponds to the probability of exp approximately it seems small but in a k vocabulary it is approximately times more probable than a random guess you can try to finetune the model to be absolutely sure that city will follow with probability but it would probably break other language modeling capabilities
73546673,understanding vocabtxt of vinaibertweetbase,python pytorch huggingfacetransformers,each number denotes the frequency count that the corresponding word appears in the pretraining corpus only top k words are included in the vocab
73537733,how to prepare custom training data for donut document understanding transformer,python huggingfacetransformers,please visit roboflow annotate your images via rob flow annotation tools than export the file in coco json format as the model of donut is expecting the input as json file use script available at hugging face for training the model
73409904,is it possible to get the meaning of each word using bert,huggingfacetransformers bertlanguagemodel,no you can not get the meaning of the word in plain english the whole idea of the bert is to convert plain english into meaningful numerical representations unfortunately these vectors are not interpretable it is a general limitation of deep learning compared to other traditional ml models that use selfextracted features but note that you can use these representation to find out certain relationships between words for example the words that are close to each other in terms of some distance measure have similar meanings have a look at this link for more information
71532653,understanding gpu usage huggingface classification,python gpu huggingfacetransformers,well the variable used for printing that summary is this one the total train batch size is defined as trainbatchsize gradientaccumulationsteps worldsize so in your case worldsize is always except when you are using a tputraining in parallel see
71338750,what is the difference between using a hugging face estimator with training script and directly using a notebook in aws sagemaker,amazonwebservices amazonsagemaker huggingfacetransformers,you could run the script in the notebook itself but it would not deploy with sagemaker provided capabilities then the estimator that you are seeing is what specifies to sagemaker what framework you are using and the training script that you are passing in if you ran the script code in the notebook that would be like training in your local environment by passing in the script to the estimator you are running a sagemaker training job the estimator is meant to encapsulate training on sagemaker sagemaker estimator overview
70367816,what is the difference between marianmt and opusmt,huggingfacetransformers machinetranslation,marian is an opensource tool for training and serving neural machine translation mostly developed at the university of edinburgh adam mickiewicz university in pozna and at microsoft it is implemented in c and is heavily optimized for mt unlike pytorchbased huggingface transformers that aim for generality rather than efficiency in a specific use case the nlp group at the university of helsinki trained many translation models using marian on parallel data collected at opus and opensourced those models later they also did a conversion of the trained model into huggingface transformers and made them available via the huggingface hub marianmt is a class in huggingface transformers for imported marian models you can train a model in marian and convert it yourself opusmt models are marian models trained on the opus data in helsinki converted to the pytorch models if you search the huggingface hub for marian you will find other marianmt models than those from helsinki
67299510,understanding how gpt tokenizes the strings,python huggingfacetransformers transformermodel gpt,you can call tokenizerdecode on the output of the tokenizer to get the words from its vocabulary under given indices
66901602,what is tokenizermax len doing in this class definition,python googlecolaboratory huggingfacetransformers huggingfacetokenizers gpt,the attribute maxlen was migrated to modelmaxlength it represents the maximum number of tokens a model can handle ie including special tokens documentation maxlensinglesentence on the other side represents the maximum number of tokens a single sentence can have ie without special tokens documentation
64631665,what is the difference in robertatokenizer and frompretrained way of initialising robertatokenizer,pytorch huggingfacetransformers huggingfacetokenizers,when you compare the property uniquenosplittokens you will see that this is initialized for the frompretrained tokenizer but not for the other frompretrained tuniquenosplittokens init tuniquenosplittokens this property is filled by addtokens that is called by frompretrained but not by init im actually not sure if this is a bug or a feature frompretrained is the recommended method to initialize a tokenizer from a pretrained tokenizer and should therefore be used
62452271,understanding bert vocab unusedxxx tokens,huggingfacetransformers,a quick search reveals the use of this specifically in the discussion of the original bert implementation and this huggingface thread unused tokens are helpful if you want to introduce specific words to your finetuning or further pretraining procedure they allow you to treat words that are relevant only in your context just like you want and avoid subword splitting that would occur with the original vocabulary of bert to quote from the first discussion just replace the unusedx tokens with your vocabulary since these were not used they are effectively randomly initialized
61774933,understanding the hugging face transformers,pretrainedmodel huggingfacetransformers bertlanguagemodel nlpquestionanswering squad,i would formulate it like this the second link basically describes communityaccepted models ie models that serve as the basis for the implemented huggingface classes like bert roberta etc and some related models that have a high aceptance or have been peerreviewed this list has bin around much longer whereas the list in the first link only recently got introduced directly on the huggingface website where the community can basically upload arbitrary checkpoints that are simply considered compatible with the library oftentimes these are additional models trained by practitioners or other volunteers and have a taskspecific finetuning note that al models from pretrainedmodelshtml are also included in the models interface as well if you have a very narrow usecase you might as well check and see if there was already some model that has been finetuned on your specific task in the worst case youll simply end up with the base model anyways
60243099,what is the meaning of the second output of huggingfaces bert,python deeplearning pytorch huggingfacetransformers,the output in this case is a tuple of lasthiddenstate pooleroutput you can find documentation about what the returns could be here
78425666,proper understanding of keras implementation of lstm how do the units work,tensorflow machinelearning keras lstm,the nuber of parameters can be computed with this formula lstm parameter number x h h h where x is the dimension of the input vector and h is the size of the output space see this link for an explanation nu nx means the ouput space size is the input space size is so p nu nx means you have changed the input space size x to so using the formula you get nu nx means you have doubled the output space again using the formula you get the formula holds also for nu nx i did not find a paper used as a reference for lstm keras implementation but maybe this source code explanation could be of help please note the source code link is not working use this instead
77943601,understanding the inputshape of lstm model,python keras timeseries lstm,in lstm the inputshape is batchsize timesteps features first you need to convert xtrain to a d tensor each x matrix will be a sample so xtrain will be nsamples now you can set the input shape to xtrainshape xtrainshape
75648914,trying to understand lstm parameter hiddensize in pytorch,python pytorch lstm,the hiddensize is a hyperparameter and it refers to the dimensionality of the vector ht it has nothing to do with the number of lstm blocks which is another hyperparameter numlayers it is also explained by the user in the other post you linked since it is a hyperparameter what its value should be needs to be found empirically for the particular task at hand if you pick your hiddensize equal to h and the input size is x notice that parameter matrices wii wif wig wio will be hxx matrices whereas whi whf whg and who will be matrices of size hxh in practice these matrices hxx matrices and hxh matrices are implemented as a two hxx and hxh matrices in pytorch the h parameters you see here are the bias terms
75578232,what is the input dimension for a lstm in keras,python keras lstm,the input to the lstm should be d with the first dimension being the sample size in your case assuming input having shape xy inputshape should xy
75505768,explain the outputs of bidirectional lstm output length is which of them are hidden state and cell state respectively,tensorflow lstm bidirectional,so i have been searching for the answers and i found it on this kaggle
75466325,meaning of d input in keras lstm,keras lstm recurrentneuralnetwork tfkeras,tldr the batch timestep features in your case is defined as none where the batch represents the batchsize parameter passed during modelfit the model does not need to know this before hand therefore when you define your input layer or your lstm layers input shape you simply defined timesteps features which is a simple modelsummary would show you that that input size is translated to none while creating the computation graph deeper dive into the subject a good way to understand whats going on is to simply print the summary of your model let me take a simple example here and walk you through the steps creating a simple stacked lstm model from tensorflowkeras import layers model import numpy as np inp layersinput x layerslstm returnsequencestrueinp x layerslstmx out layersdense activationsigmoidx model modelinp out modelcompilelossbinarycrossentropy modelsummary as you see here the flow of tensors more specifically how the shapes of tensors change as they flow down the network are displayed as you can see i am using the functional api which allows me to specifically create an input layer of the shape which i then pass to the lstm but interestingly you can see that the actual shape of this input layer is none this is the batch timesteps features that you are also referring to the time steps are and a single feature so thats easy to understand however the none is a placeholder for the batchsize parameter which you define during the modelfit fit model xtrain ytrain nprandomrandom nprandomrandom modelfitxtrain ytrain batchsize epochs in this example i set the batchsize to this means that when you train the model each step will pass batches of the shape to the model and there will be such steps in each epoch because the overall size of the training data is this is indicated by the that you see in front of the progress bar for each epoch another interesting thing to note is that you dont necessarily need to define the dimensions of the input as long as your obey the basic rules of model training and batch size constraints here is an example here i define the number of timesteps as none which means that i can now pass variable length timesteps variable length sentences for an example to encode using the lstm layers this means that the model doesnt need to know how many timesteps it will have to work with beforehand similar to the fact that it doesnt need to know what batchsize it would get beforehand these things can be interpreted during the modelfit or passed as a parameter notice the modelsummary simply extends this lack of information around the timesteps dimension to the subsequent layers an important note though lstms can work with variable size inputs because all you have to do is pass the timesteps as none in the example above however you have to ensure that each batch independently has the same number of time steps in other words to work with variablesized sentences say either use a batch size of so that each batch has a consistent size or create a generator which creates batches of equal batchsize and combine sentences with constant length for example the first batch is only sentences the second batch is only sentences etc the second method is faster than the first but may be more painful to setup bonus also for anyone curious around what is the effect of batchsize on model training a large batchsize might be very helpful to speed up computation speed as its preferred over decaying the learning rate but it can cause what is known as a generalization gap this topic is well explored in this awesome paper these papers should give a lot of clarity around how to use batchsize as a powerful parameter for your model training which is quite often ignored
74446578,understanding stacked lstm layers,tensorflow keras lstm recurrentneuralnetwork,yeah you are right lstm works on the principle of recurrences first you have to compute the the first sequence of an entity then only you can go further adding dropout between layers in lstm is not a good strategty why you dont use dropout inside the lstm layer onemore thing use kernelregularizer in the last layer that would add a penalty for large weights or inputs which are more in size
74397618,what is the purpose of ytest in lstm,python machinelearning lstm,the xtest values are the ones you are trying to make a prediction on without having the answers this represents a real world scenario you need to compare your ypred with your ytest values in order to evaluate your model and get a score once the model is deployed and you use real values you wont have any ytest to compare against as you are using unseen data the test set in model development tries to emulate this in order to test how the model generalizes on real world data
73264482,what is the difference between sequential and modelinputoutput in tensorflow,python tensorflow keras deeplearning lstm,the sequence version uses the sequencial model while the modelinputs outputs uses the functional api the first is easier to use but only works for singleinput singleoutput feed forward models in the sense of keras layers the second is more complex but get rid of those constraints allowing to create many more models so your main point is right any sequencial model can be rewritten as a functional model you can double check this by comparing the architectures with the usage of summary function and plotting the models however this only shows that architectures are the same but not the weights assuming you are fitting both models with same data and same compile and fit params by the way include those in your question there is lots of randomness in the training process which may lead to different results so try the following to compare them better remove as much randomness as possible by setting seeds in your code and for each layer instantiation avoid using data augmentation if using it use the same validationtrain split for both models to be sure you can split the dataset yourself do not use shuffling in data generators nor during the training here you can read more about producing reproducible results in keras even after following those tips your results may not be deterministic and hence not the same so finally and maybe more important do not compare single run train and eval each model several times for instance and then compare the average mae with its standard deviation if after all this your results are still so different please update your question with them
73196304,why use regressorlayersinput regressorlayersoutput instead of just regressor in deepexplainer,python tensorflow time lstm shap,the solution is quite simple lets look at the deepexplainer documentation this is the init function your confusion is about the first argument that is model according to the documentation for tensorflow model is a pair of tensorflow tensors or a list and a tensor that specifies the input and output of the model to be explained so thats it the first argument is just a pair indicating the input and the output of the model in this case update in the example front page deepexplainer mnist example it is however shown this piece of code from this it seems that besides the pair of tensors it is also possible to use the model as input just like it is possible for pytorch indeed in pytorch instead of the pair you can also use a nnmodule object at this point then i guess that the one for tensorflow is just an undocumented feature it should then be equivalent to use directly the model or the pair of tensors
73186936,what is the training accuracy of this model,matlab machinelearning deeplearning artificialintelligence lstm,the problem can be solved using the following line of code
72518461,need clear concept of the dimensions of output and hidden from lstm layers,pytorch lstm,whats tripping you up is the input format to lstm the default input shape to a lstm layer is sequence l batch n features h while in you code you are sending input as nlh batch sequence features to use this correctly set the parameter batchfirsttrue to the lstm layer then the input and output will be as you expect but there is a catch here too only the output st of the outputs will be nlh while both hidden and cell nd and rd of the outputs will still be lnh format the second thing to note here is the hidden cell will have dimensionality equal to the number of layers ie in your example each layer will require fill of its own hidden weights hence the output instead of
70629560,what is the difference between batch batchsize timesteps features in tensorflow,tensorflow keras lstm,difference between batchsize v batch in the documentation you quoted batch means batchsize meaning of timesteps and feature taking a glance at weather forecast example with realworld data will help you understand more about timeseries data feature is what you want the model to make predictions from in the above forecast example it is an vector array of pressure temperature etc rnn lstm are designed to handle timeseries this is why you need to feed timesteps along with feature to your model timesteps represents when the data is recorded again in the example above data is sampled every hour so timesteps is the data taken at the first hour timesteps the second hour order of dimensions of the input output data in tensorflow the first dimension of data often represents a batch what comes after the batch axis depends on the problem field in general global features like batch size precedes elementspecific features like examples timeseries data are in batchsize timesteps feature format are often represented in nhwc format batchsize imageheight imagewidth channels from while axes are often referred to by their indices you should always keep track of the meaning of each often axes are ordered from global to local the batch axis first followed by spatial dimensions and features for each location last this way feature vectors are contiguous regions of memory
69281314,what is the output of the dlj lstm neural network,java lstm dlj ndj,this function samples from the distribution instead of simply returning the most probable character class that also means that you arent getting the most likely character instead you are getting a random character with the probability that the given probability distribution defines this works by first getting a random value between and from a uniform distribution rngnextdouble and then finding where that value falls in the given distribution you can imagine it to be something like this if your had only a to f in your alphabet if the random value that is drawn is just over it would produce an e if it is just less than that it would be a d each letter occupies a proportional amount of space on this line between and according to the weight it has in the distribution
69277384,understanding the architecture of an lstm for sequence classification,pytorch lstm recurrentneuralnetwork,your code is a basic lstm for classification working with a single rnn layer in your picture you have multiple lstm layers while in reality there is only one hn in the picture your input to lstm is of shape b l d as correctly pointed out in the comment packedoutput and hc is not used at all hence you can change this line to ht selflstmlstminput in order no to clutter the picture further ht is output of last step for each batch element in general b d l hiddensize as this neural network is not bidirectional d as you have a single layer l as well hence the output is of shape b hiddensize this output is reshaped into nnlinear compatible this line ht htview selfhiddensize and will give you output of shape b hiddensize this input is fed to a single nnlinear layer in general the output of the last time step from rnn is used for each element in the batch in your picture hn and simply fed to the classifier by the way having selfout nnlinearhiddensize in classification is probably counterproductive most likely your are performing binary classification and selfout nnlinearhiddensize with torchnnbcewithlogitsloss might be used single logit contains information whether the label should be or everything smaller than is more likely to be according to nn everything above is considered as a label
69215063,can someone explain batchsize and timestep for a regression model using rnn,machinelearning timeseries regression lstm recurrentneuralnetwork,given output this is for m samples s timesteps with e measurements per timesteps in any case the number of data points is the size of the array so the number of data point per sample if you meaure temperature every second for an hour on one sample if you measure let say temperature and humidity let say you do that simultaneously for samples in place a and b batch size is just not related at all for each epoch it just means how many samples you want to run at once for samples batch size you have two weight update per epoch for instance
69209674,what is equivalent to pytorch lstm numlayers,python pytorch lstm,if you define state as a list of the layers states then
68109005,didnt understand expected shapenone none found shape confusion about lstm input shape the data is genome sequence,python tensorflow keras deeplearning lstm,d convolution on sequences expects a d input whereas the lstm you are using outputs a d arraybatchsize units as the argument returnsequences is set to false this argument tells whether to return the output at each time step instead of the final time step changing it to true returns a d arraybatchsize timesteps units instead of a d array also just a small thing but dont hardcode the input shape instead set it to something like inputshapextrainshapextrainshape edit so in addition to that you would need to expand the dimension of the last channel before passing it to the model reshape it using this method do not reshape it like this you could easily make an error with the number of values in any of the channels then just change the input shapes of the lstm to the nd and rd channels of the input data
67345023,what is the correct input shape of multivariate time series for lstm in keras,python machinelearning keras lstm,from the keras lstm api inputs a d tensor with shape batch timesteps feature therefore the features multiple variables should be represented by the last dimension which means your st suggestion is the right one obs the batch dimension should be only of concern if you arent using the fit function for a whole dataset otherwise if you are presenting a single example for instance in inference you should also apply the numpyexpanddims function in the th axis
67287240,what is the difference between batch size in tfkeraspreprocessingtimeseriesdatasetfromarray and batch size in modelfit,tensorflow keras timeseries lstm batchsize,from the documentation on modelfit located here so do not specify the batch size in modelfit
67202347,i cant understand lstms prediction output,python tensorflow keras neuralnetwork lstm,you are getting the probabilities of each class and do the following if you are using keras you can also
67132164,trying to understand the accuracy function being applied to lstm data in this code,python numpy tensorflow lstm,well you should describe your data and model output better i suppose the data is a pandas dataframe and you are using sklearn to preprocess your data first you need to normalize your data so i suppose somewhere in your code you had a minmaxscaler or some sklearn transformation that mapped an entire column of your dataframe to values between and from your code it seems it was the columnscaler so you have to unnormalize those values to be real cash values by using inversetransform so a ypred value of becomes the lowest value you originally had on your data suppose then you are converting the price predictions to truefalse values boolean checking if the price in the future is higher than the price in the present looking lookupstep ticks ahead with this array that tells only if prices go up or not you calculate the jaccard score from sklearn i suppose that just tells you how many up prices you got right in relation to the ones you got wrong if you did not execute those postprocessing steps the accuracyscore would give a different value i am not sure if it even accept floats as values it would give an error
67099896,trying to understand how to interpret accuracy score output from lstm neural network,python tensorflow lstm,from scikitlearns documentation the accuracy score you compute here is either the fraction default or the count normalizefalse of correct predictions
66952606,what is this flatten layer doing in my lstm,python machinelearning keras lstm flatten,an lstm layer consists of different lstm cells that are processed sequentially as seen in the figure below the first cell takes an inputembedding calculates a hidden state and the next cell uses its input and the hidden state at previous time step to compute its own hidden state basically the arrows between the cells also pass the hidden states if you do returnsequencesfalse the lstm layer only outputs the very last hidden state h in the figure so all those information from all inputs and cells are embedded in a single fixed size information and it can not contain lots of information this is why your accuracy is not good when you only use the last hidden state when you do returnsequencestrue lstm layer outputs every hidden state so the next layers have access to all hidden states and they contain naturally more information however the lstm layer returns a matrix you can also see this in your model summary it returns a matrix of size none none is basically number of samples in your batch you can forget about it is your input size and is your hidden state size the dense layer can not process a matrix it has to be a vector that why you need to apply flatten and what it does is basically just to open up the d matrix and represent it as d vector therefore the size of your flatten layer is because and of course with more hidden states the accuracy is better as they contain more information
66326292,tries to understand tensorflow inputshape,tensorflow deeplearning lstm tensorflow,the inputshape argument in a keraslayersltsm layer expects a d array with a shape of timesteps features your doc has the shape batchsize timesteps features and therefore one dimension too much you can use the batchinputshape argument instead if you want feed batchsize too to do so you have just to replace this line of your code with this one if youre setting a specific batchsize in your model and then feed a different size other than in your case you will get an error using inputshape instead you have the flexibility to feed any batch size to the network
65725287,what is training accuracy and training loss and why we need to compute them,python lstm,loss and valloss in deep learning the loss is the value that a neural network is trying to minimize that is how a neural network learns by adjusting weights and biases in a manner that reduces the loss loss and valloss differ because the former is applied to the train set and the latter to the test set as such the latter is a good indication of how the model performs on unseen data accuracy and valaccuracy once again acc is on the training data and valacc is on the validation data its best to rely on valacc for a fair representation of model performance because a good neural network will end up fitting the training data at but would perform poorly on unseen data training should be stopped when valacc stops increasing otherwise your model will probably overffit you can use earlystopping callback to stop training why do we need train accuracy and loss its not a meaningful evaluation metric because a neural network with sufficient parameters can essentially memorize the labels of training data and then perform no better than random guessing on previously unseen examples however it can be useful to monitor the accuracy and loss at some fixed interval during training as it may indicate whether the backend is functioning as expected and if the training process needs to be stopped refer here for a detailed explanation about earlystopping how accuracy and loss are calculated loss and accuracy are calculated as you train according to the loss and metrics specified in compiling the model before you train you must compile your model to configure the learning process this allows you to specify the optimizer loss function and metrics which in turn are how the model fit function knows what loss function to use what metrics to keep track of etc the loss function like binary cross entropy documentation can be found here and the metrics like accuracy documentation can be found here
65214697,understanding lstm through example,python neuralnetwork lstm recurrentneuralnetwork,so this is not obvious from the figures but here is how it works if you see two lines joining to form a single line its a concatenation operation you have interpreted it as an addition wherever you see sigmoid or tanh blocks a multiplication with a trainable weight matrix is implied if two lines are joined by an explicit x or you are doing element wise multiplication and addition respectively so instead of sigmoidhtminusxt which is what you have the correct operation would be sigmoidwf npconcatenatehtminusxt bf wf is the matrix of trainable parameters and bf is the corresponding bias terms note that i have just written the equations on the right side of the images in numpy not much else interpret a b as the concetenation operations between a and b you can define the other operations similarly note i have represented ctilda as ctt
65054600,understanding the role of timestamp in keras lstm,python tensorflow keras lstm recurrentneuralnetwork,if you make these changes you should feed to the network sequences of instead of k keras will not split automatically you have to do it manually and you should prepare labels for every sequence of
64875492,understanding the time steps and samples in keras lstm,keras lstm,the number of rows the date field is a sequence you can divide that sequence into multiple or single inputoutput and that are your samples for example you can have two time steps as input and one time step as output hence each sample has a specific number of time steps the output is a single step you can have multi step output as well so as we said the inputs two timestep and so on
64640843,understanding the model of openai unit lstm reinforcement learning,tensorflow machinelearning deeplearning lstm openaiapi,it means that the size of the hidden state is units which is essentially that your lstm has cells in each timestep we do not know in advance how many timesteps we will have the state of the lstm hidden state represents the current state that is observed by the agent it gets updated every timestep using the input received this hidden state can be used to predict the qfunction as in deep qlearning you dont have an explicit table of state action qvalue instead you have a sized vector which represents the state and feeds into another dense layer which will output the qvalues for all possible actions lstms are the mechanism which help stop vanishing gradients as the long range memory also allows the gradients to flow back easier if you are referring to the big blue and pink boxes then the pink ones seem like they are the input values which are put through a network and pooled over each pickup or modifier the blue space seems to be the same thing over each unit the terms pickup modifier unit etc should be meaningful in the context of the game they are playing here is an the lstm the yellow nodes at each step are the n the vector h is the hidden state of the lstm which is being passed to both the next timestep and being used as the output of that timestep
64623876,numunits in gru and lstm layers in keras tensorflow confuse meaning,python tensorflow keras lstm,the argument numunits in an lstm layer refers to number of lstm units in that layer with each lstm unit comprising the below architecture
63299153,lstm keras what is the right input shape,python tensorflow keras deeplearning lstm,you can use this function to transform a d dataset to a dataset with a customizable number of time steps i did it successfully with your task i simplified it a little output
62856237,understanding tensorflow keras lstm when activationsoftmax,python tensorflow keras lstm,it doesnt sum to one because the activation here is directly apply on each hidden unit as joelthchao said on github
62256568,what is the relationship between batch size timestep and error in lstm keras,python keras lstm recurrentneuralnetwork lstmstateful,batch size effect on lstm for batch size the model takes input at each timestep for batch size n model takes n input at each timestep error calculation part mentioned in question it is the error calculation for batch size error for a batch sum up the error for each element of the batch to get the final error batching in stateful lstm my understanding of parallelism was incorrect parallelism is done within batch not across them
62169725,building cnn lstm in keras for a regression problem what are proper shapes,python tensorflow keras deeplearning lstm,one possible solution is setting the lstm input to be of shape numpixels cnnfeatures in your particular case having a cnn with filters the lstm would receive
62136814,im getting tensorop is meaningless when eager execution is enabled in my simple encoder model tf,tensorflow keras lstm tensorflow keraslayer,in tf static graph preventing eager execution with dynamic graph can be constructed by using a decorator try tffunction decorator tffunction def encodermodelinp input embedobjinp h maskinglambda x xx for x in rangeinput lstm stateh statec lstm returnsequencestrue returnstatetrueh model modelinputsinput outputslstm stateh statec return model then call the function
61913223,understand the summary of a lstm model,python deeplearning lstm,part of your question is answered here simply put the reason there are so many parameters for an lstm model is because you have tons of data in your model and many weights need to be trained to fit the model dropout layers dont have parameters because there are no weights in a dropout layer all a dropout layer does is give a chance that a neuron wont be included during testing in this case youve chosen beyond that there is nothing to configure in a dropout layer
61844967,what is the connections between two stacked lstm layers,machinelearning deeplearning lstm recurrentneuralnetwork tfkeras,its not length its features the length is in the input shape and it never changes there is absolutely no difference between what happens when you give a regular input to one lstm and what happens when you give an output of an lstm to another lstm you can just look at the models summary to see the shapes and understand what is going on you never change the length using lstms they dont communicate at all each one takes the length dimension processes it recurrently independently from the other when one finishes and outputs a tensor the next one gets the tensor and process it alone following the same rules
61808538,understanding dense layer in lstm architecture labels logits,machinelearning deeplearning lstm recurrentneuralnetwork,the short answer is that the keras loss function sparsecategoricalcrossentropy does everything you need at each timestep of the lstm model the top dense layer and softmax function inside that loss function together generate a probability distribution over the models vocabulary which in this case are musical notes suppose the vocabulary comprises the notes a b c d then one possible probability distribution generated is meaning that the model is putting a lot of probability on note b index like so suppose the true note should be c which is represented by the number since it is at index in the distribution array with indexing starting at to measure the difference between the predicted distribution and the true value distributions use the sparsecategoricalcrossentropy function to produce a floatingpoint number representing the loss more information can be found on this tensorflow documentation page on that page they have the example ytrue ypred loss tfkeraslossessparsecategoricalcrossentropyytrue ypred you can see in that example there is a batch of two instances for the first instance the true label is and the predicted distribution is and for the second instance the true label is while the predicted distribution is this function is used in your jupyter notebook in section to train our model on this classification task we can use a form of the crossentropy loss negative log likelihood loss specifically we will use the sparsecategoricalcrossentropy loss as it utilizes integer targets for categorical classification tasks we will want to compute the loss using the true targets the labels and the predicted targets the logits so to answer your questions directly it is my understanding that in this notebook in computeloss in any given batch we are comparing expected labels which are the notes themselves to the logits ie predictions from the dense layer yes your understanding is correct however arent these predictions supposed to be a probability distribution yes they are when are we actually selecting the label that we are predicting against it is done inside the sparsecategoricalcrossentropy function if your distribution is then that implicitly means that the function is predicting probability for index probability for index and probability for index a little more clarification on my question if the shape of our labels is batchsize of time steps and the shape of our logits is batchsize of time steps vocabsize at what point in the computeloss function are we actually selecting a label for each time step its inside that function
61733495,understand the output of lstm autoencoder and use it to detect outliers in a sequence,machinelearning keras lstm autoencoder anomalydetection,as you said its an autoencoder your autoencoder tries to reconstruct your input as you see the output values are very close to the input values there is not a big error so the autoencoder is well trained now if you want to detect outliers in your data you can compute the reconstruction error could be mean square error between input and output and set up a threshold if reconstruction error is superior than the threshold its gonna be an outlier since the autoencoder is not trained on reconstructing outlier data this schema reprensents better the idea i hope this helps
61632584,understanding input shape to pytorch lstm,python pytorch lstm tensor,you have explained the structure of your input but you havent made the connection between your input dimensions and the lstms expected input dimensions lets break down your input assigning names to the dimensions batchsize seqlen inputsize numfeatures that means the inputsize of the lstm needs to be the hiddensize is not dependent on your input but rather how many features the lstm should create which is then used for the hidden state as well as the output since that is the last hidden state you have to decide how many features you want to use for the lstm finally for the input shape setting batchfirsttrue requires the input to have the shape batchsize seqlen inputsize in your case that would be import torch import torchnn as nn size batchsize seqlen inputsize input torchrandn lstm nnlstminputsize hiddensize batchfirsttrue output lstminput outputsize torchsize
61435747,understanding lstm with a simple dataset,python pytorch lstm recurrentneuralnetwork,there are multiple issues in your forward function take a look at the input that you are passing to the lstm inputseq inputseqview selfbatchsize printinputseq tensor this is a series of random numbers you either have to transpose the inputseq or even better pass batchfirsttrue to the lstm constructor and just unsqueeze the inputseq before passing it to the lstm you also have to update the lstmout the only operation that is needed now is to reshape it to batchsize x hiddensize lastly you need to squeeze the output of the linear layer aside from those the hidden size of the lstm is too small use or even instead of one only then the model converges in epochs here is the updated code class lstmnnmodule def initself hiddenlayersize batchsize superinit selfhiddenlayersize hiddenlayersize selfbatchsize batchsize selflstm nnlstm hiddenlayersize batchfirsttrue selflinear nnlinear hiddenlayersize selfhiddencell torchzerosselfbatchsizeselfhiddenlayersize torchzerosselfbatchsizeselfhiddenlayersize def forwardself inputseq batchsize inputseqsize inputseq inputsequnsqueeze lstmout selfhiddencell selflstminputseq selfhiddencell lstmout lstmoutreshapebatchsize predictions selflinearlstmoutsqueeze return predictions
61296736,how to understand and debug the error inside kerasmodelfit,keras lstm keraslayer tfkeras,your output layer has outputs probably classes are given but the target labels in ytrain are given as integers apparently array is flat you need to convert ytrain to a onehot encoded array first otherwise the crossentropy loss cannot be computed input and output tensors must always be compatible with the inputs and outputs of the model given that there are classes in ytrain encoded as you require a conversion etc try it like this
61149523,understanding the structure of my lstm model,python tensorflow keras lstm recurrentneuralnetwork,in a simplistic viewpoint you can consider a lstm layer as an augmented dense layer with a memory hence enabling efficient processing of sequences so the concept of units is also the same for both the number of neurons or feature units of these layers or in other words the number of distinctive features these layers can extract from the input therefore when you specify the number of units to for the lstm layer more or less it means that this layer can only extract distinctive features from the input timesteps note that the number of units has nothing to do with the length of input sequence ie the entire input sequence will be processed by the lstm layer no matter what the number of units or the length of input sequence is usually this might be suboptimal though it really depends on the difficulty of the specific problem and dataset you are working on ie maybe units might be enough for your problemdataset and you should experiment to find out therefore often a higher number is chosen for the number of units common choices and also the classification task is delegated to a dedicated dense layer or sometimes called softmax layer at the top of the model for example considering the description of your problem a model with stacked lstm layers and a dense classification layer at the top might look like this
60404120,what is timestep in lstm layers from keras and how choose the value for this parameter,tensorflow keras deeplearning lstm autoencoder,i have called timestpe i think it should be or not necessarily should be equal to the number of frames i want to predict you are right the timestep is not equal to the number of frames you want to predict let us frame it in a naturallanguage friendly description the timestep in essence is the number of units secondsminuteshoursdaysframes in a video etc which is used to predict the future steps for example you want to predict the stock price taking into account the last days in this case the timestep where t currentday t currentday etc notice that the currentday would be here something like the future day like predicting in advance for today you want to predict maybe the stock price in the current day in this case you would to onestepforecast however you may also want to predict the stock price in the current day tomorrow and the day after tomorrow that is predict ttt by taking into account tttttthe acknowledged nomenclature for the second case is called multistepforecast notice how the timestep which is strictly related to past is not related as computation for the multistepforecast evidently according to your problem it is almost always the case that for multistepforecast you may need to take into consideration a bigger past frame ie increase the number of timesteps in order to help your lstm capture more data correlation if you were to relate it to the amount of data per batch you can consider a batchsize of equal to chunks of data in which ttttt are taken to predict t therefore chunks of the form tttttt when you prepare the data and you want to predict the next frame of course you need exact perfect order for your past values tt inside a chunk what you do not need is to have the exact consecutive chunks from a video say in other words you can have a chunk like the one described above from video a chunk from video etc
59072728,what is the rule to know how many lstm cells and how many units in each lstm cell do you need in keras,python tensorflow keras lstm recurrentneuralnetwork,there are no rules but there are guidelines in practice youd experiment with depth vs width each of which works differently rnn width is defined by of input channels of cells filters output channelsunits as with cnn each rnn filter is an independent feature extractor more is suited for highercomplexity information including but not limited to dimensionality modality noise frequency rnn depth is defined by of stacked layers of timesteps specifics will vary by architecture but from information standpoint unlike cnns rnns are dense every timestep influences the ultimate output of a layer hence the ultimate output of the next layer so it again isnt as simple as more nonlinearity stacked rnns exploit both spatial and temporal information in general width extracts more features whereas depth extracts richer features but if there arent many features to extract from given data width should be lessened and the simpler the dataproblem the less layers are suitable ultimately however it may be best to spare extensive analysis and try different combinations of each see this so for more info lastly avoid dropout and use lstmrecurrentdropout instead see linked so
58748732,dropout layer before or after lstm what is the difference,tensorflow keras lstm dropout,as default dropout creates a random tensor of zeros an ones no pattern no privileged axis so you cant say a specific thing is being dropped just random coordinates in the tensor well it drops features but different features for each step and differently for each sample you can if you want use the noiseshape property which will define the shape of the random tensor then you can select if you want to drop steps features or samples or maybe a combination dropping time steps noiseshape steps dropping features noiseshape features dropping samples noiseshape none there is also the spatialdropoutd layer which uses noiseshape inputshape inputshape automatically this drops the same feature for all time steps but treats each sample individually each sample will drop a different group of features after the lstm you have shape none so you use dropout the same way you would use in any fully connected network it drops a different group of features for each sample a dropout as an argument to the lstm has a lot of differences it generates different dropout masks for creating different inputs for each of the different gates you can see the lstmcell code to check this also there is the option of recurrentdropout which will generate dropout masks but to be applied to the states instead of the inputs each step of the recurrent calculations
58053525,what is the meaning of hiddendim and embedsize in lstm,python lstm recurrentneuralnetwork,a recurrent neural network lstm at its most fundamental level is simply a type of densely connected neural network the hidden dimension is basically the number of nodes in each layer like in the multilayer perceptron for example the embedding size tells you the size of your feature vector the model uses embedded words as input here some details
57764089,deep learning concept hyperparameter tuning weights rnnlstm,deeplearning lstm recurrentneuralnetwork,we initialize weights randomly to ensure that each node acts differentlyunsymmetric from others depending upon the hyperparametersepochs batch size etc iterationsthe weights are updated until the iterations last in the end we call the updated weights as models seed is used to control the randomness of initialization if im not wrong a good learning algorithmobjective function and optimizer converges irrespective of seed values again a good model means tuning all the hyperparameters making sure that the model is not underfitting on the other hand even the model shouldnt overfit there is nothing like the best parametersweights bias we need to continuously tune the model until the results are satisfactory and the main parts are data processing
57142772,what is the correct procedure to split the data sets for classification problem,python machinelearning lstm traintestsplit,tldr try both i have been in similar situations before where my dataset was imbalanced i used traintestsplit or kfold to get through however once i stumbled upon the problem of handling imbalanced datasets and came across the techniques of overbalancing and underbalancing to do this i would recommend using the library imblearn you will find various techniques there to handle the cases where one of your classes outnumbers the other one i personally have used smote a lot and have had relatively better success in such cases other references
57126813,what is causing such low accuracy for this lstm,machinelearning keras neuralnetwork lstm recurrentneuralnetwork,youre just not training on enough epochs samples need more than epochs and your lstm network is too simple also id recommend working with the transformer model over lstm usually gives a better accuracy for voicespeech data
55770578,understanding epoch batch size accuracy and performance gain in lstm forecasting model,tensorflow machinelearning keras neuralnetwork lstm,having a very large epoch size will not necessarily improve your accuracy epoch sizes can increase the accuracy up to a certain limit beyond which you begin to overfit your model having a very low one will also result in underfitting see this so looking at the huge difference between epoch and epoch you can already tell that you are overfitting the model as a rule of thumb when you notice the accuracy stops increasing that is the ideal number of epochs you should have usually between and seems too much already batch size does not affect your accuracy this is just used to control the speed or performance based on the memory in your gpu if you have huge memory you can have a huge batch size so training will be faster what you can do to increase your accuracy is increase your dataset for the training try using convolutional networks instead find more on convolutional networks from this youtube channel or in a nutshell cnns help you identify what features to focus on in training your model try other algorithms
55723284,what is the meaning of multiple kernels in keras lstm layer,keras neuralnetwork lstm,correct me if im wrong but if you take a look at the lstm equations you have w matrices that transform the input and u matrices that transform the hidden state keras saves these sets of matrices into the kernel and recurrentkernel weight arrays from the code that uses them apparently the matrices are stored inside the weight arrays concatenated along the second dimension which explains the weight array shapes
55314078,what is the difference between these two ways of building a model in keras,python keras lstm,theyre two ways of creating dl models in keras the first code snippet follows functional style this style is used for creating complex models like multiinputoutput shared layers etc the second code snippet is sequential style simple models can be created which involves just stacking of layers if you read the functional api guide youll notice the following point a layer instance is callable on a tensor and it returns a tensor now the error youre seeing would make sense this line only creates the layer and doesnt invoke it by passing a tensor subsequently passing this embedding object to lstm layer throws an error as it is expecting a tensor this is an example from the functional api guide notice the output tensors getting passed from one layer to another
54903999,understanding lstms layers data dimensions,python machinelearning keras lstm recurrentneuralnetwork,i interpret your description as saying that your total dataset is of data samples where each data sample has time slots each with a vector of dimensions if that the case the inputshape for your model should be defined as the batch size is simple the number of samples out of the that will be used for a training test prediction run try the following this is just a simplistic model that outputs a single wide vector for each sample you will see that the expected modelinput is the batchsize is unset in the input shape which means that the model can be used to train predict batches of different sizes
54892813,what is the difference between sequencetosequence and sequencetoone regression in lstm networks,matlab neuralnetwork lstm,sequencetosequence the output is the hidden state of the lstm cell at each time step in the input sequence we want the state of the lstm as it consumes each point in the sequence and considers its previous state for example when you are differentiating a time series you want the gradient at each point in the sequence the lstm is basically translating the input sequence into an output sequence the output would be h h h h sequencetoone in this case it is assumed that all we want is the state of the lstm after consuming the whole sequence for example when you are integrating a timeseries you want the end result after integrating the whole sequence so the output would just be h
54836840,keras understanding parameters for lstm layer,keras lstm,the number of parameters of lstm taking input vectors of size m and giving output vectors of size n is nmn with bias vectors the number becomes nmn n more
54675975,i need to understand this lstm and masking layers result,keras lstm chatbot recurrentneuralnetwork,not sure exactly what exactly you dont understand but modelsummary prints a summary representation of your model kerasio it lists all layers used in the given model with its respective size this particular model obviously starts with a masking layer for input sequences i guess because of padding and is followed by the simplest lstm model possible
54491259,understanding initialization of weights and biases in tensorflow,python pythonx tensorflow lstm,in your case the creation of weight and bias variables happens inside the cell and then inside the fully connected layer so there is no need to define them explicitly also when you are building the graph tensorflow doesnt initialize any of your variables after before you start executing nodes in the graph you have you initialize the variables in the graph beforehand have a look
54009661,what is the timestep in keras lstm,python tensorflow keras lstm,im unsure on how to shape the input for a stateful lstm but before using stateful lstm ask yourself do i really need statefull lstm see here and here for more details what is the best option to reshape the data for a stateful lstms input it really depends on the problem on hands however i think you do not need reshaping just feed data directly into keras what means the timestep of the input in this case and why in your example timestamp is see here for further details on timestamp in the following picture we have timestamps that we feed them into the lstm network is the batchsize related to the timestep no it has nothing to do with batchsize more details on batchsize can be found here here is simple code based on the description that you provide it might give you some intuition
53548672,understanding keras lstm input shape,keras lstm,it only makes sense to have batches of timestep when youre using statefultrue otherwise there is no temporal dependency as you presumed the difference is statefulfalse inputshapeany first batch of shape n any contains n different sequences of length second batch contains another n different sequences of length total of the two batches n sequences of length more batches more independent sequences yes there is no point in using steps when statefulfalse statefultrue inputshapeany first batch of shape n any contains the first step of n different sequences second batch contains the second step of the same n sequences total of the two batches n sequences of length more batches more steps of the same sequences until you call modelresetstates usually its more complicated to handle statefultrue layers and if you can put entire sequences in a batch like inputshapeallsteps any there is no reason to turn stateful on if you want a detailed explanation of rnns on keras see this answer
53512769,trouble understanding lstm output,python keras lstm sequential,those numbers are the numbers you got from your last layer which is a sigmoid layer sigmoid will return values between and which is what we see in your output how to interpret these values since you are feeding and looking for onehot outputs you could select the maximum number in last axis and get its index value on that axis with npargmaxprediction axis this should give you a numpy array with shape each element is a number between which is the same format as your original data these values are what your what your lstm model predicted as the most likely outcome second biggest number would be the second most likely outcome
53475803,understanding the softmax output layer of rnn,python lstm pytorch recurrentneuralnetwork softmax,are the two models ive printed above equivalent lets ignore the recurrentdropout since i havent figure out how to do that in pytorch besides the dropout i can see no difference so they should be completely equivalent in terms of structure one note you dont have to initialize the states if you use it this way if youre not reusing the states you can just forward the lstm with x selfblstmx it will automatically initialize states with zeros what am i doing wrong with the softmax output layer in pytorch pytorch torchnncrossentropyloss already includes softmax this criterion combines nnlogsoftmax and nnnllloss in one single class so it is actually a ce with logits i guess this makes it more efficient so you can just leave out the softmax activation at the end
52621257,understanding apparently different keras lstm api calls,python keras lstm,in your question you mentioned the use of i think the author mislead you as batchsize is the incorrect term to be used here as you can see in the keras api spec the first parameter defines the number of hidden states units in this layer i looked at the medium post you linked and i believe what likely happened is that the batchsize was equal to the number of units and the author was lazy uniformed and decided to use the same constant for both there has been no change to keras since may of this year when the post was written that can explain their mistake as for the so post batchinputshape is only applicable for stateful lstm layers from the documentation you can set rnn layers to be stateful which means that the states computed for the samples in one batch will be reused as initial states for the samples in the next batch this assumes a onetoone mapping between samples in different successive batches to enable statefulness specify statefultrue in the layer constructor specify a fixed batch size for your model by passing if sequential model batchinputshape to the first layer in your model else for functional model with or more input layers batchshape to all the first layers in your model this is the expected shape of your inputs including the batch size it should be a tuple of integers eg specify shufflefalse when calling fit as for your question regarding the nature of batchsize in text analysis it simply refers to the number of samples to propagate through the network therefore if you wanted to pass only a single sentence at a time you could set it to the problem with this is that your gradient estimation will be less accurate if you can memory constraints come into play here you should use a larger batchsize
52615715,understanding keras lstm tensorboard graph,python tensorflow keras lstm tensorboard,i figured out why it is showing like that it turns out that keras creates a learningphase placeholder and it places it in the second hidden layer the learningphase object branches out to every single layer but the lstm itself does not i refer to this answer for more details heres what the insides of my lstm layer looked like in my tensorboard graph
52415147,what is the meaning of parameter in lstm matlab,matlab machinelearning neuralnetwork deeplearning lstm,the parameter is actually explained on the mathworks documentation page size of the minibatch to use for each training iteration specified as the commaseparated pair consisting of minibatchsize and a positive integer a minibatch is a subset of the training set that is used to evaluate the gradient of the loss function and update the weights see stochastic gradient descent as for what it is there exist several answers on the web both on stackexchange websites here and here and elsewhere on the web generally it should influence the convergence of your optimization algorithm and how much memory is used during the computation note that it is generally preferred by now to use smaller batch sizes as long as you dont have too much training data
52388831,understanding multivariate time series classification with keras,python machinelearning keras timeseries lstm,i believe the input shape for keras should be inputshapenumberofsamples nbtimesteps maxnbfeatures and most often nbtimesteps ps i tried solving a very similar problem for an internship position but my results turned out to be wrong you may take a look here see if you can spot my mistake
52164882,understanding weights shape of an lstm cell with d input tensor,python keras lstm recurrentneuralnetwork mnist,the equation you mentioned is for computing the output for tth timestep therefore only the input at timestep t is used ie xt and not all the inputs ie x as a result we would have and this is in harmony with what lstm layers are meant to do they get the input at timestep t and give an output based on the that input and the state resulted from processing the first to tth timesteps
51963182,understanding tensorflow basiclstmcell kernel and bias shape,tensorflow machinelearning deeplearning lstm recurrentneuralnetwork,first about summing inputdepth and hdepth rnns generally follow equations like ht wht vxt to compute the state h at time t that is we apply a matrix multiplication to the last state and the current input and add the two this is actually equivalent to concatenating ht and xt lets just call this c stacking the two matrices w and v lets just call this s and computing sc now we only have one matrix multiplication instead of two i believe this can be parallelized more effectively so this is done for performance reasons since ht has size hdepth and x has size inputdepth we need to add the two dimensionalities for the concatenated vector c second you are right about the factor coming from the gates this is essentially the same as above instead of carrying out four separate matrix multiplications for the input and each of the gates we carry out one multiplication that results in a big vector that is the input and all four gate values concatenated then we can just split this vector into four parts in the lstm cell source code this happens in lines
51932767,how to interpret clearly the meaning of the units parameter in keras,python keras lstm,you can sort of think of it exactly as you think of fully connected layers units are neurons the dimension of the output is the number of neurons as with most of the well known layer types the difference is that in lstms these neurons will not be completely independent of each other they will intercommunicate due to the mathematical operations lying under the cover before going further it might be interesting to take a look at this very complete explanation about lstms its inputsoutputs and the usage of stative truefalse understanding keras lstms notice that your input shape should be inputshapelookback the input shape goes for timesteps features while this is a series of fully connected layers hidden layer units hidden layer units output layer unit this is a series of lstm layers where inputshape batchsize arbitrarysteps each lstm layer will keep reusing the same unitsneurons over and over until all the arbitrary timesteps in the input are processed the output will have shape batch arbitrarysteps units if returnsequencestrue batch units if returnsequencesfalse the memory states will have a size of units the inputs processed from the last step will have size of units to be really precise there will be two groups of units one working on the raw inputs the other working on already processed inputs coming from the last step due to the internal structure each group will have a number of parameters times bigger than the number of units this is not related to the image its fixed flow takes an input with n steps and features layer for each time step in the inputs uses units on the inputs to get a size result uses recurrent units on the outputs of the previous step outputs the last returnsequencesfalse or all returnsequences true steps output features layer same as layer layer for each time step in the inputs uses unit on the inputs to get a size result uses unit on the outputs of the previous step outputs the last returnsequencesfalse or all returnsequences true steps
51560081,what is the difference between these two methods of batching with stateful lstm,neuralnetwork lstm recurrentneuralnetwork,for anyone interested they are the same the state is carried over between batches so submitting batches of to make is the same as submitting one batch of
51376770,rnn what is the use of returnsequences in lstm layer in keras framework,machinelearning keras lstm recurrentneuralnetwork,when the returnsequences argument is set to false default the network will only output hn ie the hidden state at the final time step otherwise the network will output the full sequence of hidden states h h hn the internal equations of the layer are unchanged refer to the documentation
51344839,what is the difference between the terms accuracy and validation accuracy,python keras lstm,when training a machine learning model one of the main things that you want to avoid would be overfitting this is when your model fits the training data well but it isnt able to generalize and make accurate predictions for data it hasnt seen before to find out if their model is overfitting data scientists use a technique called crossvalidation where they split their data into two parts the training set and the validation set the training set is used to train the model while the validation set is only used to evaluate the models performance metrics on the training set let you see how your model is progressing in terms of its training but its metrics on the validation set that let you get a measure of the quality of your model how well its able to make new predictions based on data it hasnt seen before with this in mind loss and acc are measures of loss and accuracy on the training set while valloss and valacc are measures of loss and accuracy on the validation set at the moment your model has an accuracy of on the training set and on the validation set this means that you can expect your model to perform with accuracy on new data i notice that as your epochs goes from to your acc metric increases while your valacc metric decreases this means that your model is fitting the training set better but is losing its ability to predict on new data indicating that your model is starting to fit on noise and is beginning to overfit so that is a quick explanation on validation metrics and how to interpret them
50829250,tensorflow understanding lstm output with and without dropout wrapper,tensorflow lstm dropout,y is equivalent to ydrop when the dropout is applied to y with retention probability of p then the output is then scaled by dividing it by p if you check both the matrices y is nothing but dropping randomly half the inputs and then scaling it by quote from section of the dropout paper we described dropout as a method where we retain units with probability p at training time and scale down the weights by multiplying them by a factor of p at test time another way to achieve the same effect is to scale up the retained activations by multiplying by p at training time and not modifying the weights at test time these methods are equivalent with appropriate scaling of the learning rate and weight initializations at each layer reference dropout a simple way to prevent neural networks from overfitting
50608080,what is a cell class in keras,python tensorflow keras lstm recurrentneuralnetwork,the difference is the same for every cell layer combo cell the cell is the actual computation component they take a single input a past state and produce an output new states these actually perform the step function which contain the computation of a gru cell for example rnn layer these layers wrap the corresponding cells to apply the same cell to multiple timesteps so the cell is iterated over the input sequence and collect the outputs based on extra options such as returnsequences
50438738,byte embedding in mlstm conceptual struggle,python machinelearning deeplearning lstm pytorch,even though the same symbols are being used for input and output its perfectly acceptable to have different representations used at each end cross entropy is a function of two probability distributions in this case the two distributions are the softmax distribution given by the model and a point mass on the correct byte for question yes that is what is being done in terms of inputs and outputs although the implementation might be optimized to answer question the most common thing is to form the softmax distribution at each step then sample from it
49956945,teach lstms concept of different frequencies,python tensorflow neuralnetwork keras lstm,it forgets the first wave to learn the next one this makes me think are you training one sequence then another one then another that will fail naturally for any kind of problem with any model you must train lots of sequences in the same batch or if one sequence at a time never more than once per epoch possible tricks to help the model add the frequency as a feature for all steps in the input data if you know it as input make the model output the frequency if you know it as output and train it on frequencies you may combine a model that identifies frequences with a model that will read these frequencies for predicting the desired outputs
49892528,what is the architecture behind the keras lstm layer implementation,python keras lstm,revisited and updated in i was partially correct the architecture is neurons the represents the timestep value each neuron is being fed a length vector maybe representing a word vector representing features perhaps words that help identify a word over timesteps the represents the number of neurons it represents how many hidden states there are for this layer and also represents the output dimension since we output a hidden state at the end of each lstm neuron lastly the dimensional output vector generated from the neurons at the last timestep is then fed to a dense layer of neurons which basically means plug the length vector to both neurons with weights on the input and activation more reading with somewhat helpful answers understanding keras lstms what exactly am i configuring when i create a stateful lstm layer with n units initializing lstm hidden states with keras
49883290,what is the input to lstm exactly,machinelearning neuralnetwork deeplearning lstm recurrentneuralnetwork,rnn is usually used to recognize patterns in sequential data ie one must feed the sequences to the cells in order to capture it your first idea does not feed in the sequence so the network cant recognize any meaningful information such as for instance the next symbol is likely to be smaller than the current one except when theres a heres how input looks like in most cases where x x is the input your second and third idea differ only in the way you split the long data into subsequences and actually both options are possible depending on the nature of the data when is one big sentence youd like to capture the rules from all parts of it for that youd feed all subsequences of length into the network because any triplet can be meaningful side note theres also a variant of stateful rnn to help dealing with this but its really a technical detail when and are different sentences it doesnt make sense to learn the dependency like where one starts the sequence with the last word of the previous sentence each sentence is likely to be independent but within a sentence youd want to slide over all windows of size side note stateful rnn can be useful in this case too eg when there is a story and the meaning of the previous sentence may affect the understanding of the current one so the last two guesses are very close to be correct the picture is from this post which i highly recommend to read
49692218,about lstm understanding on keras,neuralnetwork deeplearning keras lstm,your interpretation of what the lstm should return is not right the output dimensionality doesnt need to match the input dimensionality concretely the first argument of keraslayerslstm corresponds to the dimensionality of the output space and youre setting it to in other words setting modeladdlstmk inputshape returnsequencestrue will result in a none k output shape
49573242,what is sequence length in lstm,machinelearning lstm,lstms are a subclass of recurrent neural networks recurrent neural nets are by definition applied on sequential data which without loss of generality means data samples that change over a time axis a full history of a data sample is then described by the sample values over a finite time window ie if your data live in an ndimensional space and evolve over ttime steps your input representation must be of shape numsamples t n your data does not fit the above description i assume however that this representation means you have a scalar value x which evolves over time instances such that x x etc if that is the case you need to reshape your input such that instead of a list of elements you have an array of shape then your full data can be described by a rd order tensor of shape numsamples which can be accepted by a lstm
49558057,understanding rnn input for word prediction,tensorflow lstm prediction recurrentneuralnetwork,emm i guess you are using simple predict model maybe just for demonstrate we tried to use rnn to predict model with an basic idea that each word in a sentence will be affected by the former or the latter wordsthats what we called context so we use the sequential inputs of words in a sentence to represent words appear one by one with the time passes so we need a tensor with a shape batchsize wordscounts wordsrepresent and in your situation wordscounts is ninput represents time steps and the word represent tensor wordsrepresent is shape tuple but in real practice we not just transfer each word into an tuple we may use word embedding to create a meaningful and useful tensor represent of a word so maybe i guess that you have tried a simple demo or may i making mistakes
49225326,what is actually numunit in lstm cell circuit,python tensorflow deeplearning lstm recurrentneuralnetwork,your understanding is quite correct however unfortunately there is inconsistency between the tensorflow terminology and the literature in order to understand you need to dig through the tensorflow implementation code a cell in the tensorflow universe is called an lstm layer in colahs universe ie an unrolled version that is why you always define a single cell and not a layer in your tensorflow architecture for example check the code here the definition of cell in this package differs from the definition used in the literature in the literature cell refers to an object with a single scalar output the definition in this package refers to a horizontal array of such units therefore in order to understand numunits in tensorflow its best to imagine an unrolled lstm as below in an unrolled version you have an input xt which is a tensor when you specify an input of the shape batchsizetimestepsninput to tensorflow it knows how many times to unroll it from your timesteps parameter so if you have xt as a d array in tensorflow then in the colahs unrolled version each lstm cell xt becomes a scalar value please observe the capital case x vectorarray and small case xscalar also in colahs figures if you have xt as a d array in the tensorflow then in the colahs unrolled version each lstm cell xt becomes a d arrayvector as in your case here and so on now here comes the most important question how would tensorflow know what is the outputhidden dimension ztht please note the difference between ht and zt i usually prefer to keep them separate as ht goes back to input the loop and zt is the output not shown in figure would it be same dimension as xt noit can be of any different shape you need to specify it to the tensorflow and that is numunits the output size check here in the code tensorflow uses the implementation of lstm cell as defined in colahs universe from the following paper
49093292,in tensorflow what is the difference between the returned output and h of state tuple c h in lstmcell,python tensorflow machinelearning lstm recurrentneuralnetwork,jacquess answer is correct but it doesnt mention an important point the state of lstm layer almost always equals to the output the difference becomes important when the chain of lstm cells is long and not all input sequences have equal length and hence are padded thats when you should distinguish the state and output see the runnable example in my answer on a similar question it uses basicrnncell but youll get the same result with lstmcell
49032027,understanding keras prediction output of a rnn model in r,r machinelearning keras lstm recurrentneuralnetwork,note my familiarity with syntax of r is very little so unfortunately i cant give you an answer using r instead i am using python in my answer i hope you could easily translate back my words at least to r if i am correct this should give me the normalized predicted temperature for every batch yes thats right the predictions would be normalized since you have trained it with normalized labels data scaledata center mean scale std therefore you would need to denormalize the values using the computed mean and std to find the real predictions pred modelpredicttestdata denormpred pred std mean for which time is then predicted latest observation time delay thats right concretely since in this particular dataset every ten minutes a new obeservation is recorded and you have set delay it would mean that the predicted value is the temperature hours ahead ie minutes hours from the last given observation also what is the correct way to use keraspredictgenerator and the testgen function predictgenerator takes a generator that gives as output only test samples and not the labels since we dont need labels when we are performing prediction the labels are needed when training ie fitgenerator and when evaluating the model ie evaluategenerator thats why the error mentions that you need to pass one array instead of two arrays so you need to define a generator that only gives test samples or one alternative way in python is to wrap your existing generator inside another function that gives only the input samples i dont know whether you can do this in r or not def predgeneratorgen for data labels in gen yield data discards labels preds modelpredictgeneratorpredgeneratortestgenerator numberofsteps you need to provide one other argument which is the number of steps of generator to cover all the samples in test data actually we have numsteps totalnumberofsamples batchsize for example if you have samples and each time the generator generate samples you need to use generator for steps bonus to see how good your model performs you can use evaluategenerator using the existing test generator ie testgen loss modelevaluategeneratortestgen numberofsteps the given loss is also normalized and to denormalize it to get a better sense of prediction error you just need to multiply it by std you dont need to add mean since you are using mae ie mean absolute error as the loss function denormloss loss std this would tell you how much your predictions are off on average for example if you are predicting the temperature a denormloss of means that the predictions are on average degrees off ie are either less or more than the actual value update for prediction you can define a new generator using an existing generator in r like this predgenerator functiongen function wrap it in a function to make it callable gen call the given generator and get the first element ie samples preds predictgenerator generator predgeneratortestgen pass testgen directly to predgenerator without calling it steps teststeps evaluategeneratormodel testgen teststeps
49020732,what is the difference between the trainableweights and trainablevariables in the tensorflow basic lstmcell,tensorflow lstm,from the source code of the layer class that rnncell inherits from see here the rnn classes dont seem to overwrite this definition i would assume its there for special layer types that have trainable variables that dont quite qualify as weights batch normalization would come to mind but unfortunately i cant find any mention of trainablevariables in that ones source code except for graphkeystrainablevariables which is different
48491737,understanding keras lstms role of batchsize and statefulness,python keras lstm recurrentneuralnetwork,let me explain it via an example so lets say you have the following series you have to decide how many timesteps your lstm will learn and reshape your data as so like below if you decide timesteps you have to reshape your time series as a matrix of samples in this way sample sample sample etc by doing so you will end with a matrix of shape samples x timesteps this matrix should be reshape as x x indicating keras that you have just time series if you have more time series in parallel as in your case you do the same operation on each time series so you will end with n matrices one for each time series each of shape sample x timesteps for the sake of argument lets say you time series you should concat all of three matrices into one single tensor of shape samples x timesteps x timeseries the first layer of your lstm for this example would be the as first parameter is totally up to you it means that at each point in time your time series will become different variables as output space it is easier to think each time step as a fully conected layer with inputs and outputs but with a different computation than fc layers if you are about stacking multiple lstm layers use returnsequencestrue parameter so the layer will output the whole predicted sequence rather than just the last value your target shoud be the next value in the series you want to predict putting all together let say you have the following time series time series master time series support time series support create the input and target tensor reformat the rest of time series but forget about the target since you dont want to predict those series create your model compile it and train a good batch size is batch size is the size your sample matrices are splited for faster computation just dont use statefull
47327256,understanding tensor inputs transformations for use in an lstm dynamic rnn,tensorflow lstm recurrentneuralnetwork,that is because of the shape of the output of the tfnndynamicrnn from its documentation outputs the rnn output tensor if timemajor false default this will be a tensor shaped batchsize maxtime celloutputsize if timemajor true this will be a tensor shaped maxtime batchsize celloutputsize you are in the default case so your outputs gas shape batchsize maxtime outputsize and when performing outputs you obtain a tensor with shape maxtime outputsize probably slicing with outputs should fix it
46870336,lstm text generation with keras what is diversity,python deeplearning keras lstm,those are just different values of the temperature hyperparameter this answer has a good explanation of what temperature means in this context
46509344,what is the difference between binary crossentropy and binary crossentropy with logits in keras,python machinelearning keras lstm recurrentneuralnetwork,this depends on whether or not you have a sigmoid layer just before the loss function if there is a sigmoid layer it will squeeze the class scores into probabilities in this case fromlogits should be false the loss function will transform the probabilities into logits because thats what tfnnsigmoidcrossentropywithlogits expects if the output is already a logit ie the raw score pass fromlogitstrue no transformation will be made both options are possible and the choice depends on your network architecture by the way if the term logit seems scary take a look at this question which discusses it in detail
46355651,understanding seqseq model,tensorflow keras lstm,are we passing the last hidden state only to the blue lstms as the initial hidden state or is it last hidden state and cell memory both hidden state h and cell memory c are passed to the decoder tensorflow in seqseq source code you can find the following code in basicrnnseqseq encstate rnnstaticrnnenccell encoderinputs dtypedtype return rnndecoderdecoderinputs encstate cell if you use an lstmcell the returned encstate from the encoder will be a tuple c h as you can see the tuple is passed directly to the decoder keras in keras the state defined for an lstmcell is also a tuple h c note that the order is different from tf in lstmcellcall you can find to get the states returned from an lstm layer you can specify returnstatetrue the returned value is a tuple o h c the tensor o is the output of this layer which will be equal to h unless you specify returnsequencestrue is there a way to set the initial hiddden state and cell memory in keras or tensorflow if so reference tensorflow just provide the initial state to an lstmcell when calling it for example in the official rnn tutorial theres also an initialstate argument for functions such as tfnnstaticrnn if you use the seqseq module provide the states to rnndecoder as have been shown in the code for question keras use the keyword argument initialstate in the lstm function call you can actually find this usage on the official documentation note on specifying the initial state of rnns you can specify the initial state of rnn layers symbolically by calling them with the keyword argument initialstate the value of initialstate should be a tensor or list of tensors representing the initial state of the rnn layer edit theres now an example script in keras lstmseqseqpy showing how to implement basic seqseq in keras how to make prediction after training a seqseq model is also covered in this script
45496277,having trouble understanding lstm use in tensorflow code sample,python tensorflow lstm recurrentneuralnetwork,tensorflow code has two distinct phases first you build a dependency graph which contains all of the operations that you will use note that during this phase you are not processing any data instead you are simply defining the operations you want to occur tensorflow is taking note of the dependencies between the operations for example in order to compute the accuracy youll need to first compute correctpred and to compute correctpred youll need to first compute pred and so on so all you have done in the code shown is to tell tensorflow what operations you want youve saved those in a graph data structure thats a tensorflow data structure that basically is a bucket that contains all the mathematical operations and tensors later you will run operations on the data using calls to sessrunops feeddictinputs when you call sessrun notice that you have to tell it what you want from the graph if you ask for accuracy tensorflow will try to compute accuracy it will see that accuracy depends on correctpred so it will try to compute that and so on through the dependency graph that you defined the error youre making is that you think pred in the code you listed is computing something its not the line only defined the operation and its dependencies
45435049,lstm understand timesteps samples and features and especially the use in reshape and inputshape,python keras lstm,i also had this question before on a higher level in samples time steps features samples are the number of data or say how many rows are there in your data set time step is the number of times to feed in the model or lstm features is the number of columns of each sample for me i think a better example to understand it is that in nlp suppose you have a sentence to process then here sample is which means sentence to read time step is the number of words in that sentence you feed in the sentence word by word before the model read all the words and get a whole context of that sentence features here is the dimension of each word because in word embedding like wordvec or glove each word is interpreted by a vector with multiple dimensions the inputshape parameter in keras is only timesteps numfeatures more you can refer to this and the problem of yours is that when you reshape data the multiplication of each dimension should equal to the multiplication of dimensions of original data set where does not equal to when you implement lstm you should be very clear of what are the features and what are the element you want the model to read each time step there is a very similar case here surely can help you for example if you are trying to predict the value of time t using t and t you can either choose to feed in two values as one element to predict t where timestep numfeatures or you can feed each value in time steps where timestep numfeatures thats basically how i understand this hope make it clear for you
45027944,understanding the functioning of a recurrent neural network with lstm cells,tensorflow lstm recurrentneuralnetwork,the above is a simple rnn unrolled to the neuron level with time steps as you can see that the output at time step t depends upon all time steps from the beginning the network is trained using backpropagation through time where the weights are updated by the contribution of all error gradients across time the weights are shared across time so there is nothing like simultaneous update on all time steps the knowledge of the previous states are transfered through the state variable st as it is a function of previous inputs so at any time step the prediction is made based on the current input as well as function of previous inputs captured by the state variable note a basic rnn was used instead of lstm because of simplicity
45022734,understanding a simple lstm pytorch,neuralnetwork lstm pytorch recurrentneuralnetwork,the output for the lstm is the output for all the hidden nodes on the final layer hiddensize the number of lstm blocks per layer inputsize the number of input features per timestep numlayers the number of hidden layers in total there are hiddensize numlayers lstm blocks the input dimensions are seqlen batch inputsize seqlen the number of time steps in each input stream batch the size of each batch of input sequences the hidden and cell dimensions are numlayers batch hiddensize output seqlen batch hiddensize numdirections tensor containing the output features ht from the last layer of the rnn for each t so there will be hiddensize numdirections outputs you didnt initialise the rnn to be bidirectional so numdirections is so outputsize hiddensize edit you can change the number of outputs by using a linear layer note for this answer i assumed that were only talking about nonbidirectional lstms source pytorch docs
44792470,cannot understand keras convlstmd edited,machinelearning tensorflow deeplearning keras lstm,the answer is yes after asking a phd doing ai research
44772931,understanding the dimensions of states returned by rnnbasiclstmcell,python tensorflow deeplearning lstm recurrentneuralnetwork,check this very good blog post about how lstms work lstms have one hidden state but also one memory cell state hence the size of the first dimension of your states variable the size of the following dimensions are batchsize then rnnsize
44386348,understanding lstm model using tensorflow for sentiment analysis,python machinelearning tensorflow deeplearning lstm,this is loaded question let me try to put it in simple english hiding all the complicated inner details a simple unrolled lstm model with steps is shown below each lstm cell takes an input vector and the hidden output vector of the previous lstm cell and produces an output vector and the hidden output for the next lstm cell a concise representation of the same model is shown below lstm models are sequence to sequence models ie they are used for problems when a sequence has to be labeled with an another sequence like pos tagging or ner tagging of each word in a sentence you seem to be using it for classification problem there are two possible ways to use lstm model for classification take the output of all the states o o and o in our example and apply a softmax layer with softmax layer output size being equal to number of classes in your case take the output of the last state o and apply a softmax layer to it this is what you are doing in your cod outputs return the last row in the outputs so we back propagate backpropagation through time btt on the error of the softmax output coming to the implementation using tensorflow lets see what is the input and output to the lstm model each lstm takes an input but we have such lstm cells so the input x placeholder should be of size inputsize time steps but we dont calculate error for single input and btt for it but instead we do it on a batch of input output combinations so the input of lstm will be batchsize inputsize time steps a lstm cells is defined with the size of hidden state the size of output and the hidden output vector of the lstm cell will be same as the size of the hidden states check lstm internal calcuations for why we then define an lstm model using a list of these lstm cells where the size of the list will be equal to the number of unrolling of the model so we define the number of unrolling to be done and the size of input during each unrolling i have skipped lots of things like how to handle variable length sequence sequence to sequence error calcuations how lstm calcuates output and hidden output etc coming to your implementation you are applying a relu layer before the input of each lstm cell i dont understand why you are doing that but i guess you are doing it to map your input size to that of the lstm input size coming to your questions x is the placeholder tensormatrixndarray of size none inputvecsize ie it can take variable number of rows but each row with inputvecsize columns and each element being a vector is size normally placeholders are defined with none in the rows so that we can vary the batch size of the input lets say inputvecsize you are passing a ndarray of size x tftransposex x tfreshapex hlayerweights x tfnnrelutfmatmulx hlayerweights hlayerbiases no input size are hidden size are different lstm does a set of operations on the input and previous hidden output and given an output and next hidden output both of which are of size hidden size x tfplaceholderfloat none inputvecsize it defines a tensor or ndarray or variable number of rows each rows has inputvecsize columns an and each value is a single value vector x tfreshapex reshapes the input x into a matrix of size fixed to column and any number of rows batchx batchxreshapebatchsize inputvecsize batchxreshape will fail if number of values in batchx batchsizeinputvecsize this might be the case for last batch because lentrainx might not be a multiple of batchsize resulting in the non fully filled last batch you can avoid this problem by using but i am still not sure why you are using relu in front of the input layer you are applying logistic regression at the output of the last cell which is fine you can look my toy example which is a classifier using bidirectional lstm for classifying if a sequence is increasing or decreasing or mixed toy sequenceclassifier using lstm in tensorflow
43487828,understanding inputshape parameter in lstm with keras,matrix machinelearning keras lstm dimension,so data input to lstm should have shape nbofsamples seqlen features in your case as your feature vector consist of only one integer you should resize your xtrain should have shape as this representation is not very suited for neural networks you should either change your representation to onehot encoding then your output should have shape use embedding layer and leave shape
41789133,what are cstate and mstate in tensorflow lstm,python tensorflow deeplearning lstm,i agree that the documentation is unclear looking at tfnnrnncelllstmcellcall clarifies i took the code from tensorflow the key lines are and and if you compare the code to compute c and m with the lstm equations see below you can see it corresponds to the cell state typically denoted with c and hidden state typically denoted with h respectively newstate lstmstatetuplec m indicates that the first element of the returned state tuple is c cell state aka cstate and the second element of the returned state tuple is m hidden state aka mstate
40863006,what is the parameter stateistuple in tensorflow used for,python parameters tensorflow recurrentneuralnetwork lstm,this is a change to an earlier implementation of the rnncellclass in which state was a concatenation of the hidden neurons and the cell state in i think release this was changed to a preferred version of hidden neurons cell state thus as a tuple in the future the old concatenation way will be deprecated until then default is concatenation but if you already use the tuple way then stateistuple needs to be set to true
40761185,what is the intuition of using tanh in lstm,machinelearning deeplearning lstm recurrentneuralnetwork activationfunction,sigmoid specifically is used as the gating function for the three gates in out and forget in lstm since it outputs a value between and and it can either let no flow or complete flow of information throughout the gates on the other hand to overcome the vanishing gradient problem we need a function whose second derivative can sustain for a long range before going to zero tanh is a good function with the above property a good neuron unit should be bounded easily differentiable monotonic good for convex optimization and easy to handle if you consider these qualities then i believe you can use relu in place of the tanh function since they are very good alternatives of each other but before making a choice for activation functions you must know what the advantages and disadvantages of your choice over others are i am shortly describing some of the activation functions and their advantages sigmoid mathematical expression sigmoidz expz firstorder derivative sigmoidz expz expz advantages tanh mathematical expression tanhz expz expz expz expz firstorder derivative tanhz expz expz expz expz tanhz advantages hard tanh mathematical expression hardtanhz if z firstorder derivative hardtanhz if advantages relu mathematical expression reluz maxz firstorder derivative reluz if z otherwise advantages leaky relu mathematical expression leakyz maxz k dot z where firstorder derivative reluz if z k otherwise advantages this paper explains some fun activation function you may consider to read it
40367357,what is the fastest way to prepare data for rnn with numpy,python performance numpy machinelearning lstm,heres an approach using numpy strides to vectorize the creation of outputx sample run this creates a view into the input array and as such memorywise we are being efficient in most cases this should translate to benefits on performance too with further operations involving it lets verify that its a view indeed another sureshot way to verify would be to set some values into output and check the input
39324520,understanding tensorflow lstm input shape,python tensorflow regression lstm,the documentation of tfnndynamicrnn states inputs the rnn inputs if timemajor false default this must be a tensor of shape batchsize maxtime or a nested tuple of such elements in your case this means that the input should have a shape of batchsize instead of training on all sequences at once youd use only batchsize many of them in each training iteration something like the following should work added reshape for clarity from the documentation outputs will be of shape batchsize ie one output for each timestep state will be a tuple of shapes batchsize you could predict your final value one for each sequence from that the number in the shapes of outputs and state is determined by celloutputsize resp cellstatesize when creating the lstmcell like above these are the same also see the lstmcell documentation
38812730,theano lstm what is initial hidden state,python neuralnetwork theano lstm,the state of a layer of neurons is the set of all the weights of its connections that describe it at that point in time to get good training performance its necessary that you dont start off with s for all the weights for a layer of neurons the most common solution to this problems is to initialize all the weights to small but non zero numbers this would describe the initial state of the neural network
38714959,understanding keras long short term memories lstms,python deeplearning keras lstm,as a complement to the accepted answer this answer shows keras behaviors and how to achieve each picture general keras behavior the standard keras internal processing is always a many to many as in the following picture where i used features pressure and temperature just as an example in this image i increased the number of steps to to avoid confusion with the other dimensions for this example we have n oil tanks we spent hours taking measures hourly time steps we measured two features pressure p temperature t our input array should then be something shaped as n inputs for sliding windows often lstm layers are supposed to process the entire sequences dividing windows may not be the best idea the layer has internal states about how a sequence is evolving as it steps forward windows eliminate the possibility of learning long sequences limiting all sequences to the window size in windows each window is part of a long original sequence but by keras they will be seen each as an independent sequence notice that in this case you have initially only one sequence but youre dividing it in many sequences to create windows the concept of what is a sequence is abstract the important parts are you can have batches with many individual sequences what makes the sequences be sequences is that they evolve in steps usually time steps achieving each case with single layers achieving standard many to many you can achieve many to many with a simple lstm layer using returnsequencestrue achieving many to one using the exact same layer keras will do the exact same internal preprocessing but when you use returnsequencesfalse or simply ignore this argument keras will automatically discard the steps previous to the last achieving one to many now this is not supported by keras lstm layers alone you will have to create your own strategy to multiplicate the steps there are two good approaches create a constant multistep input by repeating a tensor use a statefultrue to recurrently take the output of one step and serve it as the input of the next step needs outputfeatures inputfeatures one to many with repeat vector in order to fit to keras standard behavior we need inputs in steps so we simply repeat the inputs for the length we want understanding stateful true now comes one of the possible usages of statefultrue besides avoiding loading data that cant fit your computers memory at once stateful allows us to input parts of the sequences in stages the difference is in statefulfalse the second batch contains whole new sequences independent from the first batch in statefultrue the second batch continues the first batch extending the same sequences its like dividing the sequences in windows too with these two main differences these windows do not superpose statefultrue will see these windows connected as a single long sequence in statefultrue every new batch will be interpreted as continuing the previous batch until you call modelresetstates sequence in batch will continue sequence in batch sequence in batch will continue sequence in batch sequence n in batch will continue sequence n in batch example of inputs batch contains steps and batch contains steps to notice the alignment of tanks in batch and batch thats why we need shufflefalse unless we are using only one sequence of course you can have any number of batches indefinitely for having variable lengths in each batch use inputshapenonefeatures one to many with statefultrue for our case here we are going to use only step per batch because we want to get one output step and make it be an input please notice that the behavior in the picture is not caused by statefultrue we will force that behavior in a manual loop below in this example statefultrue is what allows us to stop the sequence manipulate what we want and continue from where we stopped honestly the repeat approach is probably a better choice for this case but since were looking into statefultrue this is a good example the best way to use this is the next many to many case layer now were going to need a manual loop for predictions many to many with statefultrue now here we get a very nice application given an input sequence try to predict its future unknown steps were using the same method as in the one to many above with the difference that we will use the sequence itself to be the target data one step ahead we know part of the sequence so we discard this part of the results layer same as above training we are going to train our model to predict the next step of the sequences predicting the first stage of our predicting involves ajusting the states thats why were going to predict the entire sequence again even if we already know this part of it now we go to the loop as in the one to many case but dont reset states here we want the model to know in which step of the sequence it is and it knows its at the first new step because of the prediction we just made above this approach was used in these answers and file predicting a multiple forward time step of a time series using lstm how to use the keras model to forecast for future dates or events achieving complex configurations in all examples above i showed the behavior of one layer you can of course stack many layers on top of each other not necessarly all following the same pattern and create your own models one interesting example that has been appearing is the autoencoder that has a many to one encoder followed by a one to many decoder encoder decoder using the repeat method autoencoder train with fitxx additional explanations if you want details about how steps are calculated in lstms or details about the statefultrue cases above you can read more in this answer doubts regarding
37901047,what is numunits in tensorflow basiclstmcell,tensorflow neuralnetwork lstm recurrentneuralnetwork,from this brilliant article numunits can be interpreted as the analogy of hidden layer from the feed forward neural network the number of nodes in hidden layer of a feed forward neural network is equivalent to numunits number of lstm units in a lstm cell at every time step of the network see the image there too
36428157,understanding tensorflow lstm models input,python machinelearning tensorflow deeplearning lstm,basically lstm takes the size of your vector for once cell then how many time series do you want to feed its up to your fed vector the number of arrays in the xsplit decides the number of time steps in your example i guess the lstmsize is since its the vector size of one word the timestepsize would be the max word count in your trainingtest sentences please see this example
17454402,what is the correct architecture for a time series predicting lstm neural network,architecture machinelearning artificialintelligence neuralnetwork lstm,after talking to some of the professors at my university i finally got this sorted out you should view a lstm block as a single neuron in your network thus this network would be regarded as a neural network with a single hidden layer with two neurons
77597452,not able to understand this rasa train command error,python chatbot rasa,if you look at the stack trace you included in your question it gives the type and reason for the exception you are facing valueerror givecategory is not in list you have a valueerror because givecategory is not in your list a valueerror occurs when an incorrect value is supplied so you can fix this by either including givecategory in your list or modifying your program accordingly
68257324,what is the dialogflowurl when connecting angular nebular and dialogflow,angular firebase chatbot dialogflowesfulfillment,the answer is that dialoflow looks for an external webhook in this example const dialogflowurl the yourcloudfunction refers to an external url perhaps something externalized with ngrok or liteserver the example works fine with an external url that is crosslisted under the dialogflow fulfillment tab
67838503,give a sorry i dont understand that result from chatbot if the chatbot doesnt understand a user message,python pythonx flask chatbot,i managed to find a solution after looking at the source code of the chatterbot library i found out that each reply that the chatterbot gives has its own confidence that is a float value between and if the confidence equals then the chatbot did not understand it so the response should be sorry i do not understand that and if the confidence equals then the chatbot should return the response so this is what i came up with and it seems to work pretty well now
65636961,cant understand why im getting the raise jsondecodeerror expecting value in python spyder ide,json python spyder chatbot,the problem was that my program was calling intentsjson as well as datapickle in a later version but of course the data pickle wasnt initialised yet in this segment of the code so i kept getting a null error
65021584,what is the meaning of the metric its when training or evaluating models in rasa,machinelearning chatbot metrics rasa,its is not a rasa or ml specific metric it is just the iterationssecond performed by the system here during the prediction phase as a general rule you may want to keep in mind that nothing really important and certainly not any metric is expected to be reported through an info message in the logs its is just such an informational indication and as already said not a metric
63434927,what is the use of resizedetect azure chatbot node js,javascript resize chatbot directlinebotframework webchat,you can see the properties that can be passed to renderwebchat here notice that there is no user bot or resize property
60990781,what is the best way to give user interface to a python chatbot,python django tensorflow userinterface chatbot,think of your current code as a python module that you can import inside another python file and call one method of it to get the inference for this you can try to put it inside a class after that you have multiple choices if you want to keep python you can use flask or django to create your web layer for it
59834328,what are the steps to set up whatsapp api,c api chatbot whatsapp facebookchatbot,to answer your question there are few things you need to understand whatsapp is hosted under facebook when you want to send outbound message to user you will be charged by a fee just like normal outbound smss workeg twilio nexmo and etc you can google the fee it is different by recipient country to send whatsapp message through selfhost api you need link your whatsapp number to business accountconsider this is the most easy task you also required register as facebook partner the docker installation is just a client use to talk with whatsapp it wont send the message what it can do is configure inbound message save static as video pdf etc after you set up your docker client you need to fill in all the info in order to connect whatsapp especially the token just fyi you wont be able to send whatsapp message like outbound sms you need retrieve the user whatsapp id store it and use it across all the services last question yes because it is docker twilio and nexmo got provide whatsapp api service which you may consider
59773157,what are the restrictions of running a completely offline chatbot,android artificialintelligence chatbot offline,running a bot offline without being dependent on any cloud based service is totally feasible the app would need to establish the following for brevity i am using online bot to refer to a bot app that is based on an online service offline bot for a bot app that is based on an offline or ondevice bot development platform requirements knowledgebase containing intents entities and contexts has to be saved within the app entities contribute though in kilobytes maybe to your app size for example if your bot is to recognize a country name you would need to store all the country names within the bots knowledgebase natural language domainspecific information like dictionaries thesaurus and additional word information these may not be passed on to your deploymentpublished app after a model is generated language model generated by the app would reside within the app package this is going to be the main role player in your app size online low bandwidth data connectivity shouldnt be much of a problem as the overhead of communicating with services like the following is not that high dialogflow luis witai ibm watson the above services enable apis directly via small json data exchanges you can check how much overhead is too much of an overhead for you by looking at their apis and returned data pros and cons online bot would enjoy remote updates to their knowledgebase your online bot data is not secure as anything your users saytype goes to thirdparty services for response generation response speed of your bot depends on the performance of the online service you use typically shouldnt be a problem on normal networks your app is useless when not connected to the internet offline or ondevice if you are designing a completely offline bot you would need to rely on frameworks or platforms that are designed to fulfill the aforementioned features oscova ondevice bot development platform that i personally have used to create an android bot for general customer queries in xamarin siml an xml based knowledgebase authoring language with machine learning features botsharp bot development platform by scisharp xatkit javabased chatbot creation platform pros and cons your offline bot app would need a new package update in app store or play store whenever you wish to add more to its knowledgebase kb maybe you could send a kb directly to the app when connected online your offline bot size is going to be a bit larger in comparison to a bot that uses online services your bot is alwayson as it doesnt require internet to perform tasks or respond to its users conversation with your bot is extremely secure as the data is not shared to thirdparty service like in the case of online bots
59390883,what is the use of autofacwebapi in azure bot framework integration with cosmos db,azure netcore botframework azurecosmosdb chatbot,i cant speak to why that specific package is mentioned in that documentation it isnt needed for the sample code if you can add cosmos to your bot without compile errors i wouldnt worry about it eventually visual studio will let you know if you need it heres the autofacwebapi documentation if you want it that being said you should not be developing or expanding v bots right now its been deprecated if your v is currently working it will continue to work however i cannot express enough that if you are putting any semisignificant amount of effort towards updatingexpandingchanging your v bot youd be better off spending that time migrating to v
57782957,what is the right approach for handling direct and contextual questions in dialogflow,dialogflowes chatbot,i dont think there is a recommended approach to this it is a matter of taste your solutions are a nice way of approaching this but i dont think you will get around the fact that you will have to make an extra intent with the same response if you want to allow a followup question to also be approachable directly due to the context if you really dont like to create two intents for the same response i think you would be able to workout this scenario by creating two intents and dropping the contextual flow just create a howmanyleavesavailableintent and a howtoapplyforleaveintent without any context and train the howtoapplyforleaveintent to trigger on phrases that would followup howmanyleavesavailableintent and direct questions for howtoapplyforleaveintent due to the missing context this might not be ideal because it can create weird mappings to intents but it would allow you to have just one intent for how to apply for leave
57554183,what is the account for pepper hostchat,dialogflowes chatbot pepper,i was in the same situation a year ago and got in touch with softbank this is a product from sbra softbank robotics america and you need to buy a licence they also wrote but it should be noted that we are actually no longer actively developing the pepper chat solution despite its overwhelming success in the market as we are planning to launch a new st party solution to replace it in the near future the new solution also integrates with dialogflow but in an abstracted templatebased way configured through the cms if you are interested in purchasing a license to the software please contact our sales team at salesussoftbankroboticscom
52893931,what is magicbooleans magicstrings in alicebot package,java chat bots chatbot aiml,magicbooleans is just a class wrapping static bools source on github as they are static it means you can access them by importing magicboolean and other classes will work with the same values if they read for example magicbooleanstracemode im not sure what the tracemode is affecting but you can search in the source code the same applies for the magicstrings just static strings that you can access using the magicstrings class thats all the magic
49891310,what is the difference between no match red and no match blue in dialogflow analytic,machinelearning artificialintelligence chatbot dialogflowes,i had some contact with the df team and the same request here is the answere of df i spoke to my engineers for the clarification the blue no match nodes are mislabeled and our engineers started working on this fix the blue group represents all the other intents that didnt have a large enough volume to show up as their own node and the red nodes would be fallback intents so the blue and red represents handlednot handled i hope this is helpful for you
45125460,what is the amazon lexs equivalent of ibm conversation services entitys synonyms,amazonwebservices chatbot amazonlex,according to your comment not exactly if the utterance is order me a french dip im looking for foodtypesandwich instead of foodtypefrench dip french dip is one of the synonym of sandwich and sandwich is the value of slot foodtype possible solution is create a slot foodtype tick on restrict to slot values and synonyms give value as sandwich add as many synonyms as you like eg frenchdip french dip sand wich sauce add the slot to your bot build your bot this will give value as sandwich hope it helps
42464288,what is the expected time of training for the following seqseq model,tensorflow deeplearning chatbot,training deep models on a cpu takes forever if you plan on actually using deep learning technology you will have to get a gpu or use a pretrained one and even then i would recommend a gpu because predicting is just that much faster
39731005,what is the frontend languageplatform of apiai and witai,python django frontend chatbot,while questions about technology are typically subjective and have no right answer a frontend esque language will do you a lot of good here something like js nodejs etc you need to be able to highlight the words on the client side and not make any request to the server yet until the user specifies what the highlighted text is ofcourse the service that powers your api to persist the selected entity information can be powered by py or any language that makes you smile all the best
39353683,understanding microsoft bot platform,facebook telegram botframework chatbot,regarding and if you want to be able to take advantage of special features or concepts for a channel facebooktelegram botframework provide a way for you to send native metadata to that channel giving you much deeper control over how your bot interacts on a channel the way you do this is to pass extra properties via the channeldata property in c some things are already supported in the framework for example rich cards will render differently depending on the channel here you will find the information including facebook and telegram also here you can find how for example you can use things like quick replies
39075492,what is the right way to savetrack state inside a facebook messenger bot,bots chatbot facebookchatbot,when your app receives a message theres no payload or metadata associated with it this is as opposed to a quickreply or postback which can have a payload the only way to associate a response with a question this is to manually track the conversation state in your app as suggested by anshumandhamoon to do this its best to maintain a state for each user as well as the next state for each state optionally store this in a database const users an object of state constants const states question question question question closing closing mapping of each to state to the message associated with each state const messages statesquestion how are you today statesquestion where are you from statesclosing thats cool its nice to meet you mapping of each state to the next state const nextstates statesquestion statesquestion statesquestion statesclosing const receivedmessage event keep track of each user by their senderid const senderid eventsenderid if userssenderidcurrentstate set the initial state userssenderidcurrentstate statesquestion else store the answer and update the state userssenderiduserssenderidcurrentstate eventmessagetext userssenderidcurrentstate nextstatesuserssenderidcurrentstate send a message to the user via the messenger api sendtextmessagesenderid messagesuserssenderidcurrentstate note if you wanted you can even make the values of nextstates into callable functions that take the answer of the current state and branch off into different conversation flows by passing the user to a different state depending on hisher response
39043643,what is the right way to keep the information between my bot and facebook consistent,chatbot facebookchatbot,just decide particular time limit like hour or hours or week or as per your choice and when you store users data from facebook by its graph api responsestore one more field for that particular time of storing it either by timestamp or date and after that whenever you get message from user just compare that messages timestamp with that field and if that difference is greater than that decided time limit then update users data you can compare users current message time as you are getting it in form of timestamp with every message hope this help you
30682097,how to understand text language in utf encoded text,nodejs utf characterencoding redis languagedetection,do a google search for language detect node this turned up and
76504084,what is the current status of web speech apis recognition on firefox gecko,firefox browser crossbrowser speechrecognition speechtotext,it seems like it was never fully implemented however as of january firefox has officially indicated they are positive about implementing the web speech api we believe this is a strong and welcome improvement to the api on multiple aspects added capabilities to the platform in terms for feature and performance eg being able to do highquality lowlatency recognition but also accessibility and privacy the github issue that triggered that change github ondevice web speech api this is positive and were actively investigating initially focusing on the recognition side of things i cannot find a timeline of when this will come to firefoxit is long overdue however a positive position usually means firefox plans to implement the api in firefox in fact the entry in mozillas standards positions has a brand new bug ticket connected to it bugzilla implement ondevice web speech recognition that bug is currently marked with p priority ranges from p to p which means this isnt a bad idea and maybe well want to implement it at some point in the future but its not nearterm roadmap material some core bugzilla developer may work on it the full list of mozillas positions on standards and proposed standards can be found here
75163498,what are the ways to implement speech recognition in electron,javascript electron speechrecognition speechtotext,i ended up doing an implementation that uses the media devices api to get the users speech through their microphone and then sends it to a python server using websockets which uses the audio stream with the speechrecognition pip package and returns the transcribed text to the client electron app this is what i implemented it is way too long for a thing as simple as this but if someone has a better suggestion please do let me know by writing an answer
69952069,what is the purpose of extracallingpackage in android studio,android androidstudio speechtotext,its a flag that is used by voice search api to identify the called to this api your application so the voice search implements the callbacks and based on your package name
61087842,what are python libraries which replace from scikitsaudiolab import format sndfile,pythonx speechtotext azurecognitiveservices scikits,firstly the link code you paste is asteriskgooglespeechrecognition its not the microsoftspeechtotext if you want get a sample about microsoftspeechtotext you could refer to the official docrecognize speech from an audio file and about your problem you said yes its not completely compatible in the github issue there is a solution for it you could refer to this comment
59387046,what is the best mobile texttospeech and speechtotext tool for both android and ios,reactnative texttospeech speechtotext,for speech to text you can refer this article as it explains precisely and also it uses reactnativevoice as its an easy library to get started with reactnativespeechtotext for texttospeech functionality as per documentation of reactnativetts looks simple you could implement that hope it helps feel free for doubts
56345685,quota exceeded for quota metric speechgoogleapiscomdefaultrequests not really understandable,nodejs googlecloudplatform speechtotext,you noted that the project number isnt the same as the one youre seeing the error result so that seems to be the bigger problem here the google cloud client libraries get the project information and credentials from a few different places with different priorities for each so its possible that youre accidentally picking up credentials and identity from the application defaults possible the gcloud commandline tool can you update the question with the code youre running to get this error there are a few ways to fix an issue like this but the easiest is probably to just run gcloud auth applicationdefault login in the command line documentation once you follow the authentication flow you should end up with credentials for the intended project you also might want to take a look at the getting started with authentication guide for gcp in nodejs which talks about creating a service account and setting those credentials using an environment variable
56266810,microsoft speech recognition phraselist undefinedwhat is the issue,javascript speechrecognition speechtotext azurecognitiveservices,needed to update my sdk version
55284586,ctc what is the difference between space and blank,speechrecognition speechtotext speech labeling ctc,in connectionist temporal classification space is just a whitespace and blank is which we use to solve the repeated reoccurrence of the data for example pizza will be encoded as pizza tldr ref in ctc there is an issue of how to encode duplicate characters it is solved by introducing a pseudocharacter called blank but dont confuse it with a real blank ie a whitespace character this special character will be denoted as in the text we use a clever coding schema to solve the duplicatecharacter problem when encoding a text we can insert arbitrary many blanks at any position which will be removed when decoding it however we must insert a blank between duplicate characters like in hello further we can repeat each character as often as we like lets look at some examples to ttttttooo or to or to too tttttoo or too or too but not too as you see this schema also allows us to easily create different alignments of the same text eg to and too and to all represent the same text to but with different alignments to the image the nn is trained to output an encoded text encoded in the nn output matrix
44048081,how to change endpoint for android speech language understanding luis sdk,android speechrecognition speechtotext azurecognitiveservices,assuming you are referring to the luisclient constructor has an overload that accepts a base uri see specifically update for android speech sdk rather than luis sdk the android speech sdk has a similar method for specifying the url see the createdataclientwithintent overload that takes the optional url parameter at createdataclientwithintentandroidappactivityactivity javalangstringlanguage ispeechrecognitionservereventseventhandlers javalangstringprimarykey javalangstringsecondarykey javalangstringluisappid javalangstringluissubscriptionid javalangstringurl
41238828,what is the difference between chrome speech api and google speech api,googlechrome speechtotext speech googlespeechapi,the web speech api is a wc supported specification that allows browser vendors to supply a speech recognition engine of their choosing be it local or cloudbased that backs an api you can use directly from the browser without having to worry about api limits and the like the google speech api is a cloudbased solution that allows you to use googles speech software outside of a browser it also provides broader language support and can transcribe longer audio files it requires billing information for testing purposes and charges after days of trial
31933159,what is the best solutions for speech to text,speechtotext,there are many solution to this if you search in google php speech to text this is a php script that uses google speech to text api you could definitely impliment this in your project hope this helps
25307487,how to use libcurl with google speech api what is the equivalent for databinary or uploadfile,c curl libcurl speechtotext,you need to use callback to upload the data file you can find example here databinary is irrelevant in this example because you dont do anything with the file passing the data in callback so it will be posted as is
24436855,what is this error ioerror errno no such file or directory audioflac i am trying to use the google voice recognition api for python,python bit voicerecognition speechtotext ioerror,you miss the sox tool installed which converts recorded wav to flac you can see in line in pygsr sources systemsox s t wav r t flac sflac selffile selffile make sure that sox works for you and it can create flac files
24283687,what is the best way to use openears in ios app with multiple language support,ios objectivec speechrecognition speechtotext openears,openears developer here openears supports two languages and it doesnt perform large vocabulary recognition this is described in its docs so check them out for the answers to these questions and more
78625475,understanding usage of hifigan by vits,machinelearning pytorch artificialintelligence texttospeech,in vits the input to the hifigan module is not a traditional melspectrogram but rather latent variables produced by the encoder which is conditioned by the text and an alignment model in this way one can say that vits is an endtoend model the hifigan in vits acts as a decoder that takes these latent variables and generates the final audio waveform directly therefore what you are trying to plot is not a melspectrogram but rather these latent variations this approach allows vits to maintain flexibility and highquality synthesis without relying on traditional interactive representations such as melspectrograms
69744562,i dont understand why i cant install this pip package,linux ubuntu texttospeech coqui,thanks guys and apologies for the rookie error but i just needed to update pip
65132641,what is wrong with my if statement in line and my addition to variable statement in line,python ifstatement variables raspberrypi texttospeech,look at these two snippets when the first condition is true it adds to repetitionsocial so now that variable contains therefore the second condition will also be true because you should use elif when you have mutually exclusive conditions and dont want to consider the variable changes that occurred as a result of the first condition
56645133,what is the correct way to display a voice object to the user in an android app using tts engine comgoogleandroidtts,android texttospeech googletexttospeech,there doesnt seem to be such a function pretty silly personally i would just let the deviceengine choose the best voice and only let the user specify the language the google engine is going to automatically select the most high quality and various other factors but if you really want to allow the user to choose a specific voice from a list you could at least do something like french french instead of voice voice and it wouldnt require hard coding names unchecked code just to illustrate the idea then when you show these voices to the user just iterate and label them if the available voices change though then french could suddenly become a different voice
55291408,what is the difference between speechsynthesis and chrometts,javascript googlechrome googlechromeextension texttospeech,chromes tts is propriety to chrome and is prestandard whereas the speechsynthesis api is in the process of being standardised ie nonproprietary and is available in other nonchrome based browsers
54554350,what is the difference between systemspeechsynthesis and microsoftspeechsynthesis,c texttospeech speechsynthesis microsoftspeechapi microsoftspeechplatform,the difference really is pretty much as outlined in the linked answer systemspeechspeechsynthesis uses the desktop tts engines while microsoftspeechspeechsynthesis uses the server tts engines the differences are relatively minor from the programming perspective but considerably different from the licensing perspective the server tts engines are separately licensed however both systemspeechspeechsynthesis and microsoftspeechspeechsynthesis are deprecated apis and new development should be based on the windowsmediaspeechsynthesis api
42294437,create patterns in phraselist that cortana can understand,uwp windows texttospeech voicerecognition cortana,i have found an answer for this case it was quite simple i only had to add two subjects to my phrasetopic one small problem is that cortana adds some whitespaces inside the spelled vin this can be removed with simple string operations hope i can help somebody who has the same problem
32478182,what is the azure offer id,texttospeech azurecognitiveservices,the docs appear to be incorrect the xsearchpartnereventid header is not required and is replaced by an authorization header for a working example in rebol see
27488253,what is the purpose of speaker adaptive training and speaker dependent training,texttospeech voice hiddenmarkovmodels speechsynthesis htk,festival is a good concatenative speech synthesis tool which also uses hmm hts is another good hmm based synthesizer lab or phn files are label files where each word is split into phonemes with corresponding time stamps from the audio eg for an audio file containing word this label file can be where the numbers are starting and ending time in seconds for pronunciation of phoneme utt are utterance files which are formed after all information like stress part of speech intonation duration of speech etc are taken into account these files can then be used for speech output playing the utterance the quality of speech synthesized depends upon the audio set used for training speaker adaptive training adapts the model to accomodate speakers with different voices and accentsdialects separate models are trained in case of speaker dependent training for different voices you can go through the festival manual to know how to set up a speech synthesis pipeline festival along with hts is also used where festival is used for frontend textanalysis creating dictionary word to phoneme etc whereas hts is used for hmm based speech modelling
24664036,track what is being spoken in ios tts,ios objectivec ios texttospeech avspeechsynthesizer,you can use avspeechsynthesizerdelegate and its speechsynthesizerdidstartspeechutterance method lets assume that you store avspeechutterance objects in a nsarraynamed utterances
23645404,simple android text to speech proof of concept not working,android audio texttospeech,i have had bad luck using ttssetlanguagelocaleus heres the code i use instead when this code runs on my samsung s phone it uses the default locale instead of localeuk or localeus try removing the ttssetlanguagelocaleus and the tests for result another possibility is that ttsspeak must be called from the ui thread im just guessing that i dont know for sure ive noticed many android apis dont specify what calls must be made from the ui thread you might try the following code instead of the call to speakout
15692209,understanding windows speech api,c windows texttospeech sapi,there was two problems sapi doesnt accepts ssml its support ssml tags i cannot send a full ssml using spfparsessml doesnt means that the speak action will be done
9050271,what is right way for timing phoneme in sapi tts c spvoicephonemestreamposition,c timing sapi texttospeech,ok i will answer myself my bachelors profesor sended me some code in c what he wrote i readed it last days and now i see how stupid i am so i will answer attribute streamposition is really bites position in the output stream probably wav if you want to know millisecond position in the output stream you need write something like intstreampositiondoublewavfileformatsamplespersecdoublewavfileformatbitspersample so you need find information about the outputstream like bitspersample samplespersec and you will get the milliseconds timing
8374729,what is an earcon,android texttospeech,earcon an earcon is a brief distinctive sound used to represent a specific event or convey other information earcons are a common feature of computer operating systems and applications ranging from beeping when an error occurs to the customizable sound schemes of windows that indicate startup shutdown and many other events the name is a pun on the more familiar term icon in computer interfaces icon sounds like eyecon and are visual which inspired da sumikawa to coin earcon as the auditory equivalent in a article guidelines for the integration of audio cues into computer user interfaces heres the article theyre talking about earcon android api adds a mapping between a string of text and a sound file use this to add custom earcons and heres the api reference for that method
7234013,what is the proper syntax for the phoneme attribute in androids tts xml,android texttospeech ssml,the correct syntax for what you are trying to do is exactly as you posted in your question if your phone is setup to use the default pico tts that is under settings voice input output texttospeech settings default engine make sure that pico tts is selected and try the same code now
6877272,what is the default audio stream of tts,android texttospeech androidaudiomanager,streammusic is the default in the aosp source defined in texttospeechjava line as of this writing in frameworksbasegit
4936209,what is the work flow between voicexml and speech synthesis,texttospeech voicexml,the voicexml document as a whole is not parsed by the tts engine instead the voicexml browser is responsible for extracting the prompt including any speech synthesis markup language ssml markup included in the voicexml document and passing just that text to the tts engine via mrcp you can find more info on ssml from the wc specification ssml specification
4798189,what is wrong with my texttospeech in my countdowntimer,android texttospeech,your second argument in tts new texttospeechthis this does not implement texttospeechoninitlistener you need to have countdown or another class implement texttospeechoninitlistener then implement oninit in said class and finally pass the class that implements oninitlistener into the texttospeech constructor check out the texttospeechactivityjava tutorial for a full working example edit as nickt mentioned you also need to add curly braces to your if statement in ontick else youll execute setlanguage and speak always which will give you a nullpointerexception unless millisuntilfinished is true
552398,what are some good resources on doing texttospeech in net,c net texttospeech,microsoft speech sdk just for simple ts it should be very simple like
77150535,what are the word types in gensim,python gensim,yes this is reporting progress during the initial st vocabularysurvey and thats the loggings odd terminology for unique wordtokens discovered during the scan this will be a precise count of the unique tokens encountered unless youre using the maxvocabsize parameter which can trigger some midscan purging of rarer tokens i strongly recommend against using maxvocabsize setting unless theres no way to proceed without it because of the nonintuitive effects it has on the surveys running count final vocabulary size at the end of the scan there will also be a report of the final unique count then the unique count after your mincount is applied if you want to place a hard cap on the known vocabulary for example to cap the size of your model during training the maxfinalvocab parameter can be used it only trims to the exact mostfrequentn words at the end of the full scan rather than applyinginterim larger midscan cullings that can be triggered by maxvocabsize
73254708,what is the purpose of tags in docvec taggeddocument,gensim docvec,the tag is just the key with which to lookup the learned document vector after training is done the original paragraph vectors research papers on which gensims docvec is based tended to just assume each document had one unique id perhaps a string token just like any other word so too did a small patch to the original google wordvecc that was once shared long ago as a limited example of one mode of paragraph vectors in those original formulations documents had just one unique id lookup key for their vector however it was a fairly obviousstraightforward extension to allow these associated vectors to potentially map to other known shared labels across many documents that is not a unique vector per document but a unique vector per label which might appear on multiple texts and further that multiple such rangeoftext vectors might be relevant to a single text thats known to deserve morethanone label so the word tag was used in the gensim implementation to convery that this is an association more general than either a uniqueid or a knownlabel though it might in some cases be either if youre just starting out or trying to match early papers just consider the tag a single unique id per document give every independent document its own unique name whether its something natural from your data source like a unique article title or primary key or a mere serial number from to the count of docs in your data only if youre trying expertexperimental other approaches after understanding the basic approach would you want to either repeat a tag across multiple documents or use mroe than one tag per document neither to those approaches are necessary or typical in the initial application of docvec and if you start to reuse known tags in training docvec is no longer a strictly unsupervised machinelearning technique but starts to behave more like a supervised or semisupervised technique where youre nudging the algorithm towards desired answers thats sometimes useful and appropriate but starts to complicate estimates of how well your steps are working you then have to use things like heldback testvalidation data to get trustworthy estimates of your systems success
72221035,what is the data type of x in pcafittransformx,scikitlearn pca gensim wordvec,per scikitlearn docs the argument to fittransform as is usual for scikitlearn models is arraylike of shape nsamples nfeatures here thatd mean your samplesrows are words and featurescolumns the wordvector dimensions and youll want to remember outside of the pca object which words correspond to which rows in python x the fact your d dict will always iterate in the order of insertion should have you covered there so it may be enough to change your use of items to values so that you wind up supplying pca with your list which is suitably arraylike of vectors a few other notes the keytoindex property is already a list so you dont need to convertcopy it if your positiveterms is a large list changing it to a set could offer faster in membershiptesting rather than using a d dict which involves a little more overhead including when you then make a list of its values if your setsofwords and vectors are large you might want to preallocate a numpy array of the right size and collect your vectors in it for example x npemptylenvocab abusemodelwvvectorsize for i word in enumeratevocab xi abusemodelwvword result pcafittransformx even though your hunch is you only want the dimensionalityreduction on your subset of words you may also want to try keeping all words or some random subset of other words it might help retain some of the original structure that otherwise your subsampling will have prematurely removed unsure of this just noting it could be a factor even if you do the pca on a larger set of words you could still choose to only later plotanalyze your desired subset for clarity
71240225,what is right way to sum up wordvec vectors generated by gensim,python gensim wordvec,you can add the vectors with simple python math operators numpy actually doesnt have a cosinesimilarity or cosinedistance function so youd have to use the formula for calculating from the dotproduct unitnorm both of which numpy has or you could leverage the cosinedistance function in scipy and convert it to cosinesimilarity by subtracting it from
67116370,understanding gensim docvec ranking,gensim docvec,the problem is the same as in my prior anwer to a similar question docvec needs far more data to start working texts with maybe total words and perhaps around half that unique words is far too small to show any interesting results with this algorithm a few of gensims docvecspecific test cases tutorials manage to squeeze some vaguely understandable similarities out of a test dataset from a file leebackgroundcor that has documents each of a few hundred words so tens of thousands of words several thousand of which are unique but it still needs to reduce the dimensionality up the epochs and the results are still very weak if you want to see meaningful results from docvec you should be aiming for tensofthousands of documents ideally with each document having dozens or hundreds or words everything short of that is going to be disappointing and notrepresentative of what sort of tasks the algorithm was designed to work with theres a tutorial using a larger moviereview dataset k documents that was also used in the original paragraph vector paper at theres a tutorial based on wikipedia millions of documents that might need some fixup to work nowadays at
63916338,what is the best way to drop old words from gensim wordvec model,python gensim wordvec,theres no official support for removing words from a gensim wordvec model once theyve ever made the cut for inclusion even the ability to add words isnt on a great footing as the feature isnt based on any provenpublished method of updating a wordvec model and glosses over difficult tradeoffs in how updatebatches affect the model via choice of learningrate or whether the batches fully represent the existing vocabulary the safest course is to regularly retrain the model from scratch with a full corpus with sufficient examples of all relevant words so my main suggestion would be to regularly replace your model with a new one trained with all stillrelevant data that would ensure its no longer wasting model state on obsolete terms and that all stilllive terms have received coequal interleaved training after such a reset wordvectors wont be comparable to wordvectors from a prior model era the same word even if its tangible meaning hasnt changed could be an arbitrarily different place but the relative relationships with other vectors should remain as good or better but that same sort of driftoutofcomparison is also happening with any set of smallbatch updates that dont touch every existing word equally just at some unquantifiable rate otoh if you think you need to stay with such incremental updates even knowing the caveats its plausible that you could patchup the model structures to retain as much as is sensible from the old model continue training your code so far is a reasonable start missing a few important considerations for proper functionality because deleting earlierwords changes the index location of laterwords youd need to update the vocabwordindex values for every surviving word to match the new indexword ordering for example after doing all deletions you might do because in your default negativesampling wordvec model there is also another array of perword weights related to the models output layer that should also be updated in sync so that the right outputvalues are being checked per word roughly wheneever you delete a row from mwvvectors you should delete the same row from mtraininablessynneg because the surviving vocabulary has different relative wordfrequencies both the negativesampling and downsampling controlled by the sample parameter functions should work off different precalculated structures to assist their choices for the cumulativedistribution table used by negativesampling this is pretty easy for the downsampling youd want to update the sampleint values similar to the logic you can view around the code at but looking at that code now i think it may be buggy in that its updating all words with just the frequency info in the new dict so probably fouling the usual downsampling of trulyfrequent words and possibly erroneously downsampling words that are only frequent in the new update if those internal structures are updated properly in sync with your existing actions the model is probably in a consistent state for further training but note these structures change a lot in the forthcoming gensim release so any custom tampering will need to be updated when upgrading then one other efficiency note the npdelete operation will create a new array the full size of the surviving array and copy the old values over each time it is called so using it to remove many rows one at a time from a verylarge original array is likely to require a lot of redundant allocationcopyinggarbagecollection you may be able to call it once at the end with a list of all indexes to remove but really the simpler bettergrounded approach which may also yield significantly better continuallycomparable vectors would be to retrain with all current data whenever possible or a large amount of change has occurred
62565772,grouping words with same meaning in lda,python gensim lda,the key thing to understand is lda requires a great deal of tuning and iteration to work properly unlike say linear regression but it can be useful for a certain set of problems your intuition is right in that tourism touristic and turism should all be one word the fix however is not at the end where you are presented with their respective loadings but rather early on with stemming and lemmatization aka stemming and lemming adding unwanted words to your stopwords list and some preprocessing to some degree or another ill address them separately but not as a group as i think thats fairly obvious also because you only gave the one set of words and loadings its not really fruitful to go into providing the number of topics as you may be doing that just fine stemminglemming pick one this is where the science and experience part starts as well as the frustration but this is where youll make the biggest and easiest gains it seems like tourism and touristic might be best combined by stemming as tour the truth is a lot less clear cut as there are cases where one beats the other in the below example portastemer suffers from making sensible stems but lemmatizing fails to catch how studies and studying are the same though it accurately catches cry there are multiple stemmers such as porter snowball hunspell and paicehusk so the obvious first step would be to see if any of these is more useful out of the box as mentioned above lemmatization will get you a similar but somewhat different set of results there is no substitute for the work here this is what separates a data scientist from a hobbiest or data analyst with plussed up title the best time to do this was in the past so you would have an intuition of what works best for this sort of corpus the secondbest time is now iterate but satisfice i presume you dont have infinite resources you have to satisfice for the above you might consider preprocessing your text to correct or remove misspelled words what to do with nonenglish words is trickier the easiest solution is to remove them or add them to your stopwords list but that may not be the best solution customizing your dictionary is an option too know the current limits as of no one is doing a good job with codeswitching certainly not a free and opensource resource gridspace is about the best i know of and while their demo is pretty amazing they cant handle codeswitching well now im doing some induction here because im assuming piare is spanish for i will at least that what google translate says if thats the case your results will be confounded but when you look at the loading that seems to be more work than would be worth it
59631259,understanding of the parameter modelinfervector for docvec gensim,python gensim docvec,the docwords should be a list of individual wordtokens as strings equivalent to the words of each training document during training that is it should have been preprocessed and tokenized the same as your training data was when you ask in your question tokenized words of a document as list of strings or simply a document as a list of string as far as i understand those words those two alternatives are the same thing a python list where each item is a string word other important things to note about infervector inference always starts with a lowmagnitude random vector then iteratively improves that vector words not known to the model will be silently ignored at the extreme if you supply a text with all unknown words no inference will happen but because of the random initialization above youll still get a vector back if you dont specify an epochs value it will reuse the value cached in the model left over from model initialization or your last train call you will generally want it to use a number of epochs at least as large as was used in training which is most commonly but sometimes larger and larger values may be especially helpful with shorter texts
58069421,gensim wordvec extremely big and what are the methods to make file size smaller,python gensim wordvec,the most obvious way would be to train using a smaller vocabulary which is what this repo does the final slim model has words saved in a mb compressed wordvec format file and loads in seconds on my laptop alternatively you should consider using fasttext fasttext supports model quantization which can significantly shrink the final model size the example they give in their blog post on quantization demonstrates compressing a mb model to less than mb
55872853,gensim mostsimilar with fasttext word vectors return uselessmeaningless words,gensim fasttext,perhaps the bigger question is why does the facebook fasttext ccitvec model include so many meaningless words i havent noticed that before is there any chance youve downloaded a peculiar model that has decorated words with extra analytical markup to gain the unique benefits of fasttext including the ability to synthesize plausible betterthannothing vectors for outofvocabulary words you may not want to use the general loadwordvecformat on the plaintext vec file but rather a facebookfasttext specific load method on the bin file see im not sure that will help with these results but if choosing to use fasttext you may be interesting it using it fully finally given the source of this training commoncrawl text from the open web which may contain lots of typosjunk these might be legimate wordlike tokens essentially typos of sole that appear often enough in the training data to get wordvectors and because they really are typosynonyms for sole theyre not necessarily bad results for all purposes just for your desired purpose of only seeing realish words you might find it helpful to try using the restrictvocab argument of mostsimilar to only receive results from the leading mostfrequent part of all known wordvectors for example to only get results from among the top words picking the right value for restrictvocab might help in practice to leave out longtail junk words while still providing the realcommon similar words you seek
55103288,what is correct way to get doc vectors values,python gensim docvec,you can use either but should use the same sort of tag keys as were provided during training so if your taggeddocuments during training had a string tag of mydoctag you should use modeldocvecsmydoctag if you explicitly provided plain int tags you could use modeldocvecs but note in such a case you should be careful to assign contiguous ints starting from
54623849,what is the similarity score in the gensim similarbyword function,gensim,the similarity measure used here is the cosine similarity which takes values between and the cosine similarity measures the cosine of the angle between two vectors if the angle is very small the vectors are considered similar since they are pointing in the same direction this way of measuring similarity is common when working with high dimensional vector spaces such as word embeddings the formula for the cosine similarity of two vectors a and b is as follows
54492390,what are the defaults for gensims fasttext,gensim fasttext,the very link in your question shows all the defaults right there to excerpt it here those that are for the corresponding parameter to the facebook native fasttext probably should have the same defaults but its possible that some have varied slightly to match analogous parameters in other gensim classses so if you were counting on identical defaults for some analysis you should check these values against the facebook docs
53037373,misunderstanding the use of filterextreme in gensim,python python gensim,looking at the documentation of filterextremes you are only passing nobelow this means that tokens appearing in less than document out of are removed this means a stays as well as any other token in your corpus but then noabove is checked according to its default value since you didnt pass an explicit value for this keyword this means that tokens appearing in more than of documents out of ie the ones appearing in at least will be removed and a appears in all documents its the only one that appears in at least documents as a matter of fact this is why this token and this token alone is removed from the result the default value for keepn implies that step is a noop in your example case if you only want to strip lowfrequency extremal tokens pass an explicit noabove to filterextremes
50805556,understanding parameters in gensim lda model,python parameters gensim lda,i wonder if you have seen this page either way let me explain a few things for you the number of documents you use is small for the method it works much better when trained on a data source of the size of wikipedia therefore the results will be rather crude and you have to be aware of that this is why you should not aim for a large number of topics you chose which could maybe go sensibly up to in your case as for the other parameters randomstate this serves as a seed in case you wanted to repeat exactly the training process chunksize number of documents to consider at once affects the memory consumption updateevery update the model every updateevery chunksize chunks essentially this is for memory consumption optimization passes how many times the algorithm is supposed to pass over the whole corpus alpha to cite the documentation can be set to an explicit array prior of your choice it also support special values of asymmetric and auto the former uses a fixed normalized asymmetric topicno prior the latter learns an asymmetric prior directly from your data perwordtopics setting this to true allows for extraction of the most likely topics given a word the training process is set in such a way that every word will be assigned to a topic otherwise words that are not indicative are going to be omitted phivalue is another parameter that steers this process it is a threshold for a word treated as indicative or not optimal training process parameters are described particularly well in m hoffman et al online learning for latent dirichlet allocation for memory optimization of the training process or the model see this blog post
46807010,what are docvec training iterations,python deeplearning wordvec gensim docvec,wordvec and related algorithms like paragraph vectors aka docvec usually make multiple training passes over the text corpus gensims wordvecdocvec allows the number of passes to be specified by the iter parameter if youre also supplying the corpus in the object initialization to trigger immediate training your code above does this by supplying docs to the docvecdocs constructor call if unspecified the default iter value used by gensim is to match the default used by googles original wordvecc release so your code above is already using training passes published docvec work often uses passes if you wanted to do passes instead you could change your docvec initialization to because docvec often uses unique identifier tags for each document more iterations can be more important so that every docvector comes up for training multiple times over the course of the training as the model gradually improves on the other hand because the words in a wordvec corpus might appear anywhere throughout the corpus each words associated vectors will get multiple adjustments early and middle and late in the process as the model improves even with just a single pass so with a giant varied wordvec corpus its thinkable to use fewer than the defaultnumber of passes you dont need to do your own loop and most users shouldnt if you do manage the separate buildvocab and train steps yourself instead of the easier step of supplying the docs corpus in the initializer call to trigger immediate training then you must supply an epochs argument to train and it will perform that number of passes so you still only need one call to train
45444964,python what is the size parameter in gensim wordvec model class,python gensim wordvec,size is as you note the dimensionality of the vector wordvec needs large varied text examples to create its dense embedding vectors per word its the competition between many contrasting examples during training which allows the wordvectors to move to positions that have interesting distances and spatialrelationships with each other if you only have a vocabulary of words wordvec is unlikely an appropriate technology and if trying to apply it youd want to use a vector size much lower than your vocabulary size ideally much lower for example texts containing many examples of each of tensofthousands of words might justify dimensional wordvectors using a higher dimensionality than vocabulary size would moreorless guarantee overfitting the training could tend toward an idiosyncratic vector for each word essentially like a onehot encoding that would perform better than any other encoding because theres no crossword interference forced by representing a larger number of words in a smaller number of dimensions thatd mean a model that does about as well as possible on the wordvec internal nearbyword prediction task but then awful on other downstream tasks because theres been no generalizable relativerelations knowledge captured the crossword interference is what the algorithm needs over many training cycles to incrementally settle into an arrangement where similar words must be similar in learned weights and contrasting words different
44011706,what is different between docvec models when the dbowwords is set to or,gensim docvec,the dbowwords parameter only has effect when training a dbow model that is with the nondefault dm parameter so between your two example lines of code which both leave the default dm value unchanged theres no difference if you instead switch to dbow training dm then with a default dbowwords setting the model is pure pvdbow as described in the original paragraph vectors paper docvectors are trained to be predictive of text example words but no wordvectors are trained therell still be some randomlyinitialized wordvectors in the model but theyre not used or improved during training this mode is fast and still works pretty well if you add the dbowwords setting then skipgram wordvector training will be added to the training in an interleaved fashion for each text example both docvectors over the whole text then wordvectors over each sliding context window will be trained since this adds more training examples as a function of the window parameter it will be significantly slower for example with window adding wordtraining will make training about x slower this has the benefit of placing both the dbow docvectors and the wordvectors into the same space perhaps making the docvectors more interpretable by their closeness to words this mixed training might serve as a sort of corpusexpansion turning each contextwindow into a minidocument that helps improve the expressiveness of the resulting docvector embeddings though especially with sufficiently large and diverse document sets it may be worth comparing against puredbow with more passes
42382207,what is the parameter in gensim wordvec,python null deeplearning gensim wordvec,the nullword is only used if using the pvdm with concatenation mode parameters dm dmconcat in model initialization in this nondefault mode the doctagvector and the vectors of the neighboring words within window positions of a target word are concatenated into a verywide input layer rather than the more typical averaging such models are much larger and slower than other modes in the case of target words near the beginning or end of a text example there might not be enough neighboring words to create this input layer but the model requires values for those slots so the nullword is essentially used as padding while the original paragraph vectors paper mentioned using this mode in some of their experiments this mode is not sufficient to reproduce their results no one that i know of has been able to reproduce those results and other comments from one of the authors imply that the original paper has some error or omission in its process additionally i havent found cases where this mode offers a clear benefit to justify the added timememory it might require verylarge datasets or verylong training times to show any benefit so you shouldnt be too concerned about this model property unless youre doing advanced experiments with this lesscommon mode in which case you can review the source for all the fine details about how its used as padding
36160322,what is tmptext gensim,python gensim,like he says in his description you need to download and unzip the file to tmp directory you can do this like this now you should be ok
29837563,what is the difference between modelsldamodelldamodel and modelsldamodel,python lda gensim,theyre the same if you look at the source the initpy in the models package has the line which basically just makes it so that gensimmodelsldamodelldamodel is the same thing as gensimmodelsldamodel just to save some typing as helpfully pointed out by the comment
20349958,understanding lda implementation using gensim,python gensim lda topicmodeling dirichlet,the answer youre looking for is in the gensim tutorial ldaprinttopicsk prints the most contributing words for k randomly selected topics one can assume that this is partially the distribution of words over each of the given topics meaning the probability of those words appearing in the topic to the left usually one would run lda on a large corpus running lda on a ridiculously small sample wont give the best results
79482841,what is wandb in google colab and why do we use it,deeplearning googlecolaboratory wandb,short answer if you dont need it just hit option longer answer wandb weights and biases is a really cool tool for live visuals of data essentially you can log data as something like a training loop runs and each iteration of the loop ie each time the log function is called it will update a plot in real time the plots are accessible via a web ui which the api key its asking for in the be associated with your accountproject in the initialization phase of the yolo model youre running there will be something that looks like this to initialize weights and biases when this is called itll either search for an environment variable wandbapikey or prompt you with the message you see to enter it in the training loop you will see a call to wandlog with a dictionary in it such as wandblogplot data where plot is the key of the dictionary which will be the name of the plot if you log into weights and biases and data is whatever data is being logged on the y axis here is an example from a gan project i have if you dont need visualization dont worry about it just hit option to skip all use of wandb if you need any visuals i highly recommend it as you can also sort and group different training runs together in the same plots if you want to try using it just create an account make a new project and then it should generate an api key for you you should only need to paste it in the terminal when prompted once or alternatively set an environment variable
78841275,what are tokens top k and top p,machinelearning deeplearning artificialintelligence googlegemini,you can find those details at the model parameters documentation but in a short max output tokens limits the response max length you literally limit how short or long you want your answer in tokens roughly speaking just as a reference tokens is around words gemini is a generative model which means that in a high level explanation it composes or generates an answer given its semantic knowledge in a given language being a spoken language a programming language etc so basically you can imagine a bag of possible next tokens when writing a sentence and topk and topp will customize the possible vocabulary to be considered with topk basically you limit the possible tokens universe if the next tokens can be possible different ones you limit in the top first k ones so topk means that the model you consider the first tokens in the possible list but the next tokens is not picked yet at this step with topp you will work on a limit based on the cumulative probability meaning each token will have a probability related to how often the model saw the previous token followed by this token so if you define topp each means that from the token you limited with topk it will generate a new list with the tokens that sum a max probability of ie if the first token has a probability the second has the third has and the fifth has the list after the topp analysis will contain the first the second and the third yet the next token is not picked in the step too finally comes the temperature parameter which defines how deterministic the next token will be picked a temperature equals to drives the more deterministic choice where the token with higher priority will be chosen temperature at maximum will be the more random choice of next token which means that even the less probable token may be chosen too hope that helps
78654902,what is the alternative for keraslayersdensefeatures in tensorflow,pythonx tensorflow deeplearning datapreprocessing,i assume you were doing this lab from google cloud i have finished the training and predict parts with tensorflow as well first of all according to this migration guide densefeatures is deprecated in favour of preprocessing layer when we transit from tensorflow to tensorflow during the lab i also received the warning which looked similar to it clearly said that we should either use preprocessing layer or featurespace utility i tried both and can give you the solutions as following use preprocessing layer in this lab i find it reasonable to use normalization because the inputs seem to accept floating point values first define the constants for batch size number of epochs number of examples and prepare your dataset i do this step before creating the model which is different from what the lab was designed without changing the result the reason is the normalizer needs the dataset as argument in the next step then define a normalizer as a method then build your model with functional api as follows compile your model finally do the training part as required in the lab use featurespace utility with this approach we initialize the featurespace which then do the normalization for us in the background then we can build our model with sequential the model compilation dataset preparation and training can be repeated as mentioned above after trying both approaches i figured out i might not understand how to use featurespaceadapt thoroughly which leads to the fact that the first approach performs much better the model gives tremendously better metrics maybe someone can clear this for me as well i hope that help
78245568,understanding batching in pytorch models,python machinelearning deeplearning pytorch transformermodel,check the docs transformer class transformer decoder for an unbatched dim input where src s e and tgt t e the output will be of shape t e in the transformer decoder layer the first argument is tgt which defines the output size since you define your tgt param l as torchrandn d your transformer decoder output will be of size d this has nothing to do with broadcasting this is just the inputoutput mechanics of the transformer layer
78048435,trying to understand pytorch runtimeerror trying to backward through the graph a second time,python deeplearning pytorch recurrentneuralnetwork,adding totalloss totallossdetach after modeloptstep is indeed the solution as clarified by c p to properly update the optimizer from the averaged loss after each batch
77821670,neural networks unable to understand the behaviour of the output layer,python keras deeplearning neuralnetwork,yes i understand your question the output layer should be equal to the number of target classes for example in your case take output neuron as ytrainnunique is then the final layer output and label should be in the range of the label value will be not included in that specific range so it throw error received a label value of which is outside the valid range becasuse the label will not include in the final softmax neuron number of the above represent the softmax layer with the classes of is class is class is class if number of class only class probability in softmax will be created in your case the number of classes will be if ytrainnunique is then the final layer output and label should be in the range of here for the th class the probability softmax will be created so the code works fine sum of all classes probability will be result in the missing is also will be consider as one class
77367649,what is the difference between registerforwardhook and registermoduleforwardhook in pytorch,deeplearning pytorch neuralnetwork,i was just trying to figure out the same question and found your question when googling for it from some digging registerforwardhook was added in this pr years registermoduleforwardhook was added years ago in this pr it appears former needs to be set on a permodule basis while later is a global hook you set once to run for every module looking at blame for registermoduleforwardhook shows this relevant issue with more details from months ago it sounds like the latter is the better choice for your case in particular considering comments from latest commit as it makes it compatible with context managers for example you can use it to compute perexample activation norms on every layer by using a context manager like this full code from colab
76935321,sb attributeerror dummyvecenv object has no attribute getactionmeanings,deeplearning reinforcementlearning stablebaselines,i managed to solve using envs is a list of environments
76747386,what is s in coco object keypoint similarity equation,python deeplearning computervision objectdetection,what does the s rapresents the s in the oks equation represents the object scale which is a measure of the size of the object that the keypoints belong to meaning that in keypoint detection tasks such as human pose estimation one of the most common applications of keypoint detection an object refers to the entity of interest in the image in this case a human being the scale of an object typically refers to its size in the context of the image its often represented as the area of the bounding box containing the object for a human pose estimation task if the bounding box around the person is large it means that the person or the object appears larger in the image thus having a larger scale conversely if the bounding box is small the person appears smaller in the image and the scale is smaller the scale is critical when considering the distance between keypoints like elbows knees eyes etc on a human body for a larger scale big bounding box the keypoints are generally farther apart because the person takes up more space in the image for a smaller scale small bounding box the keypoints are closer together because the person appears smaller in the oks equation s is used to normalize the distances between the predicted and actual keypoints why diving by it by dividing by the scale we account for the fact that an error of say five pixels is a lot more significant if the person is small in the image and thus the keypoints are close together than if the person is large in the image and the keypoints are far apart
76739339,how to understand the structure of a neural network,python deeplearning neuralnetwork,argsuserelu is a bool that is used as an index on a the list nntanh nnrelu python automatically converts it to an integer for false and for true this is an opaque but concise way of saying if argsuserelu selfactivatefunc nnrelu else selfactivatefunc nntanh
75989228,i am trying to build a variational autoencoder i am getting an error while running modelfit which i dont understand,python tensorflow keras deeplearning autoencoder,i remember this happened to me as well it seems that tensorflow doesnt support a vaeloss function like this anymore i have solutions to this i will paste here the short and simple one instead of creating a vaeloss function you need to add the loss like this i also have another solution to this problem that is using a custom model you can find this solution here
75644566,explaining the derivative in a neural network with one neuron,python math deeplearning neuralnetwork derivative,write the weight as w input as x goal as g and loss function ie sqerror in the code as l then l wx g what we need for backpropagation is the gradient of the loss function with respect to weight which is dl dw xwx g which is equivalent to input clearerror so the derivative in the code is actually half the real gradient but being out by a constant factor doesnt matter youre scaling the gradient by alpha anyway if you want to break the calculation of the derivative down further write u wx g so that l u so du dw x and dl du u then dl dw dl du du dw chain rule ie dl dw ux xwx g dl dw input clearerror in terms of the variables in your code so derivative is equivalent to dl dw
75374120,what is meant by stability in relation to neural networks,machinelearning deeplearning,stability also known as algorithmic stability is a notion in computational learning theory of how a machine learning algorithm is perturbed by small changes to its inputs a stable learning algorithm is one for which the prediction does not change much when the training data is modified slightly here stability means suppose you have training data that you use to train the model and it performs well so in terms of model stability if you train the same model with training data the model should still perform well thats why it is also called as algorithmic stability as for the loss graph if the model is stable the loss graph probably should be same for both size of training data and different in case of unstable model as in machine learning we want to minimize loss so when we say a model converges we mean to say that the models loss value is within acceptable margin and the model is at that stage where no additional training would improve the model divergence is a nonsymmetric metrics which is used to measure the difference between continuous value for example you want to calculate difference between graphs you would use divergence instead of traditional symmetric metrics like distance
75305535,what is the difference between object detection fps and video fps,python deeplearning framerate,if i understand correctly your object detection fps indicates the number of frames or images that your model given your system can process in a second a video fps in your input sources frames per second for example if your video has an fps also referred to as framerate of then your model would be able to detect objects in all of the frames in ms or of a second in your case your video input source seems to have frames in a second this means that your model given your system will process second wort of a video in about ms
75250628,while coding a gan and i encountered an error saying please explain this error and some possible solutions,deeplearning pytorch tensor generativeadversarialnetwork pytorchdataloader,please check your getgenblock function looks like you missed else branch or messed up the indentation and when finalblock false it returns none instead of return nnsequential nnconvtransposedinchannels outchannels kernelsize stride nnbatchnormdoutchannels nnrelu if cond return module return module always returns module when condition is met otherwise none i think you wanted this if cond return module return module when condition is met return module otherwise module and now compare the indentation
74947598,what is recursive under the number of parameters in the summary of neural netwroks in pytorch,python deeplearning pytorch neuralnetwork,the problem is with hiddenlayers torchnnlinearnumunits numunits activationfun it recreates a pointer to the same linear and the activation function so they are executed twice instead of constructed twice
74710732,what are the differences between adapter tuning and prefix tuning,machinelearning deeplearning artificialintelligence finetuning fewshotlearning,these are alternatives to finetuning model they are essentially solutions that reside between fewshot learning and complete finetuning of models the other answer in this so post is completely wrong finetuning has nothing to do with neither prompt tuning nor prefix tuning these two are completely different techniques than finetuning correct reference to prompt tuning and prefix tuning are given below prompt tuning for prompt tuning k learnable parameter ie continuous token embeddings is appended to the input but the entire pretrained language model is frozen prefix tuning for k positions prepended to the input concatenate additional learnable weights for keys and values at every attention layer different to prompt tuning only learnable input vectors papers that introduced these techniques are given below prompt tuning prefixtuning
74548358,what is the difference between tensorflow glorotnormal and glorotuniform,tensorflow keras deeplearning recurrentneuralnetwork,as far as i understand the normal and uniform of glorot are very similar the main difference is in the random values that are pulled during the initialization in the normal variation the random values are pulled from a normal distribution centered around which you also know as gaussian and in the uniform case from the uniform distribution with limit limitlimit where limit sqrt fanin fanout as for your second question which is better for rnn im not aware that there is a consensus which approach is better there is still an ongoing discussion but you can find a good insight in this answer in the datascience stackexchange
74106965,aggregation by mlp for gin and gcn what is the difference,deeplearning pytorch mlp pytorchgeometric graphneuralnetwork,you can see ginconv and gcnconv api from torchgeometric ginconv there is a nn argument eg defined by torchnnsequential therefore in the tutorial you mentioned above can use the sequential method gcnconv but gcnconv does not have nn argument when you wonder about a method you dont know searching for the method in api is a good way to solve issues
73594247,what is the reason for low gpu util when training machine learning model,machinelearning deeplearning pytorch gpu cpu,there are basically two ways of using multigpus for deep learning use torchnndataparallelmodule dp this function is quite discouraged by the official documentation because it replicates the entire module in all gpus at each forward pass at the end of forward pass the models are destroyed therefore when you have big models it could be an important bottleneck in your training time and even slow it by compared to single gpu it could be the case for instance when you freeze a large part of big module for fine tuning thats why you may consider using torchnnparalleldistributeddataparallelmodule deviceids ddp documentation this function often requires refactoring your code a little bit more but it improves the efficiency because it copy the models on gpus only once at the beginning of the training the models are persistent over time and the gradients are synchronized after each backward pass via hooks to go further you can distributed data and optimizer as well to avoid data transfer you can do it simply as well as parallelized modules using torchignitedistributed i dont know what kind of method you tried but i encourage you to use ddp instead of dp if you are using it
73490943,what is the right way of minibatching the validation set while training,python machinelearning deeplearning neuralnetwork minibatch,i think this question is more or less answered here what is the meaning of batchsize for validation since you dont train the model anymore it does not affect the results in other words since you dont apply minibatch gradient descent while validating your model with the validation set it does not really matter it may have an impact memorywise though
73360500,better understanding of what is used to feed yolo,deeplearning pytorch objectdetection yolo,probably the reason for your confusion is that there is nowadays a whole family of different yolo models the initial yolo model the one you refer to uses offsets relative to grid cell size nowadays most people nowadays probably use something like yolov which does not employ the grid structure anymore instead you get the annotation format that you probably got from most other websites the hackernoon article you refer to can subtract by since the grid cell is actually at in grid coordinates however when you are not you need to compensate for that so to compute x take the modulo first so as to take off all previous grid cells and then do the relative offset like so x x g g with g being grid size
73052293,detectron what is difference between inputminsize and inputmaxsize,deeplearning convneuralnetwork recurrentneuralnetwork imageresizing detectron,the answer is exactly as it says in resizeshortestedge documentation it attempts to scale the shorter edge to the given shortedgelength as long as the longer edge does not exceed maxsize if maxsize is reached then downscale so that the longer edge does not exceed maxsize you can also see this here in the source code where it calculates the new shape pasted below for easy reference def getoutputshape oldh int oldw int shortedgelength int maxsize int tupleint int compute the output size given input size and target short edge length h w oldh oldw size shortedgelength scale size minh w if h w newh neww size scale w else newh neww scale h size if maxnewh neww maxsize scale maxsize maxnewh neww newh newh scale neww neww scale neww intneww newh intnewh return newh neww so in your case you would be setting the shortedgelength to and the maxsize to if you do that referring to the code above you will see that a first a scaling factor is calculated as at the line scale size minh w b then the new width and height are calculated as and respectively at the line newh neww size scale w c lastly the condition if maxnewh neww maxsize is not satisfied so a new scaling factor is not calculated and the new width and height are not updated note that you can set the maxsize higher than as well and it will make no difference if you set it to lower than though the condition referred to in c will be true so a new scale is calculated and the new width and height are downscaled
72960439,trouble understanding resnet implementation,python deeplearning pytorch resnet imageclassification,what does a minibatch size of on two gpus entail does this mean the batch size per gpu is when running two gpus on the same machine then the batch size is split between the gpus as youve said the gradient produced by both gpus will be transfered averaged and applied on one of the gpus or possibly on the cpu heres more info how can i convert from iterations to epochs is the model trained for epochs i encourage everyone to think in terms of iterations rather than epochs each iteration equates to a single weight update which is much more relevant to model convergence than an epoch is if you think in epochs you have to adjust the number of epochs of training every time you try a different batch size this isnt the case if you use think in terms of iterations aka training steps or weight updates but your formula is correct in computing epochs how can i implement the training and learning rate scheduling in pytorch i think this pytorch post answers the question it looks like this was added to pytorch sorry for a non authoritative answer here im more familiar with tensorflow you can also just use epochs of course and adjusting the learning rate doesnt have to happen exactly at the same point as the paper describes as near as you can reasonably get with rounding error will work just fine
72881661,what is difference between the following optimization method,python deeplearning pytorch recurrentneuralnetwork,you are using two different optimization methods the first one is sgd while the nd is adam
72867845,what is the multiplicative depth of a single relu layer for encrypted inference,machinelearning deeplearning neuralnetwork seal fhe,relu is not a polynomial function over the reals and therefore an exact computation of the relu has infinite depth this problem can be eliminated in several ways one option is to replace relu by some other function such as the square activation another option is to approximate the relu using a polynomial yet another option is to use the base representation of numbers and compute relu as a logic function instead of computing it as an arithmetic function other options may exist
72865629,understanding model training and evaluation in pytorch,python deeplearning pytorch,for each epoch you are doing train followed by validationtest for validationtest you are moving the model to evaluation model using modeleval and then doing forward propagation with torchnograd which is correct again you are moving back the model back to train model using modeltrain at the start of train there is no issue with the code and you are using the model modes correctly in your code if adaptivelr if false then you are optimizing the parameters given by modelparameters and when adaptivelr is true then you are optimizing modelweight modellinearparameters modellinearparameters modellayersparameters
72811155,what are some of the best practices to reduce the size of mlrelated docker image,python docker machinelearning deeplearning,first keep the data if any apart from the image in volumes for examplealso use dockerignore to ignore files you dont want in your image now some techniques a first technique is to use multistage builds for example an to install dependencies and another starts from the first one and run the app a second technique is to minimize the number of each run copy and from command creates a different layer try to combine commands in a single one using linux operators like a third technique is to take profit of the caching in docker run every command you can before copying the actual content into the image for exemple for a python app you might install dependencies before copying the contents of the app inside the image
72771707,what is the difference between softmax or sigmoid activation for binary classification,python deeplearning classification,there is essentially no difference between the two as you describe in this question however softmax can also be applied to multiclass classification whereas sigmoid is only for binary classification sigmoid predicts a value between and graphically it looks like this softmax predicts a value between and for each output node all outputs normalized so that they sum to for example for class classification you could get the output here the second class is the prediction as it has the largest value for binary classification the output of both nodes must sum to the value output by each node is the confidence that it predicts that class for example if the output is then class is predicted with likelihood ie not very likely and class is predicted with likelihood so you can be pretty certain that it is class the only difference between these two approaches will be how you use the output of your neural network with sigmoid your output will be a single value per example eg for three different examples corresponds to example being predicted as class example being predicted class but not very certain and example being predicted class with higher certainty with softmax for each example you will predict two values the liklihood of class and class for that example eg meaning that example was predicted to be class with likelihood and example two was predicted class with likelihood
72726549,what is the efficient way to get compressed ml models in multiple sizes of one model for non ml expert,deeplearning artificialintelligence facerecognition,network compression is not like a slider in which you can move anywhere from slowaccurate to fastnotaccurate from your starting model you can apply some techniques which may or may not reduce the size of the network and may or may not reduce also the accuracy for example converting weights from float to float will for sure reduce the memory requirement of the network by half but can also introduce a small reduction in accuracy and its not supported on all devices my suggestion is start with the base model and perform some tests with it understand how far you are from the target fps and size of your application and then decide which approach makes more sense to reach the objective you have in mind since you said youre not an ml expert i think this kind of task at least to my knowledge requires some amount of studying of the subject and experimentation and i would start with an open source solution like for example
72611335,what are the differences between fine tuning and few shot learning,machinelearning deeplearning artificialintelligence finetuning fewshotlearning,fine tuning when you already have a model trained to perform the task you want but on a different dataset you initialise using the pretrained weights and train it on target usually smaller dataset usually with a smaller learning rate few shot learning when you want to train a model on any task using very few samples eg you have a model trained on different but related task and you optionally modify it and train for target task using small number of examples for example fine tuning training a model for intent classification and then fine tuning it on a different dataset few shot learning training a language model on large text dataset and modifying it usually last few layer to classify intents by training on small labelled dataset there could be many more ways to do few shot learning for more example training a model to classify images where some classes have very small or for zero shot and for one shot number of training samples here in inference classifying these rare classes rare in training correctly becomes the aim of few shot learning
72610665,in the latest version of pytorch what is best practice to get all tensors to use a particular device by default,python pythonx deeplearning pytorch,pytorch has an optional function to change the default type of tensor setdefaulttensortype applying the default type on the main script import torch if name main cuda torchcudaisavailable if cuda torchsetdefaulttensortypetorchcudafloattensor a torchrandn printadevice cuda or would that be a bad thing to do for some reason eg is there any reason i wouldnt want every tensoroperation to be done on cuda by default i couldnt find any reference or any document to answer this question however in my opinion its to avoid the memory fragmentation in gpu memory im not an expert but the data in memory should be arranged in an efficient way if not the redundant space will cause oom thats why in default tensorflow will take all of your gpus memory no matter how many parameters your model has you can improve the space and speed just by setting the tensor shape multiples of amp documents in practice higher performance is achieved when a and b dimensions are multiples of in conclusion i think its better to control the device of tensor manually instead of setting it gpu as default
72489551,difficulty understanding flops in this scenario,deeplearning convneuralnetwork artificialintelligence flops,some hardware manufacturers specify flops as the performance metric on the other hand you can calculate approximate flops value for your model for regular not depthwise convolutional layer it would be according to this where is for two different types of instructions multiplying and accumulating you need to keep in mind that low flops value do not automatically provide high performance
72488415,what is the difference between filed of view and receptive field,machinelearning deeplearning,these are essentially different concepts field of view is a term related to the theory of optics which means a solid angle with a vertex in the center of entrance pupil on the other hand receptive field is a term of neural networks convolutionaltransformers that means the size of the region in the input that produces the feature in the output read more here
72481620,what is coeft purpose of using t,pythonx machinelearning deeplearning pycharm logisticregression,t method means transpose which switches rows columns if you have a matrix m then mt would be it looks like its used in this line pltplotlrlcoeft to make sure it plots the coefficients in an expected way if the model was built from sklearn logisticregression then you can review the docs here coef has shape nclassesnfeatures so that means coeft has shape nfeaturesnclasses here is a notebook that shows how this works
72267884,what is the alternative of pytorch moduleregisterparametername param in tensorflow,python tensorflow deeplearning neuralnetwork pytorch,tfvariable is the equivalent of nnparameter in pytorch tfvariable is mainly used to store model parameters since their values are constantly updated during training to use a tensor as a new model parameter you need to convert it to tfvariable you can check here how to create variables from tensors if you want to add a model parameter in tensorflow inside the model itself you could simply create a variable inside the model class and it will be automatically registered as a model parameter by tensorflow if you want to add a tfvariable externally to a model as a model parameter you could manually add it to the trainableweights attribute of tfkeraslayerslayer by extending it like this
72225625,what are these files in the centernet mobilenetv from the tensorflow od model zoo do we need them,tensorflow object deeplearning detection,the modeltflite file is the pretrained model in tflite format so if you want to use the model out of the box you can use this file the labelmaptxt is used to map the output of your network to actual comprehensible results ie both of the files are needed if you want to use the model out of the box it is not needed for retraining
71918073,issue with presenting understandable predictions on a python keras cnn model,python tensorflow keras deeplearning densenet,the models predictions ie these floating point numbers are the probabilities for the respective classes eg a value of e indicating a probability of your prediction is then the element in your array of classes at the index of the maximum value in your array of probabilities meaning you want to predict whichever class gets assigned the highest probability by your model example outputs
71846855,what is the difference between these two layers conv and mbconv,machinelearning deeplearning convneuralnetwork imageclassification,a conv means that there is a convolution core to scan the matrix corresponding to the target by line and convolution the result of each convolution constitutes a value of the output matrix about the mbconvi think you means mobile inverted bottleneck convolutionits more of an encapsulated module than a single conv layer a mbconvs structure can be expressed as follows mbconv xconvascending dimension depthwise convolution senet xconvdimensionality reduction add by the way you may notice the new names depthwise convolution and senet which are also a kind of moduleshonestly its like a nesting doll if you just want to use it you dont necessarily need to fully understand it until you need to improve your model structure so my answer to your question what is the difference between these two layers conv and mbconv is the former is a simple layer and the latter is a complex module made up of many simple layers
71608032,pytorch clipgradnorm vs clipgradnorm what is the differece when it has underline,deeplearning pytorch gradient backpropagation,pytorch uses the trailing underscore convention for inplace operations so the difference is that the one with an underscore modifies the tensor in place and the other one leaves the original tensor unmodified and returns a new tensor
71187485,what is the problem with my gradient descent algorithm or how its applied,machinelearning deeplearning lua neuralnetwork backpropagation,all initial weights must be different numbers otherwise backpropagation will not work for example you can replace with mathrandom increase number of attempts to with these modifications your code works fine results input input input input
71140227,pytorch different behaviours in gan training with different but conceptually equivalent code,deeplearning neuralnetwork pytorch torch generativeadversarialnetwork,why do we different results supplying inputs in either the same batch or separate batches can make a difference if the model includes dependencies between different elements of the batch by far the most common source in current deep learning models is batch normalization as you mentioned the discriminator does include batchnorm so this is likely the reason for different behaviors here is an example using single numbers and a batch size of now we split the batch into two parts first part second part as we can see in the splitbatch version the two batches are normalized to the exact same numbers even though the inputs are very different in the jointbatch version on the other hand the larger numbers are still larger than the smaller ones as they are normalized using the same statistics why does this matter with deep learning its always hard to say and especially with gans and their complex training dynamics a possible explanation is that as we can see in the example above the separate batches result in more similar features after normalization even if the original inputs are quite different this may help early in training as the generator tends to output garbage which has very different statistics from real data with a joint batch these differing statistics make it easy for the discriminator to tell the real and generated data apart and we end up in a situation where the discriminator overpowers the generator by using separate batches however the different normalizations result in the generated and real data to look more similar which makes the task less trivial for the discriminator and allows the generator to learn
71102661,what is validation set for yolov training and is it necessary,deeplearning pytorch trainingdata yolov,the validation dataset provides an unbiased assessment of a fitted model on the training dataset while fitting the models hyperparameters eg the number of hidden units layers and layer widths in a neural network validation datasets can be used for early stop regularization stopping training when the error in the validation dataset increases as this is a sign of overfitting to the training dataset
70961541,what is the official implementation of first order maml using the higher pytorch library,machinelearning deeplearning pytorch convneuralnetwork pytorchhigher,the reason why trackhighergradsfalse doesnt actually work is that it detaches the gradients of the postadaptation parameters rather than just the gradients see here so you get no gradient at all from your outer loop loss what you really want is just to detach the gradients on just the inner loopcomputed gradients but leave the otherwise trivial computation graph between model initialization and adapted parameters intact
70865699,what is different between dataloader and dataloader in pytorch,python deeplearning pytorch datascience,you should definitely not use it dataloader torchutilsdatadataloader actually torchutilsdatadataloaderexperimentaldataloader was added as an experimental feature as a future replacement for dataloader it is defined here currently it is only accessible on the master branch unstable and is of course not documented on the official pages
70806915,what is json and ymal models in tensorflow,python tensorflow deeplearning,they are common file formats not too different from txt or csv files they store data that will be read and written to by tensorflow in your case when you train a model you will be able to save it in a json or yaml format these formats are generally pretty humanreadable the functions you are referring to can load a saved model configuration from a json or yaml file
70713265,understanding pytorch weight and biases in linear layer,python deeplearning neuralnetwork pytorch gradientdescent,you simply need to expand the original equation of two linear layers ie you can expand x a b c d x a c b c d also note that matrix multiplication transpose rule is also used here ie transposeab transposeb transposea thats why combinedlayerweightt is multiplied by x as we didnt take transpose in layerweight layerweight
70359575,understanding maskrcnn annotation feed,deeplearning convneuralnetwork objectdetection mask imagesegmentation,if i understand correctly the shape of the annotation becomes longer and more stretched out if going for multicross annotation in that case you can change the size and side ratio of the anchors that are scanning the objects with default settings the model often has squarish bounding boxes this means that very long and narrow annotations create bounding boxes with a great difference between width and height these objects seem to be harder to segment and detect by the model these are the default configurations in the configpy file length of square anchor side in pixels rpnanchorscales ratios of anchors at each cell widthheight a value of represents a square anchor and is a wide anchor rpnanchorratios you can play around with these values in inference mode and look if it gives you some better results
70254984,what is the classification algorithm used by keras,tensorflow machinelearning keras deeplearning,youre using a convolutional neural network cnn
69990009,understanding intermediate values and pruning in optuna,python machinelearning deeplearning hyperparameters optuna,the basic model creation can be done by passing a complete training datasets once but there are models that can still be improved an increase in accuracy by retraining again on the same training datasets to see to it that we are not wasting resources here we would check the accuracy after every step using the validation datasets via intermediatescore if accuracy improves if not we prune the whole trial skipping other steps then we go for next trial asking another value of alpha the hyperparameter that we are trying to determine to have the greatest accuracy on the validation datasets for other libraries it is just a matter of asking ourselves what do we want with our model accuracy for sure is a good criteria to measure the models competency there can be others example optuna pruning i want the model to continue retraining but only at my specific conditions if intermediate value cannot defeat my bestaccuracy and if steps are already more than half of my max iteration then prune this trial optuna has specialized pruners at
69909781,how to understand the results of training a neural network type transformer bert,python tensorflow deeplearning neuralnetwork pytorch,the loss starts at which is arbitrary because the first epoch is a randomisation of the weights and so you would be extremely lucky to be accurate early on the learning rate you supply to trainingarguments is just the initial learning rate the training method adapts this automatically the learning rate changing indicates that the initial rate may be too high or too low and the method is adapting to prevent overfitting or underfitting the data based on the returned loss and accuracy of each epoch the accuracy and loss are good measures to track across the epochs less loss is better more accuracy is better if you also had an accuracy measure you could compare accuracy to evalaccuracy and if the evalaccuracy becomes higher than the accuracy then you are starting to overfit the data
69620683,explain x tfkeraslayersdense activationrelupretrainedmodeloutput,tensorflow deeplearning computervision artificialintelligence,in the first line you define inputs to be equal to the inputs of the pretrained model then you define x to be equal to the pretrained models outputs after applying an additional dense layer tensorflow now automatically recognizes how inputs and x are connected if we assume the the pretrained model consists of the five layers pretrainedin pretrainedh pretrainedh pretrainedh pretrainedout this means that tensorflow realizes that the information will take the following way inputs pretrainedin pretrainedh pretrainedh pretrainedh pretrainedout newdenselayer x if we now take the final layers into account we will have the following information flow inputs pretrainedin pretrainedh pretrainedh pretrainedh pretrainedout newdenselayer x denselayersoftmax outputs now the model tfkerasmodelinputsinputs outputsoutputs statement just tells tensorflow that it is supposed to treat this information flow as a new model so that you can easily pass new information through all of these layers by just using this new model edit you asked why dense is followed by two brackets the layersdense call is actually not the function that processes your data instead if you call tfkeraslayersdense tensorflow basically creates a new dense layer and returns it to you which you can then use to process your data you could actually write this in two lines to make it more clear
69406476,what is the meaning of perlayer learning rate in fast rcnn paper,deeplearning pytorch fasterrcnn,the perlayer terminology in that paper is slightly ambiguous they arent referring to the layerspecific learning rates all layers use a perlayer learning rate of for weights and for biases and a global learning rate of the concerned statement is wrt caffe framework in which fast rcnn was originally written github link they meant that theyre setting the learning rate multiplier of weights and biases to be and respectively check any prototxt file in the repo eg caffenettrainprototxt thus the effective learning rate is going to be baselrlrmult and here the base learning rate is which is defined in solverprototxt
69240517,what is the best choice for an activation function in case of small sized neural networks,python machinelearning deeplearning pytorch activationfunction,in the deep learning world relu is usually prefered over other activation functions because it overcomes the vanishing gradient problem allowing models to learn faster and perform better but it could have downsides dying relu problem the dying relu problem refers to the scenario when a large number of relu neurons only output values of when most of these neurons return output zero the gradients fail to flow during backpropagation and the weights do not get updated ultimately a large part of the network becomes inactive and it is unable to learn further what causes the dying relu problem high learning rate if learning rate is set too high there is a significant chance that new weights will be in negative value range large negative bias large negative bias term can indeed cause the inputs to the relu activation to become negative how to solve the dying relu problem use of a smaller learning rate it can be a good idea to decrease the learning rate during the training variations of relu leaky relu is a common effective method to solve a dying relu problem and it does so by adding a slight slope in the negative range there are other variations like prelu elu gelu if you want to dig deeper check out this link modification of initialization procedure it has been demonstrated that the use of a randomized asymmetric initialization can help prevent the dying relu problem do check out the arxiv paper for the mathematical details sources practical guide for relu relu variants dying relu problem
69148722,what is the alias to pytorch nnmodule in tensorflow,python tensorflow deeplearning pytorch,in this case nnmodule is used to create a custom layer tensorflow has a tutorial on that please take a look in short one way you could implement it is with tfkeraslayerslayer where call is the equivalent of forward in pytorch class channelpooltfkeraslayerslayer def callself inputs return tfconcattfreducemaxinputs axis keepdimstrue tfreducemeaninputs axis keepdimstrue axis you can check that they are equivalent like this import torch from torch import nn import tensorflow as tf import numpy as np class pytorchchannelpoolnnmodule def forwardself x return torchcattorchmaxx unsqueeze torchmeanx unsqueeze dim class tensorflowchannelpooltfkeraslayerslayer def callself inputs return tfconcattfreducemaxinputs axis keepdimstrue tfreducemeaninputs axis keepdimstrue axis nprandomseed x nprandomrandomastypenpfloat a pytorchchannelpool b tensorflowchannelpool pytorchoutput atorchfromnumpyxnumpy tensorflowoutput bxnumpy npallpytorchoutput tensorflowoutput true
68788411,unable to understand unet architecture,python deeplearning pytorch imagesegmentation,thats a design decision so you wont find a clear reason for your question other than that the numbers in architecture are usually kept as multiple of here this is for practical reasons it is usually the goto method when testing variablesized networks they will try varying the numbers of layers and numbers of channels as well as other network layouts and figure out which one is best for the task by experimenting by your first question should we need to choose it randomly why would you not stick to the networks specification if youre looking to replicate it in the first place if you ever find an advantage to putting instead of or even if you have the capacity to do so then go right ahead
68708396,need help in understanding shape error while building a cnn with sklearn and keras,python tensorflow keras scikitlearn deeplearning,you havent passed y label to model while calling model needs both and x and y label to train accordingly here i added an example please take a pause and go through videos of keras architecture and documentation in keras io these would give more information about deep learning modelling once after you got familiar with all jump to modelling
68171716,what is the input shape of the inputlayer in keras tensorflow,python tensorflow deeplearning tfkeras,inputlayer is actually just the same as specifying the parameter inputshape in a dense layer keras actually uses inputlayer when you use method in the background the parameter inputshape is actually supposed to be a tuple if you noticed that i set the inputshape in your example to be this is a tuple with a single element in it as your data is d you pass in a single element at a time therefore the input shape is if your input data was a d input for example when trying to predict the price of a house based on multiple variables you would have multiple rows and multiple columns of data in this case you pass in the input shape of the last dimension of the xregtrain which is the number of inputs if xregtrain was then we use the inputshape of ignoring the batchsize for a moment with this we are actually just sending a single row of the data to predict a single house price the batchsize is just here to chunk multiple rows of data together so that we do not have to load the entire dataset into memory which is computationally expensive so we send small chunks with the default value being when running the training you would have noticed that under each epoch it says which are for the batches of data you have since the training size is rounded up for d input with the dense layer it actually just gets flattened to a d input ie from batchsize sequencelength dim batchsize sequencelength dim batchsize sequencelength hiddenunits which is the same as using a convd layer with a kernel of so i wouldnt even use the dense layer in this case
68145649,what is the argument referring to in the message passing class,machinelearning deeplearning pytorch pytorchgeometric,after referring to here and here i think the thing related to it is the output of the message function in most cases the shape of the output is edgenum embout and if we set the nodedim as it means that we will aggregate along the edgenum using indices of the target nodes this is exactly the process that aggregates the information from source nodes the result after aggregation is nodenum embout
68069272,what is the name of different layers in my pytorch model,python deeplearning pytorch convneuralnetwork,the names are given by whats inside the parentheses be aware that modulelist is a list type so the modules within are addressed by index the pytorch forums are usually quite good for that this post describes how you can access and alter a layer but it similarly applies to register a forward hook for instance in your case will get you the basicmodule in the first encoder
68045316,rbf layer difficulty in understanding,python tensorflow machinelearning deeplearning neuralnetwork,gamma according to the doc the gamma parameter defines how far the influence of a single training example reaches with low values meaning far and high values meaning close the behavior of the model is very sensitive to the gamma parameter when gamma is very small the model is too constrained and cannot capture the complexity or shape of the data its a hyperparameter kwargs kwargs is used to let the functions take an arbitrary number of keyword arguments details call in the call function youre calculating the radial basis function kernel ie rbf kernel defined as follows source the calculation of numerator part the calculation of denominator part the selfgamma can be expressed as follows
67996880,what are the costs of many trainable parameters and layers in machine learning,machinelearning deeplearning convneuralnetwork,do more params mean more ram is required to load the model yes it requires more ramvram depending on your training mode do more params mean the model is computationally expensive ie requires better hardware to train yes do more params mean the model takes longer to train and classify or is the change negligible in most cases yes it takes longer as the number of calculations increases i noticed that deeper models with more params have a larger file size when the models are saved are there any other costs aside from what you have already pointed out yes the optimization can be affected the training regime is affected most sources i can find on this topic just mention keeping the params low but never elaborate and why exactly we do this when the number of trainable parameters increases the number of calculations also increases this denotes an increase in the hardware requirements both in form of ram and processing power it also introduces difficulties in terms of optimization such as overfitting or even altogether the choice of the optimization algorithm used the transfer of the model can become an issue depending on your use case for example consider iot devices drones autonomous vehiclesrobots that require updates etc badpoor connection speed etc and stuff like this there are ways to reduce the model size and increase its performance but in general the more parameters means more spacetime
67870887,trouble understanding behaviour of modified vgg forward method pytorch,python deeplearning neuralnetwork pytorch convneuralnetwork,i cant run your code but i believe the issue is because linear layers expect d data input as it is really a matrix multiplication while you provide d input with dims and of size please try squeeze for less hackylooking code in the squeeze part see torch einops
67582871,what is the difference between resnet and yolo or rcnn,machinelearning deeplearning computervision artificialintelligence,resnet is a family of neural networks using residual functions a lot of neural network use resnet architecture for example resnet resnet wide resnet resnest and many more it is commonly used as a backbone also called encoder or feature extractor for object detection object segmentation and many more there is others families of nets like vgg efficientnets etc fasterrcnnrcn yolo and ssd are more like pipeline for object detection for example fasterrcnn use a backbone for feature extraction like resnet and a second network called rpn region proposal network take a look a this article which present the most common pipeline for object detection
67562663,deep learning for d datasets what is the best way to prepare a pipeline and which algorithm would be best,machinelearning deeplearning pipeline,the fact that your problem is d does not mean your dataset have to be this seems to me like a very straight forward machine learning problem you could reformat your data into one dateset were each rows contains cell location x y z cell type subattribute and the target temperature the preprocessing required will depend on the kind of model you choose some dont support categorical input others do you can use deep learning if you prefer but they typically dont work with categorical variable so youll have to encode all textual information and instances is very small to train that kind of model you might have more luck with a random forest algorithm as a first step
67513214,what is bias node in googlenet and how to remove it,deeplearning neuralnetwork computervision pytorch,to compute the layer n outputs a linear neural network computes a linear combination of the layer n output for each layer n output adds a scalar constant value to each layer n output the bias term and then applies an activation function in pytorch one could disable the bias in a linear layer using to overwrite the existing structure of say the googlenet included in torchvisionmodels defined here you can simply override the last fully connected layer after initialization
67360314,what is the correct last layer for a concatenate multiinput deep neural network in keras,python keras deeplearning neuralnetwork classification,the intermediate layers do not have to output categories as in model theres no correct way in this case its just two different way in the case of model the added layer is compressing the information of each channel into cells it could be interpreted as if each channel was asked to do their own prediction and the last one rely on the intermediate predictions to output the final class whereas in the case of model the final layer has much more connections with the channels layers but the overall model is less deeper but none of this can tell you in advance which one is the best in your case
67176320,modulenotfounderror no module named tfexplain,tensorflow installation deeplearning convneuralnetwork,i tested on windows and linux colab os and it works your issue probably involves a spyder environment setup
67104205,what is the activation layer used for tensorflow text classification example,tensorflow machinelearning keras deeplearning activationfunction,as you read the model definition is written something like this and the data set used in that tutorials is a binary classification zero and one by not defining any activation to the last layer of the model the original author wants to get the logits rather than probability and that why they used the loss function as now if we set the last layer activation as sigmoid which usually pick for binary classification then we must set fromlogitsfalse so here are two option to chose from with logit true we take the logit from the last layer and that why we set fromlogitstrue without logit false and here we take the probability from the last layer and that why we set fromlogitsfalse now you may wonder why this tutorial uses logit or no activation to the last layer the short answer is it generally doesnt matter we can choose any option the thing is there is a chance of numerical instability in the case of using fromlogitsfalse check this answer for more details
66964167,understanding loss functions,deeplearning neuralnetwork pytorch lossfunction,that function is the euclidean lnorm it returns the sum of the squared errors between network output and expected output as for the derivative of the function or better its gradient it it computed internally by the deep learning framework you are using here pytorch i assume and is needed to update the network parameter for most use cases you do not need to think at it its computation is totally automatic one note if you call item on a tensor you are extracting its raw value ie what you get is no more a tensor but just a number this means that you cannot compute the gradient from it call backward
66931281,what is the sequence of preprocessing operations when using keras imagedatagenerator,tensorflow keras deeplearning computervision convneuralnetwork,whether the rescaling will happen first or the preprocessfunction or such rescaling will be applied after the transformations are done preprocessfunction after augmention for featurewise functionalities you need to fit the generator to the data from the docs will these happen all at once or the class will select one transformation at a time transformations are applied randomly on each image preprocessfunction will be applied on each image after the augmention completed if it is selecting all at once zooming flipping shifting rotating shearing will lead to an alien object in the image where doing one or more in random order makes sense for the cases exactly they will seem awkard but you specify ranges when using imagedatagenerator so transformations will be applied in that range randomly example will generate it is clear that not every zoomed with a factor of or vice versa
66849867,understanding input and output size for convd,python deeplearning pytorch convneuralnetwork,these are the dimensions of the itself ie height x width unpadded convolutions unless you pad your zeros a convolutional filter will shrink the size of your output filtersize across the height and width filter takes a x a x image zero padding preserves you can add padding in pytorch by setting convdpadding chain of transformations since it has gone through layer shape transformation one conv layer without padding h w h w a maxpool h w another conv layer without padding h w another maxpool h w a flatten h w we go from the original of to to to to to x to visualise this you can use the torchsummary package layer type output shape param convd maxpoold convd maxpoold linear linear linear
66420064,what is the behaviour when resuming the training when learning rate decay is used in tensorflowkeras,tensorflow keras deeplearning learningrate,when you restart training after using modelsave it trains with the learning rate it had when you saved the model to make sure i wrote a simple callback using the learning rate scheduler callbackthe code for the callback is shown below i then trained a model for epochs saved the model loaded the model and trained again the callback prints the value of the learning rate at the beginning of each epoch and shows when training resumes the learning rate was preserved put this in your code before you call modelfit then in modelfit include
66370887,understand and implement elementwise attention module,python tensorflow machinelearning keras deeplearning,understanding the elementwise attention when paper introduce they method they said the attention modules aim to exploit the relationship between disease labels and diagnosisspecific feature channels diagnosisspecific locations on images ie the regions of thoracic abnormalities and diagnosisspecific scales of the feature maps corresponding to channelwise attention elementwise attention scalewise attention we can tell that elementwise attention is for deal with disease location weight info ie at each location on image how likely there is a disease as it been mention again when paper introduce the elementwise attention the elementwise attention learning aims to enhance the sensitivity of feature representations to thoracic abnormal regions while suppressing the activations when there is no abnormality ok we could easily get location weight info for one disease but we have multiple disease since there are multiple thoracic diseases we choose to estimate an elementwise attention map for each category in this work we could store the multiple disease location weight info by using a tensor a with shape height width number of disease the allcategory attention map is denoted by a rhwc where each element aijc is expected to represent the relative importance at location i j for identifying the cth category of thoracic abnormalities and we have linear classifiers for produce a tensor s with same shape as a this can be interpret as at each location on feature maps xca how confident those linear classifiers think there is certain disease at that location now we elementwise multiply s and a to get m ie we are prevent the attention maps from paying unnecessary attention to those location with nonexistent labels so after all those we get tensor m which tells us location weight info about certain disease that linear classifiers are confident about it then if we do global average pooling over m we get prediction of weight for each disease add another softmax or sigmoid we could get prediction of probability for each disease now since we have label and prediction so naturally we could minimizing loss function to optimize the model implementation following code is tested on colab and will show you how to implement channelwise attention and elementwise attention and build and training a simple model base on your code with densenet and without scalewise attention ps serendipity i also answered your another question related to this paper few month back how to place custom layer inside a inbuilt pre trained model
66334784,is it meaningless to use reducelronplateau with adam optimizer,tensorflow machinelearning keras deeplearning tfkeras,conceptually consider the gradient a fixed mathematical value from automatic differentiation what every optimizer other than pure sgd does is to take the gradient and apply some statistical analysis to create a better gradient in the simplest case momentum the gradient is averaged with previous gradients in rmsprop the variance of the gradient across batches is measured the noisier it is the less rmsprop trusts the gradient and so the gradient is reduced divided by the stdev of the gradient for that weight adam does both then all optimizers multiply the statistically adjusted gradient by a learning rate so although one colloquial description of adam is that it automatically tunes a learning rate a more informative description is that adam statistically adjusts gradients to be more reliable but you still need to decide on a learning rate and how it changes during training eg a lr policy reducelronplateau cosine decay warmup etc are examples of an lr policy whether you program tf or pytorch the psuedocode on pytorchs optimizers are my go to to understand the optimizer algorithms looks like a wall of greek letters as first but youll grok it if you stare at it for a few minutes
66299408,what are the differences between aggregation and concatenation in convolutional neural networks,deeplearning convneuralnetwork terminology,concatenation generally consists of taking or more output tensors from different network layers and concatenating them along the channel dimension aggregation consists in taking or more output tensors from different network layers and applying a chosen multivariate function on them to aggregate the results summation is a special case of aggregation where the function is a sum this implies that we lose information by doing aggregation on the other hand concatenation will make it possible to retain information at the cost of greater memory usage eg in pytorch
66255161,what is the difference between stepsperepoch and batch size in tensorlfows modelfit method,tensorflow machinelearning keras deeplearning neuralnetwork,here is a simple example assume that you have training samples and you set the batch size to in that case you will need to run batches of data if you want to go through all of your training data once for each epoch so to do that you set stepsperepoch many people set stepsperepochnumber of train samplesbatchsize this is a good approximation to go through all your training examples in an epoch but it only works exactly once if batchsize is a factor of the number of train samples below if a piece of code i wrote that determines the batchsize and stepsperepoch to go through the samples exactly once per epoch in the code length is equal to the number of samples and bmax is the maximum batch size you will allow based on memory constraints for training going through the training set exactly once isnt that important if you shuffle your data however for validation and test going through the validation set once or the test set once is important to get a precisely true result
66254168,what are the benefits of fully convolutional neural networks compared to cnns with pooling,machinelearning deeplearning computervision artificialintelligence convneuralnetwork,with fcns we avoid the use of dense layers which means less parameters and because of that we can make the network learn faster if you avoid pooling your output will be of the same heightwidth of your input but our goal is to reduce the size of the convolutions because it is much more computationally efficient also with pooling we can go deeper as we go through higher layers individual neurons see more of the input in addition it helps to propagate information across different scales usually those networks consists of a downsampling path to extract all the necessary features and an upsampling path to reconstruct highlevel features back to the original there are some architecture like the all convolutional net by springenberg that avoids in a sense pooling in favor of speed and simplicity in this paper the author replaced all pooling operations with stride convolutions and used a global average pooling at the output layer the global averaging pooling operation reduce the dimension of the given input
66127619,understanding of classification report generated from my model,pythonx machinelearning scikitlearn deeplearning neuralnetwork,try using texty is an already n shaped vector with classes and will always give same value for testyargmaxaxis which is equal to thats why your first class has a precision of while the second has a precision of because you have predicted all s correctly predictionsargmaxaxis is a n shaped vector has probability values for class and class you will have to convert it to its classes by taking the argmax so dont change that
66036697,what is the purpose of a sequence folding layer in matlab,matlab deeplearning neuralnetwork timeseries convneuralnetwork,what would be the function of such a sequence folding layer and how would the architecture need to be changed simply speaking youre parsing in a sequence or as you called it an array of images whereas you need to convert them into a batch of images before performing any convolutional operations documentation about sequencefoldinglayer a sequence folding layer converts a batch of to a batch of images use a sequence folding layer to perform convolution operations on time steps of independently regarding the usage of a sequencefoldinglayer once again suggested to check out the documentation to use a sequence folding layer you must connect the minibatchsize output to the minibatchsize input of the corresponding sequence unfolding layer for an example see create network for video classification on said website are also lots of examples on how to create a sequence folding layer eg one with the name of fold as well as examples on how to properly implement it within your project
65942486,explain concept of instantiating a model with another model as argument vggfacemodelresnet includetopfalse,deeplearning convneuralnetwork resnet,in fact it does recognizes faces but the model parameter is used to specify which architecture is used in this case resnet see dont know much about resnet but its a residual network and that means that one of the earliest layers usually the input is feed back into the network in a later layer as a technique to increase accuracy on big networks this one has layers more details
65842406,what is keras imagedatagenerator logic,python keras deeplearning,this is not exactly how imagedatagenerator works it does not multiply your data if you dont pass any argument during the instantiation it will just fetch your images from the folder and feed them unspoiled to the network when you add rotationrange widthshiftrange you are instructing the datagenerator to apply random modification to the incoming images within the specified range these are random augmentation during the training they are not pushed after your done with your initial data
65812100,what is the best way to create augmentation on while training instance segmentation,deeplearning computervision pytorch artificialintelligence imagesegmentation,try this tensorflowkeraspreprocessingimageimagedatagenerator
